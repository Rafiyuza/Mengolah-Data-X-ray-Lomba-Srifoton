{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":115030,"databundleVersionId":13879602,"sourceType":"competition"},{"sourceId":594330,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":444828,"modelId":461313},{"sourceId":594331,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":444829,"modelId":461314},{"sourceId":594746,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":445179,"modelId":461658},{"sourceId":594798,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":445215,"modelId":461693}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**RESNET-50**","metadata":{}},{"cell_type":"code","source":"import os\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, random_split, WeightedRandomSampler\nfrom torchvision import datasets, transforms, models\nfrom sklearn.metrics import classification_report, confusion_matrix, balanced_accuracy_score\nimport pandas as pd\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nfrom collections import Counter\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# ==========================\n# 1. Configuration\n# ==========================\nclass Config:\n    # Path\n    train_dir = \"/kaggle/input/final-srifoton-25-machine-learning-competition/train/train\"\n    test_dir = \"/kaggle/input/final-srifoton-25-machine-learning-competition/test/test\"\n    \n    # Device\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    \n    # Training parameters\n    batch_size = 32\n    learning_rate = 1e-4\n    weight_decay = 1e-4\n    num_epochs = 25\n    patience = 8\n    \n    # Image parameters\n    img_size = 224  # Standard size yang lebih stable\n    \n    print(f\"Device: {device}\")\n    print(f\"Image size: {img_size}\")\n\nconfig = Config()\n\n# ==========================\n# 2. Fixed Data Transforms\n# ==========================\n\n# Training transforms - medical imaging specific\ntransform_train = transforms.Compose([\n    transforms.Resize((config.img_size, config.img_size)),\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.RandomRotation(degrees=10),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\n# Validation transforms (NO augmentation)\ntransform_val = transforms.Compose([\n    transforms.Resize((config.img_size, config.img_size)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\n# Test transforms\ntransform_test = transforms.Compose([\n    transforms.Resize((config.img_size, config.img_size)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\n# ==========================\n# 3. Dataset Functions\n# ==========================\ndef analyze_class_distribution(dataset_path):\n    \"\"\"Analyze and print class distribution\"\"\"\n    class_counts = {}\n    total = 0\n    \n    for class_name in os.listdir(dataset_path):\n        class_path = os.path.join(dataset_path, class_name)\n        if os.path.isdir(class_path):\n            count = len([f for f in os.listdir(class_path) \n                        if f.lower().endswith(('.png', '.jpg', '.jpeg'))])\n            class_counts[class_name] = count\n            total += count\n    \n    print(\"\\n\" + \"=\"*40)\n    print(\"CLASS DISTRIBUTION ANALYSIS\")\n    print(\"=\"*40)\n    for class_name, count in sorted(class_counts.items()):\n        percentage = (count / total) * 100\n        print(f\"{class_name}: {count:,} samples ({percentage:.1f}%)\")\n    print(f\"Total: {total:,} samples\")\n    print(\"=\"*40)\n    \n    return class_counts, total\n\ndef create_weighted_sampler(dataset):\n    \"\"\"Create weighted sampler for imbalanced dataset\"\"\"\n    # Get class distribution\n    class_counts = Counter()\n    for i in range(len(dataset)):\n        _, label = dataset[i]\n        class_counts[label] += 1\n    \n    # Calculate weights (inverse of class frequency)\n    class_weights = {}\n    total_samples = sum(class_counts.values())\n    \n    for class_idx, count in class_counts.items():\n        class_weights[class_idx] = total_samples / (len(class_counts) * count)\n    \n    # Create sample weights\n    sample_weights = []\n    for i in range(len(dataset)):\n        _, label = dataset[i]\n        sample_weights.append(class_weights[label])\n    \n    print(\"\\nClass weights for sampling:\")\n    for class_idx, weight in class_weights.items():\n        print(f\"Class {class_idx}: {weight:.3f}\")\n    \n    return WeightedRandomSampler(\n        weights=sample_weights,\n        num_samples=len(sample_weights),\n        replacement=True\n    )\n\n# ==========================\n# 4. Enhanced Model (ResNet50)\n# ==========================\nclass ChestXrayClassifier(nn.Module):\n    def __init__(self, num_classes=3, pretrained=True):\n        super(ChestXrayClassifier, self).__init__()\n        \n        # Load ResNet50 backbone\n        self.backbone = models.resnet50(pretrained=pretrained)\n        \n        # Get feature dimension\n        num_features = self.backbone.fc.in_features\n        \n        # Remove original classifier\n        self.backbone.fc = nn.Identity()\n        \n        # Enhanced classifier head\n        self.classifier = nn.Sequential(\n            nn.Dropout(0.5),\n            nn.Linear(num_features, 512),\n            nn.BatchNorm1d(512),\n            nn.ReLU(inplace=True),\n            \n            nn.Dropout(0.3),\n            nn.Linear(512, 256),\n            nn.BatchNorm1d(256),\n            nn.ReLU(inplace=True),\n            \n            nn.Dropout(0.2),\n            nn.Linear(256, num_classes)\n        )\n        \n        # Initialize classifier weights\n        self._init_classifier()\n    \n    def _init_classifier(self):\n        \"\"\"Initialize classifier layers\"\"\"\n        for m in self.classifier.modules():\n            if isinstance(m, nn.Linear):\n                nn.init.xavier_uniform_(m.weight)\n                nn.init.constant_(m.bias, 0)\n    \n    def forward(self, x):\n        features = self.backbone(x)\n        return self.classifier(features)\n\n# ==========================\n# 5. Training Functions\n# ==========================\ndef calculate_class_weights(dataset):\n    \"\"\"Calculate class weights for loss function\"\"\"\n    class_counts = Counter()\n    for i in range(len(dataset)):\n        _, label = dataset[i]\n        class_counts[label] += 1\n    \n    total = sum(class_counts.values())\n    weights = []\n    \n    for i in range(len(class_counts)):\n        weight = total / (len(class_counts) * class_counts[i])\n        weights.append(weight)\n    \n    return torch.FloatTensor(weights)\n\ndef train_epoch(model, dataloader, criterion, optimizer, device):\n    \"\"\"Train one epoch\"\"\"\n    model.train()\n    total_loss = 0.0\n    correct_predictions = 0\n    total_samples = 0\n    \n    for batch_idx, (inputs, targets) in enumerate(dataloader):\n        inputs, targets = inputs.to(device), targets.to(device)\n        \n        # Forward pass\n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = criterion(outputs, targets)\n        \n        # Backward pass\n        loss.backward()\n        \n        # Gradient clipping for stability\n        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n        \n        optimizer.step()\n        \n        # Statistics\n        total_loss += loss.item()\n        _, predicted = torch.max(outputs.data, 1)\n        total_samples += targets.size(0)\n        correct_predictions += (predicted == targets).sum().item()\n        \n        # Progress update\n        if batch_idx % 50 == 0:\n            print(f'Batch {batch_idx}/{len(dataloader)}, Loss: {loss.item():.4f}')\n    \n    avg_loss = total_loss / len(dataloader)\n    accuracy = correct_predictions / total_samples\n    \n    return avg_loss, accuracy\n\ndef validate_epoch(model, dataloader, criterion, device):\n    \"\"\"Validate one epoch\"\"\"\n    model.eval()\n    total_loss = 0.0\n    correct_predictions = 0\n    total_samples = 0\n    all_predictions = []\n    all_targets = []\n    \n    with torch.no_grad():\n        for inputs, targets in dataloader:\n            inputs, targets = inputs.to(device), targets.to(device)\n            \n            outputs = model(inputs)\n            loss = criterion(outputs, targets)\n            \n            total_loss += loss.item()\n            _, predicted = torch.max(outputs.data, 1)\n            total_samples += targets.size(0)\n            correct_predictions += (predicted == targets).sum().item()\n            \n            all_predictions.extend(predicted.cpu().numpy())\n            all_targets.extend(targets.cpu().numpy())\n    \n    avg_loss = total_loss / len(dataloader)\n    accuracy = correct_predictions / total_samples\n    balanced_acc = balanced_accuracy_score(all_targets, all_predictions)\n    \n    return avg_loss, accuracy, balanced_acc, all_predictions, all_targets\n\ndef train_model():\n    \"\"\"Main training function\"\"\"\n    \n    print(\"\\n\" + \"=\"*60)\n    print(\"STARTING TRAINING PROCESS\")\n    print(\"=\"*60)\n    \n    # 1. Load and analyze dataset\n    print(\"\\n1. Loading and analyzing dataset...\")\n    temp_dataset = datasets.ImageFolder(root=config.train_dir, transform=transform_val)\n    class_counts, total_samples = analyze_class_distribution(config.train_dir)\n    class_names = temp_dataset.classes\n    num_classes = len(class_names)\n    \n    print(f\"Classes: {class_names}\")\n    print(f\"Number of classes: {num_classes}\")\n    \n    # 2. Create dataset and split\n    print(\"\\n2. Creating dataset and splitting...\")\n    full_dataset = datasets.ImageFolder(root=config.train_dir, transform=transform_train)\n    \n    # Create 80:20 split\n    train_size = int(0.8 * len(full_dataset))\n    val_size = len(full_dataset) - train_size\n    train_dataset, val_temp = random_split(full_dataset, [train_size, val_size])\n    \n    # Create validation dataset with different transforms\n    val_full_dataset = datasets.ImageFolder(root=config.train_dir, transform=transform_val)\n    val_indices = val_temp.indices\n    \n    # Manual validation subset with correct transforms\n    class ValDataset:\n        def __init__(self, base_dataset, indices):\n            self.base_dataset = base_dataset\n            self.indices = indices\n        \n        def __len__(self):\n            return len(self.indices)\n        \n        def __getitem__(self, idx):\n            return self.base_dataset[self.indices[idx]]\n    \n    val_dataset = ValDataset(val_full_dataset, val_indices)\n    \n    print(f\"Training samples: {len(train_dataset):,}\")\n    print(f\"Validation samples: {len(val_dataset):,}\")\n    \n    # 3. Create weighted sampler for training\n    print(\"\\n3. Creating weighted sampler for class balance...\")\n    train_sampler = create_weighted_sampler(train_dataset)\n    \n    # 4. Create data loaders\n    print(\"\\n4. Creating data loaders...\")\n    train_loader = DataLoader(\n        train_dataset, \n        batch_size=config.batch_size,\n        sampler=train_sampler,\n        num_workers=2,\n        pin_memory=True\n    )\n    \n    val_loader = DataLoader(\n        val_dataset,\n        batch_size=config.batch_size,\n        shuffle=False,\n        num_workers=2,\n        pin_memory=True\n    )\n    \n    print(f\"Training batches: {len(train_loader)}\")\n    print(f\"Validation batches: {len(val_loader)}\")\n    \n    # 5. Initialize model\n    print(f\"\\n5. Initializing ResNet50 model...\")\n    model = ChestXrayClassifier(num_classes=num_classes, pretrained=True)\n    model = model.to(config.device)\n    \n    # Model summary\n    total_params = sum(p.numel() for p in model.parameters())\n    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n    print(f\"Total parameters: {total_params:,}\")\n    print(f\"Trainable parameters: {trainable_params:,}\")\n    \n    # 6. Loss function with class weights\n    print(\"\\n6. Setting up loss function and optimizer...\")\n    class_weights = calculate_class_weights(train_dataset)\n    class_weights = class_weights.to(config.device)\n    print(f\"Class weights: {class_weights}\")\n    \n    criterion = nn.CrossEntropyLoss(weight=class_weights)\n    \n    # 7. Optimizer and scheduler\n    optimizer = optim.AdamW(\n        model.parameters(),\n        lr=config.learning_rate,\n        weight_decay=config.weight_decay\n    )\n    \n    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n        optimizer,\n        mode='max',\n        factor=0.5,\n        patience=4,\n        verbose=True,\n        min_lr=1e-7\n    )\n    \n    # 8. Training loop\n    print(f\"\\n7. Starting training for {config.num_epochs} epochs...\")\n    print(\"=\"*60)\n    \n    best_balanced_acc = 0.0\n    patience_counter = 0\n    \n    for epoch in range(config.num_epochs):\n        print(f\"\\nEpoch {epoch+1}/{config.num_epochs}\")\n        print(\"-\" * 50)\n        \n        # Training\n        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, config.device)\n        \n        # Validation\n        val_loss, val_acc, val_balanced_acc, val_preds, val_targets = validate_epoch(\n            model, val_loader, criterion, config.device\n        )\n        \n        # Update scheduler\n        scheduler.step(val_balanced_acc)\n        current_lr = optimizer.param_groups[0]['lr']\n        \n        # Print epoch results\n        print(f\"\\nEpoch {epoch+1} Results:\")\n        print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}\")\n        print(f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f} | Val Balanced Acc: {val_balanced_acc:.4f}\")\n        print(f\"Learning Rate: {current_lr:.2e}\")\n        \n        # Save best model\n        if val_balanced_acc > best_balanced_acc:\n            best_balanced_acc = val_balanced_acc\n            torch.save({\n                'epoch': epoch,\n                'model_state_dict': model.state_dict(),\n                'optimizer_state_dict': optimizer.state_dict(),\n                'best_balanced_acc': best_balanced_acc,\n                'class_names': class_names\n            }, 'best_chest_xray_model.pth')\n            print(f\"✅ New best model saved! Balanced Accuracy: {best_balanced_acc:.4f}\")\n            patience_counter = 0\n        else:\n            patience_counter += 1\n        \n        # Early stopping\n        if patience_counter >= config.patience:\n            print(f\"\\nEarly stopping triggered after {config.patience} epochs without improvement\")\n            break\n    \n    print(f\"\\n\" + \"=\"*60)\n    print(\"TRAINING COMPLETED!\")\n    print(f\"Best Balanced Accuracy: {best_balanced_acc:.4f}\")\n    print(\"=\"*60)\n    \n    # Final validation report\n    model.load_state_dict(torch.load('best_chest_xray_model.pth')['model_state_dict'])\n    _, _, _, final_preds, final_targets = validate_epoch(model, val_loader, criterion, config.device)\n    \n    print(\"\\n\" + \"=\"*40)\n    print(\"FINAL VALIDATION REPORT\")\n    print(\"=\"*40)\n    print(classification_report(final_targets, final_preds, target_names=class_names, digits=4))\n    \n    # Confusion Matrix\n    cm = confusion_matrix(final_targets, final_preds)\n    plt.figure(figsize=(8, 6))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n                xticklabels=class_names, yticklabels=class_names)\n    plt.title('Confusion Matrix - Final Validation')\n    plt.xlabel('Predicted')\n    plt.ylabel('Actual')\n    plt.tight_layout()\n    plt.savefig('confusion_matrix.png', dpi=300, bbox_inches='tight')\n    plt.show()\n    \n    return model, class_names, best_balanced_acc\n\n# ==========================\n# 6. Test Time Augmentation\n# ==========================\ndef predict_with_tta(model, image_path):\n    \"\"\"Predict with Test Time Augmentation\"\"\"\n    model.eval()\n    \n    # TTA transforms\n    tta_transforms = [\n        transform_test,  # Original\n        transforms.Compose([\n            transforms.Resize((config.img_size, config.img_size)),\n            transforms.RandomHorizontalFlip(p=1.0),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n        ]),\n        transforms.Compose([\n            transforms.Resize((config.img_size, config.img_size)),\n            transforms.RandomRotation(degrees=5),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n        ])\n    ]\n    \n    predictions = []\n    \n    with torch.no_grad():\n        for transform in tta_transforms:\n            try:\n                image = Image.open(image_path).convert('RGB')\n                image_tensor = transform(image).unsqueeze(0).to(config.device)\n                \n                outputs = model(image_tensor)\n                probabilities = torch.softmax(outputs, dim=1)\n                predictions.append(probabilities.cpu().numpy())\n            except Exception as e:\n                print(f\"TTA error for {image_path}: {e}\")\n                continue\n    \n    if predictions:\n        # Average all predictions\n        avg_prediction = np.mean(predictions, axis=0)\n        return avg_prediction\n    else:\n        # Fallback: single prediction\n        image = Image.open(image_path).convert('RGB')\n        image_tensor = transform_test(image).unsqueeze(0).to(config.device)\n        outputs = model(image_tensor)\n        probabilities = torch.softmax(outputs, dim=1)\n        return probabilities.cpu().numpy()\n\n# ==========================\n# 7. Generate Submission\n# ==========================\ndef generate_submission():\n    \"\"\"Generate final submission\"\"\"\n    print(\"\\n\" + \"=\"*60)\n    print(\"GENERATING SUBMISSION\")\n    print(\"=\"*60)\n    \n    # Load best model\n    checkpoint = torch.load('best_chest_xray_model.pth', map_location=config.device)\n    class_names = checkpoint['class_names']\n    \n    model = ChestXrayClassifier(num_classes=len(class_names), pretrained=False)\n    model.load_state_dict(checkpoint['model_state_dict'])\n    model = model.to(config.device)\n    model.eval()\n    \n    print(f\"Loaded model with best balanced accuracy: {checkpoint['best_balanced_acc']:.4f}\")\n    print(f\"Classes: {class_names}\")\n    \n    # Process test images\n    test_images = sorted([f for f in os.listdir(config.test_dir) \n                         if f.lower().endswith(('.png', '.jpg', '.jpeg'))])\n    \n    print(f\"Found {len(test_images)} test images\")\n    \n    image_ids = []\n    predictions = []\n    confidences = []\n    \n    for i, img_name in enumerate(test_images):\n        if i % 100 == 0:\n            print(f\"Processing {i+1}/{len(test_images)} images...\")\n        \n        img_path = os.path.join(config.test_dir, img_name)\n        \n        try:\n            # Predict with TTA\n            prob_vector = predict_with_tta(model, img_path)\n            \n            # Get prediction and confidence\n            pred_class = np.argmax(prob_vector)\n            confidence = np.max(prob_vector)\n            \n            image_ids.append(img_name)\n            predictions.append(class_names[pred_class])\n            confidences.append(confidence)\n            \n        except Exception as e:\n            print(f\"Error processing {img_name}: {e}\")\n            # Use most common class as fallback\n            image_ids.append(img_name)\n            predictions.append(\"Normal\")\n            confidences.append(0.33)\n    \n    # Create submission\n    submission_df = pd.DataFrame({\n        'image_id': image_ids,\n        'label': predictions\n    })\n    \n    # Analysis dataframe\n    analysis_df = pd.DataFrame({\n        'image_id': image_ids,\n        'label': predictions,\n        'confidence': confidences\n    })\n    \n    # Save files\n    submission_df.to_csv('submission.csv', index=False)\n    analysis_df.to_csv('submission_analysis.csv', index=False)\n    \n    print(f\"\\n✅ Submission completed!\")\n    print(f\"Total predictions: {len(submission_df)}\")\n    \n    print(\"\\nPrediction distribution:\")\n    label_counts = submission_df['label'].value_counts()\n    for label, count in label_counts.items():\n        percentage = (count / len(submission_df)) * 100\n        print(f\"{label}: {count} ({percentage:.1f}%)\")\n    \n    print(f\"\\nMean confidence: {np.mean(confidences):.4f}\")\n    print(f\"Confidence std: {np.std(confidences):.4f}\")\n    \n    return submission_df\n\n# ==========================\n# 8. Main Execution\n# ==========================\nif __name__ == \"__main__\":\n    print(\"🔬 Chest X-Ray Classification - Stable Solution\")\n    print(\"=\" * 60)\n    \n    try:\n        # Train model\n        model, class_names, best_score = train_model()\n        \n        # Generate submission\n        submission = generate_submission()\n        \n        print(\"\\n🎉 Process completed successfully!\")\n        print(f\"📈 Best validation score: {best_score:.4f}\")\n        print(\"📁 Files generated:\")\n        print(\"   - best_chest_xray_model.pth\")\n        print(\"   - submission.csv\") \n        print(\"   - submission_analysis.csv\")\n        print(\"   - confusion_matrix.png\")\n        \n    except Exception as e:\n        print(f\"\\n❌ Error occurred: {e}\")\n        import traceback\n        traceback.print_exc()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T04:53:16.573390Z","iopub.execute_input":"2025-09-29T04:53:16.573783Z","iopub.status.idle":"2025-09-29T05:33:28.442200Z","shell.execute_reply.started":"2025-09-29T04:53:16.573743Z","shell.execute_reply":"2025-09-29T05:33:28.441283Z"},"jupyter":{"outputs_hidden":true,"source_hidden":true},"collapsed":true},"outputs":[{"name":"stdout","text":"Device: cuda\nImage size: 224\n🔬 Chest X-Ray Classification - Stable Solution\n============================================================\n\n============================================================\nSTARTING TRAINING PROCESS\n============================================================\n\n1. Loading and analyzing dataset...\n\n========================================\nCLASS DISTRIBUTION ANALYSIS\n========================================\nCOVID: 1,596 samples (18.6%)\nNormal: 6,310 samples (73.6%)\nViral Pneumonia: 666 samples (7.8%)\nTotal: 8,572 samples\n========================================\nClasses: ['COVID', 'Normal', 'Viral Pneumonia']\nNumber of classes: 3\n\n2. Creating dataset and splitting...\nTraining samples: 6,857\nValidation samples: 1,715\n\n3. Creating weighted sampler for class balance...\n\nClass weights for sampling:\nClass 1: 0.453\nClass 0: 1.780\nClass 2: 4.321\n\n4. Creating data loaders...\nTraining batches: 215\nValidation batches: 54\n\n5. Initializing ResNet50 model...\n","output_type":"stream"},{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n100%|██████████| 97.8M/97.8M [00:00<00:00, 174MB/s] \n","output_type":"stream"},{"name":"stdout","text":"Total parameters: 24,690,755\nTrainable parameters: 24,690,755\n\n6. Setting up loss function and optimizer...\nClass weights: tensor([1.7801, 0.4531, 4.3207], device='cuda:0')\n\n7. Starting training for 25 epochs...\n============================================================\n\nEpoch 1/25\n--------------------------------------------------\nBatch 0/215, Loss: 1.4306\nBatch 50/215, Loss: 0.1634\nBatch 100/215, Loss: 0.0460\nBatch 150/215, Loss: 0.2675\nBatch 200/215, Loss: 0.0206\n\nEpoch 1 Results:\nTrain Loss: 0.1971 | Train Acc: 0.8600\nVal Loss: 0.1445 | Val Acc: 0.9248 | Val Balanced Acc: 0.9471\nLearning Rate: 1.00e-04\n✅ New best model saved! Balanced Accuracy: 0.9471\n\nEpoch 2/25\n--------------------------------------------------\nBatch 0/215, Loss: 0.0240\nBatch 50/215, Loss: 0.0903\nBatch 100/215, Loss: 0.0677\nBatch 150/215, Loss: 0.0123\nBatch 200/215, Loss: 0.0598\n\nEpoch 2 Results:\nTrain Loss: 0.0809 | Train Acc: 0.9453\nVal Loss: 0.1058 | Val Acc: 0.9504 | Val Balanced Acc: 0.9633\nLearning Rate: 1.00e-04\n✅ New best model saved! Balanced Accuracy: 0.9633\n\nEpoch 3/25\n--------------------------------------------------\nBatch 0/215, Loss: 0.0293\nBatch 50/215, Loss: 0.0284\nBatch 100/215, Loss: 0.0744\nBatch 150/215, Loss: 0.0174\nBatch 200/215, Loss: 0.0311\n\nEpoch 3 Results:\nTrain Loss: 0.0586 | Train Acc: 0.9631\nVal Loss: 0.1228 | Val Acc: 0.9615 | Val Balanced Acc: 0.9607\nLearning Rate: 1.00e-04\n\nEpoch 4/25\n--------------------------------------------------\nBatch 0/215, Loss: 0.0037\nBatch 50/215, Loss: 0.0017\nBatch 100/215, Loss: 0.0492\nBatch 150/215, Loss: 0.0223\nBatch 200/215, Loss: 0.0081\n\nEpoch 4 Results:\nTrain Loss: 0.0470 | Train Acc: 0.9673\nVal Loss: 0.0664 | Val Acc: 0.9720 | Val Balanced Acc: 0.9760\nLearning Rate: 1.00e-04\n✅ New best model saved! Balanced Accuracy: 0.9760\n\nEpoch 5/25\n--------------------------------------------------\nBatch 0/215, Loss: 0.0074\nBatch 50/215, Loss: 0.0111\nBatch 100/215, Loss: 0.0388\nBatch 150/215, Loss: 0.0085\nBatch 200/215, Loss: 0.0343\n\nEpoch 5 Results:\nTrain Loss: 0.0339 | Train Acc: 0.9784\nVal Loss: 0.1050 | Val Acc: 0.9633 | Val Balanced Acc: 0.9742\nLearning Rate: 1.00e-04\n\nEpoch 6/25\n--------------------------------------------------\nBatch 0/215, Loss: 0.0317\nBatch 50/215, Loss: 0.0214\nBatch 100/215, Loss: 0.0227\nBatch 150/215, Loss: 0.0022\nBatch 200/215, Loss: 0.0069\n\nEpoch 6 Results:\nTrain Loss: 0.0352 | Train Acc: 0.9780\nVal Loss: 0.0997 | Val Acc: 0.9813 | Val Balanced Acc: 0.9767\nLearning Rate: 1.00e-04\n✅ New best model saved! Balanced Accuracy: 0.9767\n\nEpoch 7/25\n--------------------------------------------------\nBatch 0/215, Loss: 0.0086\nBatch 50/215, Loss: 0.0128\nBatch 100/215, Loss: 0.0060\nBatch 150/215, Loss: 0.0101\nBatch 200/215, Loss: 0.0225\n\nEpoch 7 Results:\nTrain Loss: 0.0282 | Train Acc: 0.9789\nVal Loss: 0.0912 | Val Acc: 0.9563 | Val Balanced Acc: 0.9749\nLearning Rate: 1.00e-04\n\nEpoch 8/25\n--------------------------------------------------\nBatch 0/215, Loss: 0.0009\nBatch 50/215, Loss: 0.0025\nBatch 100/215, Loss: 0.0044\nBatch 150/215, Loss: 0.0008\nBatch 200/215, Loss: 0.0042\n\nEpoch 8 Results:\nTrain Loss: 0.0293 | Train Acc: 0.9816\nVal Loss: 0.0933 | Val Acc: 0.9837 | Val Balanced Acc: 0.9712\nLearning Rate: 1.00e-04\n\nEpoch 9/25\n--------------------------------------------------\nBatch 0/215, Loss: 0.0465\nBatch 50/215, Loss: 0.0017\nBatch 100/215, Loss: 0.1039\nBatch 150/215, Loss: 0.0046\nBatch 200/215, Loss: 0.0476\n\nEpoch 9 Results:\nTrain Loss: 0.0191 | Train Acc: 0.9856\nVal Loss: 0.0816 | Val Acc: 0.9860 | Val Balanced Acc: 0.9766\nLearning Rate: 1.00e-04\n\nEpoch 10/25\n--------------------------------------------------\nBatch 0/215, Loss: 0.0111\nBatch 50/215, Loss: 0.0230\nBatch 100/215, Loss: 0.0030\nBatch 150/215, Loss: 0.0007\nBatch 200/215, Loss: 0.0009\n\nEpoch 10 Results:\nTrain Loss: 0.0168 | Train Acc: 0.9856\nVal Loss: 0.0660 | Val Acc: 0.9913 | Val Balanced Acc: 0.9796\nLearning Rate: 1.00e-04\n✅ New best model saved! Balanced Accuracy: 0.9796\n\nEpoch 11/25\n--------------------------------------------------\nBatch 0/215, Loss: 0.0034\nBatch 50/215, Loss: 0.0520\nBatch 100/215, Loss: 0.0103\nBatch 150/215, Loss: 0.0534\nBatch 200/215, Loss: 0.0013\n\nEpoch 11 Results:\nTrain Loss: 0.0202 | Train Acc: 0.9867\nVal Loss: 0.0574 | Val Acc: 0.9773 | Val Balanced Acc: 0.9816\nLearning Rate: 1.00e-04\n✅ New best model saved! Balanced Accuracy: 0.9816\n\nEpoch 12/25\n--------------------------------------------------\nBatch 0/215, Loss: 0.0011\nBatch 50/215, Loss: 0.0005\nBatch 100/215, Loss: 0.0642\nBatch 150/215, Loss: 0.0004\nBatch 200/215, Loss: 0.0086\n\nEpoch 12 Results:\nTrain Loss: 0.0198 | Train Acc: 0.9879\nVal Loss: 0.0855 | Val Acc: 0.9813 | Val Balanced Acc: 0.9756\nLearning Rate: 1.00e-04\n\nEpoch 13/25\n--------------------------------------------------\nBatch 0/215, Loss: 0.0007\nBatch 50/215, Loss: 0.0061\nBatch 100/215, Loss: 0.0011\nBatch 150/215, Loss: 0.0010\nBatch 200/215, Loss: 0.1408\n\nEpoch 13 Results:\nTrain Loss: 0.0180 | Train Acc: 0.9883\nVal Loss: 0.1144 | Val Acc: 0.9510 | Val Balanced Acc: 0.9649\nLearning Rate: 1.00e-04\n\nEpoch 14/25\n--------------------------------------------------\nBatch 0/215, Loss: 0.0034\nBatch 50/215, Loss: 0.0227\nBatch 100/215, Loss: 0.0022\nBatch 150/215, Loss: 0.0104\nBatch 200/215, Loss: 0.0408\n\nEpoch 14 Results:\nTrain Loss: 0.0141 | Train Acc: 0.9899\nVal Loss: 0.1333 | Val Acc: 0.9609 | Val Balanced Acc: 0.9700\nLearning Rate: 1.00e-04\n\nEpoch 15/25\n--------------------------------------------------\nBatch 0/215, Loss: 0.0685\nBatch 50/215, Loss: 0.0006\nBatch 100/215, Loss: 0.0004\nBatch 150/215, Loss: 0.0015\nBatch 200/215, Loss: 0.0004\n\nEpoch 15 Results:\nTrain Loss: 0.0119 | Train Acc: 0.9915\nVal Loss: 0.0484 | Val Acc: 0.9848 | Val Balanced Acc: 0.9802\nLearning Rate: 1.00e-04\n\nEpoch 16/25\n--------------------------------------------------\nBatch 0/215, Loss: 0.0082\nBatch 50/215, Loss: 0.0137\nBatch 100/215, Loss: 0.0037\nBatch 150/215, Loss: 0.0009\nBatch 200/215, Loss: 0.0002\n\nEpoch 16 Results:\nTrain Loss: 0.0110 | Train Acc: 0.9912\nVal Loss: 0.0467 | Val Acc: 0.9883 | Val Balanced Acc: 0.9842\nLearning Rate: 1.00e-04\n✅ New best model saved! Balanced Accuracy: 0.9842\n\nEpoch 17/25\n--------------------------------------------------\nBatch 0/215, Loss: 0.0049\nBatch 50/215, Loss: 0.0019\nBatch 100/215, Loss: 0.0333\nBatch 150/215, Loss: 0.0167\nBatch 200/215, Loss: 0.0259\n\nEpoch 17 Results:\nTrain Loss: 0.0073 | Train Acc: 0.9943\nVal Loss: 0.0461 | Val Acc: 0.9848 | Val Balanced Acc: 0.9845\nLearning Rate: 1.00e-04\n✅ New best model saved! Balanced Accuracy: 0.9845\n\nEpoch 18/25\n--------------------------------------------------\nBatch 0/215, Loss: 0.0081\nBatch 50/215, Loss: 0.0011\nBatch 100/215, Loss: 0.0020\nBatch 150/215, Loss: 0.0364\nBatch 200/215, Loss: 0.0016\n\nEpoch 18 Results:\nTrain Loss: 0.0118 | Train Acc: 0.9912\nVal Loss: 0.0603 | Val Acc: 0.9866 | Val Balanced Acc: 0.9799\nLearning Rate: 1.00e-04\n\nEpoch 19/25\n--------------------------------------------------\nBatch 0/215, Loss: 0.0012\nBatch 50/215, Loss: 0.0346\nBatch 100/215, Loss: 0.0344\nBatch 150/215, Loss: 0.0001\nBatch 200/215, Loss: 0.0003\n\nEpoch 19 Results:\nTrain Loss: 0.0097 | Train Acc: 0.9931\nVal Loss: 0.1211 | Val Acc: 0.9895 | Val Balanced Acc: 0.9733\nLearning Rate: 1.00e-04\n\nEpoch 20/25\n--------------------------------------------------\nBatch 0/215, Loss: 0.0105\nBatch 50/215, Loss: 0.0050\nBatch 100/215, Loss: 0.0004\nBatch 150/215, Loss: 0.0001\nBatch 200/215, Loss: 0.0007\n\nEpoch 20 Results:\nTrain Loss: 0.0139 | Train Acc: 0.9899\nVal Loss: 0.1060 | Val Acc: 0.9889 | Val Balanced Acc: 0.9728\nLearning Rate: 1.00e-04\n\nEpoch 21/25\n--------------------------------------------------\nBatch 0/215, Loss: 0.0031\nBatch 50/215, Loss: 0.0010\nBatch 100/215, Loss: 0.0014\nBatch 150/215, Loss: 0.0226\nBatch 200/215, Loss: 0.0019\n\nEpoch 21 Results:\nTrain Loss: 0.0123 | Train Acc: 0.9910\nVal Loss: 0.0326 | Val Acc: 0.9913 | Val Balanced Acc: 0.9912\nLearning Rate: 1.00e-04\n✅ New best model saved! Balanced Accuracy: 0.9912\n\nEpoch 22/25\n--------------------------------------------------\nBatch 0/215, Loss: 0.0034\nBatch 50/215, Loss: 0.0057\nBatch 100/215, Loss: 0.0020\nBatch 150/215, Loss: 0.0002\nBatch 200/215, Loss: 0.0001\n\nEpoch 22 Results:\nTrain Loss: 0.0076 | Train Acc: 0.9940\nVal Loss: 0.0557 | Val Acc: 0.9901 | Val Balanced Acc: 0.9815\nLearning Rate: 1.00e-04\n\nEpoch 23/25\n--------------------------------------------------\nBatch 0/215, Loss: 0.0006\nBatch 50/215, Loss: 0.0124\nBatch 100/215, Loss: 0.0015\nBatch 150/215, Loss: 0.0124\nBatch 200/215, Loss: 0.0053\n\nEpoch 23 Results:\nTrain Loss: 0.0124 | Train Acc: 0.9931\nVal Loss: 0.0754 | Val Acc: 0.9878 | Val Balanced Acc: 0.9772\nLearning Rate: 1.00e-04\n\nEpoch 24/25\n--------------------------------------------------\nBatch 0/215, Loss: 0.0002\nBatch 50/215, Loss: 0.0036\nBatch 100/215, Loss: 0.0010\nBatch 150/215, Loss: 0.0005\nBatch 200/215, Loss: 0.0112\n\nEpoch 24 Results:\nTrain Loss: 0.0072 | Train Acc: 0.9952\nVal Loss: 0.0749 | Val Acc: 0.9889 | Val Balanced Acc: 0.9761\nLearning Rate: 1.00e-04\n\nEpoch 25/25\n--------------------------------------------------\nBatch 0/215, Loss: 0.0024\nBatch 50/215, Loss: 0.0012\nBatch 100/215, Loss: 0.0050\nBatch 150/215, Loss: 0.0387\nBatch 200/215, Loss: 0.0034\n\nEpoch 25 Results:\nTrain Loss: 0.0073 | Train Acc: 0.9943\nVal Loss: 0.1332 | Val Acc: 0.9819 | Val Balanced Acc: 0.9641\nLearning Rate: 1.00e-04\n\n============================================================\nTRAINING COMPLETED!\nBest Balanced Accuracy: 0.9912\n============================================================\n\n❌ Error occurred: Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n\tWeightsUnpickler error: Unsupported global: GLOBAL numpy.core.multiarray.scalar was not an allowed global by default. Please use `torch.serialization.add_safe_globals([scalar])` or the `torch.serialization.safe_globals([scalar])` context manager to allowlist this global if you trust this class/function.\n\nCheck the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.\n","output_type":"stream"},{"name":"stderr","text":"Traceback (most recent call last):\n  File \"/tmp/ipykernel_36/3710337192.py\", line 593, in <cell line: 0>\n    model, class_names, best_score = train_model()\n                                     ^^^^^^^^^^^^^\n  File \"/tmp/ipykernel_36/3710337192.py\", line 424, in train_model\n    model.load_state_dict(torch.load('best_chest_xray_model.pth')['model_state_dict'])\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/serialization.py\", line 1470, in load\n    raise pickle.UnpicklingError(_get_wo_message(str(e))) from None\n_pickle.UnpicklingError: Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n\tWeightsUnpickler error: Unsupported global: GLOBAL numpy.core.multiarray.scalar was not an allowed global by default. Please use `torch.serialization.add_safe_globals([scalar])` or the `torch.serialization.safe_globals([scalar])` context manager to allowlist this global if you trust this class/function.\n\nCheck the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"**VISUALISASI RESNET-50**","metadata":{}},{"cell_type":"code","source":"import torch\nimport pandas as pd\nfrom PIL import Image\nimport numpy as np\nimport os\n\n# Load the saved model and generate submission\nprint(\"\\n\" + \"=\"*60)\nprint(\"LOADING SAVED MODEL AND GENERATING SUBMISSION\")\nprint(\"=\"*60)\n\n# Load best model with fixed weights_only parameter\ncheckpoint = torch.load('best_chest_xray_model.pth', weights_only=False)\nclass_names = checkpoint['class_names']\nbest_acc = checkpoint['best_balanced_acc']\n\nprint(f\"Loaded model with best balanced accuracy: {best_acc:.4f}\")\nprint(f\"Classes: {class_names}\")\n\n# Initialize model architecture (same as training)\nmodel = ChestXrayClassifier(num_classes=len(class_names), pretrained=False)\nmodel.load_state_dict(checkpoint['model_state_dict'])\nmodel = model.to(config.device)\nmodel.eval()\n\nprint(\"Model loaded successfully!\")\n\n# Display final validation report\nprint(\"\\n\" + \"=\"*40)\nprint(\"FINAL VALIDATION REPORT\")\nprint(\"=\"*40)\nprint(f\"Best Balanced Accuracy achieved: {best_acc:.4f} (99.12%)\")\nprint(\"This is an excellent result for medical imaging classification!\")\n\n# Test Time Augmentation function (same as before)\ndef predict_with_tta(model, image_path):\n    \"\"\"Predict with Test Time Augmentation\"\"\"\n    model.eval()\n    \n    # TTA transforms\n    tta_transforms = [\n        transform_test,  # Original\n        transforms.Compose([\n            transforms.Resize((config.img_size, config.img_size)),\n            transforms.RandomHorizontalFlip(p=1.0),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n        ]),\n        transforms.Compose([\n            transforms.Resize((config.img_size, config.img_size)),\n            transforms.RandomRotation(degrees=5),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n        ])\n    ]\n    \n    predictions = []\n    \n    with torch.no_grad():\n        for transform in tta_transforms:\n            try:\n                image = Image.open(image_path).convert('RGB')\n                image_tensor = transform(image).unsqueeze(0).to(config.device)\n                \n                outputs = model(image_tensor)\n                probabilities = torch.softmax(outputs, dim=1)\n                predictions.append(probabilities.cpu().numpy())\n            except Exception as e:\n                print(f\"TTA error for {image_path}: {e}\")\n                continue\n    \n    if predictions:\n        # Average all predictions\n        avg_prediction = np.mean(predictions, axis=0)\n        return avg_prediction\n    else:\n        # Fallback: single prediction\n        image = Image.open(image_path).convert('RGB')\n        image_tensor = transform_test(image).unsqueeze(0).to(config.device)\n        outputs = model(image_tensor)\n        probabilities = torch.softmax(outputs, dim=1)\n        return probabilities.cpu().numpy()\n\n# Process test images\ntest_images = sorted([f for f in os.listdir(config.test_dir) \n                     if f.lower().endswith(('.png', '.jpg', '.jpeg'))])\n\nprint(f\"\\nFound {len(test_images)} test images\")\nprint(\"Starting prediction with Test Time Augmentation...\")\n\nimage_ids = []\npredictions = []\nconfidences = []\n\nfor i, img_name in enumerate(test_images):\n    if i % 100 == 0:\n        print(f\"Processing {i+1}/{len(test_images)} images...\")\n    \n    img_path = os.path.join(config.test_dir, img_name)\n    \n    try:\n        # Predict with TTA\n        prob_vector = predict_with_tta(model, img_path)\n        \n        # Get prediction and confidence\n        pred_class = np.argmax(prob_vector)\n        confidence = np.max(prob_vector)\n        \n        image_ids.append(img_name)\n        predictions.append(class_names[pred_class])\n        confidences.append(confidence)\n        \n    except Exception as e:\n        print(f\"Error processing {img_name}: {e}\")\n        # Use most common class as fallback\n        image_ids.append(img_name)\n        predictions.append(\"Normal\")\n        confidences.append(0.33)\n\n# Create submission DataFrame with correct format (no file extension)\nimage_ids_clean = [os.path.splitext(img_id)[0] for img_id in image_ids]  # Remove extension\n\nsubmission_df = pd.DataFrame({\n    'Id': image_ids_clean,\n    'Predicted': [class_names.index(pred) for pred in predictions]  # Convert to numeric labels\n})\n\n# Analysis dataframe with confidence scores (for your reference)\nanalysis_df = pd.DataFrame({\n    'image_id_full': image_ids,  # With extension for reference\n    'image_id_clean': image_ids_clean,  # Without extension\n    'label_name': predictions,\n    'label_numeric': [class_names.index(pred) for pred in predictions],\n    'confidence': confidences\n})\n\n# Save files\nsubmission_df.to_csv('submission.csv', index=False)\nanalysis_df.to_csv('submission_analysis.csv', index=False)\n\nprint(f\"\\n✅ Submission completed!\")\nprint(f\"\\nTotal predictions: {len(submission_df)}\")\n\nprint(\"\\nSubmission format validation:\")\nprint(\"=\" * 30)\nprint(f\"Header: {list(submission_df.columns)}\")\nprint(f\"Sample rows:\")\nprint(submission_df.head(10))\n\nprint(\"\\nPrediction distribution:\")\nlabel_counts = submission_df['Predicted'].value_counts().sort_index()\nfor label_idx, count in label_counts.items():\n    label_name = class_names[label_idx]\n    percentage = (count / len(submission_df)) * 100\n    print(f\"Class {label_idx} ({label_name}): {count} ({percentage:.1f}%)\")\n\nprint(\"\\nLabel mapping:\")\nprint(\"=\" * 20)\nfor idx, name in enumerate(class_names):\n    print(f\"{idx}: {name}\")\n\nprint(f\"\\nConfidence Statistics:\")\nprint(f\"Mean confidence: {np.mean(confidences):.4f}\")\nprint(f\"Std confidence: {np.std(confidences):.4f}\")\nprint(f\"Min confidence: {np.min(confidences):.4f}\")\nprint(f\"Max confidence: {np.max(confidences):.4f}\")\n\n# Generate and display confusion matrix\nprint(\"\\n\" + \"=\"*40)\nprint(\"GENERATING CONFUSION MATRIX\")\nprint(\"=\"*40)\n\n# Load validation dataset to generate confusion matrix\nprint(\"Loading validation data for confusion matrix...\")\n\n# Recreate validation dataset (same as training)\nfull_dataset = datasets.ImageFolder(root=config.train_dir, transform=transform_train)\ntrain_size = int(0.8 * len(full_dataset))\nval_size = len(full_dataset) - train_size\ntrain_dataset, val_temp = torch.utils.data.random_split(full_dataset, [train_size, val_size])\n\n# Create validation dataset with correct transforms\nval_full_dataset = datasets.ImageFolder(root=config.train_dir, transform=transform_val)\nval_indices = val_temp.indices\n\nclass ValDataset:\n    def __init__(self, base_dataset, indices):\n        self.base_dataset = base_dataset\n        self.indices = indices\n    \n    def __len__(self):\n        return len(self.indices)\n    \n    def __getitem__(self, idx):\n        return self.base_dataset[self.indices[idx]]\n\nval_dataset = ValDataset(val_full_dataset, val_indices)\n\nval_loader = torch.utils.data.DataLoader(\n    val_dataset,\n    batch_size=32,\n    shuffle=False,\n    num_workers=2,\n    pin_memory=True\n)\n\n# Generate predictions on validation set\nmodel.eval()\nval_predictions = []\nval_true_labels = []\n\nprint(\"Generating validation predictions...\")\nwith torch.no_grad():\n    for batch_idx, (inputs, targets) in enumerate(val_loader):\n        if batch_idx % 10 == 0:\n            print(f\"Processing validation batch {batch_idx+1}/{len(val_loader)}\")\n        \n        inputs, targets = inputs.to(config.device), targets.to(config.device)\n        outputs = model(inputs)\n        _, predicted = torch.max(outputs.data, 1)\n        \n        val_predictions.extend(predicted.cpu().numpy())\n        val_true_labels.extend(targets.cpu().numpy())\n\n# Generate confusion matrix\nfrom sklearn.metrics import confusion_matrix, classification_report\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ncm = confusion_matrix(val_true_labels, val_predictions)\n\n# Create confusion matrix plot\nplt.figure(figsize=(10, 8))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n            xticklabels=class_names, yticklabels=class_names,\n            cbar_kws={'label': 'Number of Samples'})\nplt.title(f'Confusion Matrix - Validation Set\\nBest Balanced Accuracy: {best_acc:.4f}', fontsize=14, pad=20)\nplt.xlabel('Predicted Label', fontsize=12)\nplt.ylabel('True Label', fontsize=12)\nplt.xticks(rotation=45, ha='right')\nplt.yticks(rotation=0)\nplt.tight_layout()\n\n# Save confusion matrix\nplt.savefig('confusion_matrix.png', dpi=300, bbox_inches='tight')\nplt.show()\n\n# Display detailed classification report\nprint(\"\\nDetailed Classification Report:\")\nprint(\"=\"*50)\nprint(classification_report(val_true_labels, val_predictions, \n                          target_names=class_names, digits=4))\n\n# Display confusion matrix numbers\nprint(\"\\nConfusion Matrix Details:\")\nprint(\"=\"*30)\nfor i, true_class in enumerate(class_names):\n    for j, pred_class in enumerate(class_names):\n        if cm[i,j] > 0:\n            print(f\"True: {true_class:15} | Pred: {pred_class:15} | Count: {cm[i,j]:4d}\")\n\n# Calculate per-class accuracy\nprint(\"\\nPer-Class Performance:\")\nprint(\"=\"*30)\nfor i, class_name in enumerate(class_names):\n    class_correct = cm[i,i]\n    class_total = cm[i,:].sum()\n    class_accuracy = class_correct / class_total if class_total > 0 else 0\n    print(f\"{class_name:15}: {class_correct:3d}/{class_total:3d} = {class_accuracy:.4f} ({class_accuracy*100:.2f}%)\")\n\nprint(\"\\nProcess completed successfully!\")\nprint(f\"Best validation score: {best_acc:.4f}\")\nprint(\"Files generated:\")\nprint(\"   - best_chest_xray_model.pth (already saved)\")\nprint(\"   - submission(29-09-2025).csv\") \nprint(\"   - submission_analysis.csv\")\nprint(\"   - confusion_matrix.png\")\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"READY FOR KAGGLE SUBMISSION!\")\nprint(\"=\"*60)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T05:45:46.327036Z","iopub.execute_input":"2025-09-29T05:45:46.327672Z","iopub.status.idle":"2025-09-29T05:50:49.135606Z","shell.execute_reply.started":"2025-09-29T05:45:46.327616Z","shell.execute_reply":"2025-09-29T05:50:49.134931Z"},"jupyter":{"outputs_hidden":true,"source_hidden":true},"collapsed":true},"outputs":[{"name":"stdout","text":"\n============================================================\nLOADING SAVED MODEL AND GENERATING SUBMISSION\n============================================================\nLoaded model with best balanced accuracy: 0.9912\nClasses: ['COVID', 'Normal', 'Viral Pneumonia']\nModel loaded successfully!\n\n========================================\nFINAL VALIDATION REPORT\n========================================\nBest Balanced Accuracy achieved: 0.9912 (99.12%)\nThis is an excellent result for medical imaging classification!\n\nFound 6382 test images\nStarting prediction with Test Time Augmentation...\nProcessing 1/6382 images...\nProcessing 101/6382 images...\nProcessing 201/6382 images...\nProcessing 301/6382 images...\nProcessing 401/6382 images...\nProcessing 501/6382 images...\nProcessing 601/6382 images...\nProcessing 701/6382 images...\nProcessing 801/6382 images...\nProcessing 901/6382 images...\nProcessing 1001/6382 images...\nProcessing 1101/6382 images...\nProcessing 1201/6382 images...\nProcessing 1301/6382 images...\nProcessing 1401/6382 images...\nProcessing 1501/6382 images...\nProcessing 1601/6382 images...\nProcessing 1701/6382 images...\nProcessing 1801/6382 images...\nProcessing 1901/6382 images...\nProcessing 2001/6382 images...\nProcessing 2101/6382 images...\nProcessing 2201/6382 images...\nProcessing 2301/6382 images...\nProcessing 2401/6382 images...\nProcessing 2501/6382 images...\nProcessing 2601/6382 images...\nProcessing 2701/6382 images...\nProcessing 2801/6382 images...\nProcessing 2901/6382 images...\nProcessing 3001/6382 images...\nProcessing 3101/6382 images...\nProcessing 3201/6382 images...\nProcessing 3301/6382 images...\nProcessing 3401/6382 images...\nProcessing 3501/6382 images...\nProcessing 3601/6382 images...\nProcessing 3701/6382 images...\nProcessing 3801/6382 images...\nProcessing 3901/6382 images...\nProcessing 4001/6382 images...\nProcessing 4101/6382 images...\nProcessing 4201/6382 images...\nProcessing 4301/6382 images...\nProcessing 4401/6382 images...\nProcessing 4501/6382 images...\nProcessing 4601/6382 images...\nProcessing 4701/6382 images...\nProcessing 4801/6382 images...\nProcessing 4901/6382 images...\nProcessing 5001/6382 images...\nProcessing 5101/6382 images...\nProcessing 5201/6382 images...\nProcessing 5301/6382 images...\nProcessing 5401/6382 images...\nProcessing 5501/6382 images...\nProcessing 5601/6382 images...\nProcessing 5701/6382 images...\nProcessing 5801/6382 images...\nProcessing 5901/6382 images...\nProcessing 6001/6382 images...\nProcessing 6101/6382 images...\nProcessing 6201/6382 images...\nProcessing 6301/6382 images...\n\n✅ Submission completed!\n\nTotal predictions: 6382\n\nSubmission format validation:\n==============================\nHeader: ['Id', 'Predicted']\nSample rows:\n          Id  Predicted\n0  test_0001          1\n1  test_0002          0\n2  test_0003          0\n3  test_0004          1\n4  test_0005          1\n5  test_0006          1\n6  test_0007          1\n7  test_0008          1\n8  test_0009          0\n9  test_0010          1\n\nPrediction distribution:\nClass 0 (COVID): 1932 (30.3%)\nClass 1 (Normal): 3743 (58.6%)\nClass 2 (Viral Pneumonia): 707 (11.1%)\n\nLabel mapping:\n====================\n0: COVID\n1: Normal\n2: Viral Pneumonia\n\nConfidence Statistics:\nMean confidence: 0.9870\nStd confidence: 0.0588\nMin confidence: 0.5019\nMax confidence: 1.0000\n\n========================================\nGENERATING CONFUSION MATRIX\n========================================\nLoading validation data for confusion matrix...\nGenerating validation predictions...\nProcessing validation batch 1/54\nProcessing validation batch 11/54\nProcessing validation batch 21/54\nProcessing validation batch 31/54\nProcessing validation batch 41/54\nProcessing validation batch 51/54\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1000x800 with 2 Axes>","image/png":"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\n"},"metadata":{}},{"name":"stdout","text":"\nDetailed Classification Report:\n==================================================\n                 precision    recall  f1-score   support\n\n          COVID     0.9967    0.9902    0.9934       306\n         Normal     0.9976    0.9912    0.9944      1255\nViral Pneumonia     0.9390    1.0000    0.9686       154\n\n       accuracy                         0.9918      1715\n      macro avg     0.9778    0.9938    0.9855      1715\n   weighted avg     0.9922    0.9918    0.9919      1715\n\n\nConfusion Matrix Details:\n==============================\nTrue: COVID           | Pred: COVID           | Count:  303\nTrue: COVID           | Pred: Normal          | Count:    3\nTrue: Normal          | Pred: COVID           | Count:    1\nTrue: Normal          | Pred: Normal          | Count: 1244\nTrue: Normal          | Pred: Viral Pneumonia | Count:   10\nTrue: Viral Pneumonia | Pred: Viral Pneumonia | Count:  154\n\nPer-Class Performance:\n==============================\nCOVID          : 303/306 = 0.9902 (99.02%)\nNormal         : 1244/1255 = 0.9912 (99.12%)\nViral Pneumonia: 154/154 = 1.0000 (100.00%)\n\nProcess completed successfully!\nBest validation score: 0.9912\nFiles generated:\n   - best_chest_xray_model.pth (already saved)\n   - submission(29-09-2025).csv\n   - submission_analysis.csv\n   - confusion_matrix.png\n\n============================================================\nREADY FOR KAGGLE SUBMISSION!\n============================================================\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"**EFFNET-B3**","metadata":{}},{"cell_type":"code","source":"import os\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, random_split, WeightedRandomSampler\nfrom torchvision import datasets, transforms, models\nfrom sklearn.metrics import classification_report, confusion_matrix, balanced_accuracy_score\nimport pandas as pd\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nfrom collections import Counter\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# ==========================\n# Configuration\n# ==========================\nclass Config:\n    train_dir = \"/kaggle/input/final-srifoton-25-machine-learning-competition/train/train\"\n    test_dir = \"/kaggle/input/final-srifoton-25-machine-learning-competition/test/test\"\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    \n    # Training parameters - OPTIMIZED\n    batch_size = 16  \n    learning_rate = 5e-5  \n    weight_decay = 1e-4\n    num_epochs = 30\n    patience = 10\n    \n    # Image parameters\n    img_size = 384  \n    \n    # TTA control\n    use_tta = False \n    \n    print(f\"Device: {device}\")\n    print(f\"Image size: {img_size}\")\n    print(f\"Use TTA: {use_tta}\")\n\nconfig = Config()\n\n# ==========================\n# Enhanced Data Transforms\n# ==========================\ntransform_train = transforms.Compose([\n    transforms.Resize((config.img_size, config.img_size)),\n    transforms.RandomHorizontalFlip(p=0.3),  # Reduced probability\n    transforms.RandomRotation(degrees=7),\n    transforms.ColorJitter(brightness=0.15, contrast=0.15),\n    transforms.RandomAffine(degrees=0, translate=(0.05, 0.05)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\ntransform_val = transforms.Compose([\n    transforms.Resize((config.img_size, config.img_size)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\ntransform_test = transforms.Compose([\n    transforms.Resize((config.img_size, config.img_size)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\n# ==========================\n# Enhanced Model: EfficientNet-B3\n# ==========================\nclass ChestXrayClassifier(nn.Module):\n    def __init__(self, num_classes=3, pretrained=True):\n        super(ChestXrayClassifier, self).__init__()\n        \n        # Use EfficientNet-B3 for better performance\n        self.backbone = models.efficientnet_b3(pretrained=pretrained)\n        num_features = self.backbone.classifier[1].in_features\n        \n        # Replace classifier\n        self.backbone.classifier = nn.Sequential(\n            nn.Dropout(0.4),\n            nn.Linear(num_features, 768),\n            nn.BatchNorm1d(768),\n            nn.ReLU(inplace=True),\n            nn.Dropout(0.3),\n            nn.Linear(768, 384),\n            nn.BatchNorm1d(384),\n            nn.ReLU(inplace=True),\n            nn.Dropout(0.2),\n            nn.Linear(384, num_classes)\n        )\n        \n        self._init_classifier()\n    \n    def _init_classifier(self):\n        for m in self.backbone.classifier.modules():\n            if isinstance(m, nn.Linear):\n                nn.init.xavier_uniform_(m.weight)\n                if m.bias is not None:\n                    nn.init.constant_(m.bias, 0)\n    \n    def forward(self, x):\n        return self.backbone(x)\n\n# ==========================\n# Helper Functions\n# ==========================\ndef analyze_class_distribution(dataset_path):\n    class_counts = {}\n    total = 0\n    \n    for class_name in os.listdir(dataset_path):\n        class_path = os.path.join(dataset_path, class_name)\n        if os.path.isdir(class_path):\n            count = len([f for f in os.listdir(class_path) \n                        if f.lower().endswith(('.png', '.jpg', '.jpeg'))])\n            class_counts[class_name] = count\n            total += count\n    \n    print(\"\\n\" + \"=\"*40)\n    print(\"CLASS DISTRIBUTION\")\n    print(\"=\"*40)\n    for class_name, count in sorted(class_counts.items()):\n        percentage = (count / total) * 100\n        print(f\"{class_name}: {count:,} ({percentage:.1f}%)\")\n    print(f\"Total: {total:,}\")\n    print(\"=\"*40)\n    \n    return class_counts, total\n\ndef create_weighted_sampler(dataset):\n    class_counts = Counter()\n    for i in range(len(dataset)):\n        _, label = dataset[i]\n        class_counts[label] += 1\n    \n    class_weights = {}\n    total_samples = sum(class_counts.values())\n    \n    for class_idx, count in class_counts.items():\n        class_weights[class_idx] = total_samples / (len(class_counts) * count)\n    \n    sample_weights = []\n    for i in range(len(dataset)):\n        _, label = dataset[i]\n        sample_weights.append(class_weights[label])\n    \n    print(\"\\nClass weights:\")\n    for class_idx, weight in class_weights.items():\n        print(f\"Class {class_idx}: {weight:.3f}\")\n    \n    return WeightedRandomSampler(\n        weights=sample_weights,\n        num_samples=len(sample_weights),\n        replacement=True\n    )\n\ndef calculate_class_weights(dataset):\n    class_counts = Counter()\n    for i in range(len(dataset)):\n        _, label = dataset[i]\n        class_counts[label] += 1\n    \n    total = sum(class_counts.values())\n    weights = []\n    \n    for i in range(len(class_counts)):\n        weight = total / (len(class_counts) * class_counts[i])\n        weights.append(weight)\n    \n    return torch.FloatTensor(weights)\n\n# ==========================\n# Training Functions\n# ==========================\ndef train_epoch(model, dataloader, criterion, optimizer, device):\n    model.train()\n    total_loss = 0.0\n    correct = 0\n    total = 0\n    \n    for batch_idx, (inputs, targets) in enumerate(dataloader):\n        inputs, targets = inputs.to(device), targets.to(device)\n        \n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = criterion(outputs, targets)\n        \n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n        optimizer.step()\n        \n        total_loss += loss.item()\n        _, predicted = torch.max(outputs.data, 1)\n        total += targets.size(0)\n        correct += (predicted == targets).sum().item()\n        \n        if batch_idx % 50 == 0:\n            print(f'Batch {batch_idx}/{len(dataloader)}, Loss: {loss.item():.4f}')\n    \n    return total_loss / len(dataloader), correct / total\n\ndef validate_epoch(model, dataloader, criterion, device):\n    model.eval()\n    total_loss = 0.0\n    correct = 0\n    total = 0\n    all_preds = []\n    all_targets = []\n    \n    with torch.no_grad():\n        for inputs, targets in dataloader:\n            inputs, targets = inputs.to(device), targets.to(device)\n            outputs = model(inputs)\n            loss = criterion(outputs, targets)\n            \n            total_loss += loss.item()\n            _, predicted = torch.max(outputs.data, 1)\n            total += targets.size(0)\n            correct += (predicted == targets).sum().item()\n            \n            all_preds.extend(predicted.cpu().numpy())\n            all_targets.extend(targets.cpu().numpy())\n    \n    balanced_acc = balanced_accuracy_score(all_targets, all_preds)\n    return total_loss / len(dataloader), correct / total, balanced_acc, all_preds, all_targets\n\n# ==========================\n# Main Training\n# ==========================\ndef train_model():\n    print(\"\\n\" + \"=\"*60)\n    print(\"TRAINING WITH EFFICIENTNET-B3\")\n    print(\"=\"*60)\n    \n    # Load dataset\n    temp_dataset = datasets.ImageFolder(root=config.train_dir, transform=transform_val)\n    analyze_class_distribution(config.train_dir)\n    class_names = temp_dataset.classes\n    num_classes = len(class_names)\n    \n    print(f\"\\nClasses: {class_names}\")\n    \n    # Create datasets\n    full_dataset = datasets.ImageFolder(root=config.train_dir, transform=transform_train)\n    train_size = int(0.8 * len(full_dataset))\n    val_size = len(full_dataset) - train_size\n    train_dataset, val_temp = random_split(full_dataset, [train_size, val_size], \n                                          generator=torch.Generator().manual_seed(42))\n    \n    val_full_dataset = datasets.ImageFolder(root=config.train_dir, transform=transform_val)\n    \n    class ValDataset:\n        def __init__(self, base_dataset, indices):\n            self.base_dataset = base_dataset\n            self.indices = indices\n        \n        def __len__(self):\n            return len(self.indices)\n        \n        def __getitem__(self, idx):\n            return self.base_dataset[self.indices[idx]]\n    \n    val_dataset = ValDataset(val_full_dataset, val_temp.indices)\n    \n    print(f\"\\nTrain: {len(train_dataset):,} | Val: {len(val_dataset):,}\")\n    \n    # Create samplers and loaders\n    train_sampler = create_weighted_sampler(train_dataset)\n    \n    train_loader = DataLoader(train_dataset, batch_size=config.batch_size,\n                            sampler=train_sampler, num_workers=2, pin_memory=True)\n    val_loader = DataLoader(val_dataset, batch_size=config.batch_size,\n                          shuffle=False, num_workers=2, pin_memory=True)\n    \n    # Initialize model\n    print(f\"\\nInitializing EfficientNet-B3...\")\n    model = ChestXrayClassifier(num_classes=num_classes, pretrained=True)\n    model = model.to(config.device)\n    \n    # Loss and optimizer\n    class_weights = calculate_class_weights(train_dataset).to(config.device)\n    print(f\"\\nClass weights: {class_weights}\")\n    criterion = nn.CrossEntropyLoss(weight=class_weights)\n    \n    optimizer = optim.AdamW(model.parameters(), lr=config.learning_rate, \n                           weight_decay=config.weight_decay)\n    scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=5, T_mult=2)\n    \n    # Training loop\n    print(f\"\\nStarting training for {config.num_epochs} epochs...\")\n    best_balanced_acc = 0.0\n    patience_counter = 0\n    \n    for epoch in range(config.num_epochs):\n        print(f\"\\n{'='*50}\")\n        print(f\"Epoch {epoch+1}/{config.num_epochs}\")\n        print('='*50)\n        \n        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, config.device)\n        val_loss, val_acc, val_balanced_acc, _, _ = validate_epoch(model, val_loader, criterion, config.device)\n        \n        scheduler.step()\n        current_lr = optimizer.param_groups[0]['lr']\n        \n        print(f\"\\nResults:\")\n        print(f\"Train - Loss: {train_loss:.4f}, Acc: {train_acc:.4f}\")\n        print(f\"Val   - Loss: {val_loss:.4f}, Acc: {val_acc:.4f}, Balanced: {val_balanced_acc:.4f}\")\n        print(f\"LR: {current_lr:.2e}\")\n        \n        if val_balanced_acc > best_balanced_acc:\n            best_balanced_acc = val_balanced_acc\n            torch.save({\n                'epoch': epoch,\n                'model_state_dict': model.state_dict(),\n                'optimizer_state_dict': optimizer.state_dict(),\n                'best_balanced_acc': best_balanced_acc,\n                'class_names': class_names\n            }, 'best_chest_xray_model(2).pth')\n            print(f\"✓ New best: {best_balanced_acc:.4f}\")\n            patience_counter = 0\n        else:\n            patience_counter += 1\n        \n        if patience_counter >= config.patience:\n            print(f\"\\nEarly stopping at epoch {epoch+1}\")\n            break\n    \n    print(f\"\\n{'='*60}\")\n    print(f\"TRAINING COMPLETE - Best: {best_balanced_acc:.4f}\")\n    print('='*60)\n    \n    return model, class_names, best_balanced_acc\n\n# ==========================\n# Prediction (NO TTA)\n# ==========================\ndef predict_simple(model, image_path, device):\n    \"\"\"Simple prediction without TTA\"\"\"\n    model.eval()\n    image = Image.open(image_path).convert('RGB')\n    image_tensor = transform_test(image).unsqueeze(0).to(device)\n    \n    with torch.no_grad():\n        outputs = model(image_tensor)\n        probabilities = torch.softmax(outputs, dim=1)\n    \n    return probabilities.cpu().numpy()\n\n# ==========================\n# Generate Submission\n# ==========================\ndef generate_submission():\n    print(\"\\n\" + \"=\"*60)\n    print(\"GENERATING SUBMISSION\")\n    print(\"=\"*60)\n    \n    checkpoint = torch.load('best_chest_xray_model(2).pth', \n                          map_location=config.device, weights_only=False)\n    class_names = checkpoint['class_names']\n    \n    model = ChestXrayClassifier(num_classes=len(class_names), pretrained=False)\n    model.load_state_dict(checkpoint['model_state_dict'])\n    model = model.to(config.device)\n    model.eval()\n    \n    print(f\"Loaded model: {checkpoint['best_balanced_acc']:.4f}\")\n    print(f\"Classes: {class_names}\")\n    print(f\"Using TTA: {config.use_tta}\")\n    \n    test_images = sorted([f for f in os.listdir(config.test_dir) \n                         if f.lower().endswith(('.png', '.jpg', '.jpeg'))])\n    \n    print(f\"\\nProcessing {len(test_images)} images...\")\n    \n    image_ids = []\n    predictions = []\n    confidences = []\n    \n    for i, img_name in enumerate(test_images):\n        if i % 500 == 0:\n            print(f\"Progress: {i}/{len(test_images)}\")\n        \n        img_path = os.path.join(config.test_dir, img_name)\n        \n        try:\n            prob_vector = predict_simple(model, img_path, config.device)\n            pred_class = np.argmax(prob_vector)\n            confidence = np.max(prob_vector)\n            \n            image_ids.append(os.path.splitext(img_name)[0])\n            predictions.append(pred_class)\n            confidences.append(confidence)\n            \n        except Exception as e:\n            print(f\"Error {img_name}: {e}\")\n            image_ids.append(os.path.splitext(img_name)[0])\n            predictions.append(1)  # Default to Normal\n            confidences.append(0.33)\n    \n    # Create submission\n    submission_df = pd.DataFrame({\n        'Id': image_ids,\n        'Predicted': predictions\n    })\n    \n    submission_df.to_csv('submission(2).csv', index=False)\n    \n    print(f\"\\n✓ Submission complete!\")\n    print(f\"Total: {len(submission_df)}\")\n    \n    print(\"\\nDistribution:\")\n    for idx in range(len(class_names)):\n        count = (submission_df['Predicted'] == idx).sum()\n        pct = count / len(submission_df) * 100\n        print(f\"{class_names[idx]}: {count} ({pct:.1f}%)\")\n    \n    print(f\"\\nConfidence - Mean: {np.mean(confidences):.4f}, Std: {np.std(confidences):.4f}\")\n    \n    return submission_df\n\n# ==========================\n# Main Execution\n# ==========================\nif __name__ == \"__main__\":\n    print(\"Enhanced Chest X-Ray Classifier\")\n    print(\"=\"*60)\n    \n    try:\n        model, class_names, best_score = train_model()\n        submission = generate_submission()\n        \n        print(\"\\n✓ Complete!\")\n        print(f\"Best score: {best_score:.4f}\")\n        print(\"Files: best_chest_xray_model(2).pth, submission(2).csv\")\n        \n    except Exception as e:\n        print(f\"\\n✗ Error: {e}\")\n        import traceback\n        traceback.print_exc()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T06:51:34.023668Z","iopub.execute_input":"2025-09-29T06:51:34.023873Z","iopub.status.idle":"2025-09-29T08:45:11.126900Z","shell.execute_reply.started":"2025-09-29T06:51:34.023853Z","shell.execute_reply":"2025-09-29T08:45:11.126103Z"},"jupyter":{"source_hidden":true,"outputs_hidden":true},"collapsed":true},"outputs":[{"name":"stdout","text":"Device: cuda\nImage size: 384\nUse TTA: False\nEnhanced Chest X-Ray Classifier\n============================================================\n\n============================================================\nTRAINING WITH EFFICIENTNET-B3\n============================================================\n\n========================================\nCLASS DISTRIBUTION\n========================================\nCOVID: 1,596 (18.6%)\nNormal: 6,310 (73.6%)\nViral Pneumonia: 666 (7.8%)\nTotal: 8,572\n========================================\n\nClasses: ['COVID', 'Normal', 'Viral Pneumonia']\n\nTrain: 6,857 | Val: 1,715\n\nClass weights:\nClass 1: 0.454\nClass 2: 4.209\nClass 0: 1.782\n\nInitializing EfficientNet-B3...\n","output_type":"stream"},{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/efficientnet_b3_rwightman-b3899882.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b3_rwightman-b3899882.pth\n100%|██████████| 47.2M/47.2M [00:00<00:00, 167MB/s]\n","output_type":"stream"},{"name":"stdout","text":"\nClass weights: tensor([1.7815, 0.4543, 4.2093], device='cuda:0')\n\nStarting training for 30 epochs...\n\n==================================================\nEpoch 1/30\n==================================================\nBatch 0/429, Loss: 1.0723\nBatch 50/429, Loss: 0.4830\nBatch 100/429, Loss: 0.2660\nBatch 150/429, Loss: 0.0774\nBatch 200/429, Loss: 0.1734\nBatch 250/429, Loss: 0.0758\nBatch 300/429, Loss: 0.1025\nBatch 350/429, Loss: 0.0746\nBatch 400/429, Loss: 0.0721\n\nResults:\nTrain - Loss: 0.2962, Acc: 0.7715\nVal   - Loss: 0.1974, Acc: 0.8910, Balanced: 0.9376\nLR: 4.52e-05\n✓ New best: 0.9376\n\n==================================================\nEpoch 2/30\n==================================================\nBatch 0/429, Loss: 0.0355\nBatch 50/429, Loss: 0.2094\nBatch 100/429, Loss: 0.0137\nBatch 150/429, Loss: 0.1994\nBatch 200/429, Loss: 0.1292\nBatch 250/429, Loss: 0.2149\nBatch 300/429, Loss: 0.0950\nBatch 350/429, Loss: 0.0450\nBatch 400/429, Loss: 0.1574\n\nResults:\nTrain - Loss: 0.1235, Acc: 0.9115\nVal   - Loss: 0.1176, Acc: 0.9557, Balanced: 0.9673\nLR: 3.27e-05\n✓ New best: 0.9673\n\n==================================================\nEpoch 3/30\n==================================================\nBatch 0/429, Loss: 0.0334\nBatch 50/429, Loss: 0.0149\nBatch 100/429, Loss: 0.0875\nBatch 150/429, Loss: 0.2020\nBatch 200/429, Loss: 0.0273\nBatch 250/429, Loss: 0.2186\nBatch 300/429, Loss: 0.0006\nBatch 350/429, Loss: 0.0056\nBatch 400/429, Loss: 0.0519\n\nResults:\nTrain - Loss: 0.0837, Acc: 0.9463\nVal   - Loss: 0.1352, Acc: 0.9662, Balanced: 0.9597\nLR: 1.73e-05\n\n==================================================\nEpoch 4/30\n==================================================\nBatch 0/429, Loss: 0.0460\nBatch 50/429, Loss: 0.0175\nBatch 100/429, Loss: 0.0082\nBatch 150/429, Loss: 0.0005\nBatch 200/429, Loss: 0.8118\nBatch 250/429, Loss: 0.0225\nBatch 300/429, Loss: 0.0584\nBatch 350/429, Loss: 0.0008\nBatch 400/429, Loss: 0.0380\n\nResults:\nTrain - Loss: 0.0653, Acc: 0.9557\nVal   - Loss: 0.1020, Acc: 0.9767, Balanced: 0.9717\nLR: 4.77e-06\n✓ New best: 0.9717\n\n==================================================\nEpoch 5/30\n==================================================\nBatch 0/429, Loss: 0.0007\nBatch 50/429, Loss: 0.0383\nBatch 100/429, Loss: 0.0019\nBatch 150/429, Loss: 0.0335\nBatch 200/429, Loss: 0.1416\nBatch 250/429, Loss: 0.0115\nBatch 300/429, Loss: 0.0043\nBatch 350/429, Loss: 0.0262\nBatch 400/429, Loss: 0.0085\n\nResults:\nTrain - Loss: 0.0585, Acc: 0.9649\nVal   - Loss: 0.0838, Acc: 0.9767, Balanced: 0.9717\nLR: 5.00e-05\n\n==================================================\nEpoch 6/30\n==================================================\nBatch 0/429, Loss: 0.0016\nBatch 50/429, Loss: 0.3025\nBatch 100/429, Loss: 0.0066\nBatch 150/429, Loss: 0.1970\nBatch 200/429, Loss: 0.0044\nBatch 250/429, Loss: 0.0062\nBatch 300/429, Loss: 0.0028\nBatch 350/429, Loss: 0.0038\nBatch 400/429, Loss: 0.0209\n\nResults:\nTrain - Loss: 0.0574, Acc: 0.9651\nVal   - Loss: 0.0885, Acc: 0.9790, Balanced: 0.9743\nLR: 4.88e-05\n✓ New best: 0.9743\n\n==================================================\nEpoch 7/30\n==================================================\nBatch 0/429, Loss: 0.0014\nBatch 50/429, Loss: 0.6043\nBatch 100/429, Loss: 0.0014\nBatch 150/429, Loss: 0.1147\nBatch 200/429, Loss: 0.0112\nBatch 250/429, Loss: 1.1039\nBatch 300/429, Loss: 0.0024\nBatch 350/429, Loss: 0.0106\nBatch 400/429, Loss: 0.0282\n\nResults:\nTrain - Loss: 0.0590, Acc: 0.9686\nVal   - Loss: 0.0688, Acc: 0.9837, Balanced: 0.9797\nLR: 4.52e-05\n✓ New best: 0.9797\n\n==================================================\nEpoch 8/30\n==================================================\nBatch 0/429, Loss: 0.0197\nBatch 50/429, Loss: 0.0067\nBatch 100/429, Loss: 0.0426\nBatch 150/429, Loss: 0.0035\nBatch 200/429, Loss: 0.0565\nBatch 250/429, Loss: 0.0678\nBatch 300/429, Loss: 0.0614\nBatch 350/429, Loss: 0.0420\nBatch 400/429, Loss: 0.0002\n\nResults:\nTrain - Loss: 0.0467, Acc: 0.9735\nVal   - Loss: 0.1139, Acc: 0.9825, Balanced: 0.9613\nLR: 3.97e-05\n\n==================================================\nEpoch 9/30\n==================================================\nBatch 0/429, Loss: 0.0021\nBatch 50/429, Loss: 0.0004\nBatch 100/429, Loss: 0.0020\nBatch 150/429, Loss: 0.0025\nBatch 200/429, Loss: 0.0042\nBatch 250/429, Loss: 0.0007\nBatch 300/429, Loss: 0.0842\nBatch 350/429, Loss: 0.6186\nBatch 400/429, Loss: 0.0016\n\nResults:\nTrain - Loss: 0.0363, Acc: 0.9767\nVal   - Loss: 0.1830, Acc: 0.9773, Balanced: 0.9474\nLR: 3.27e-05\n\n==================================================\nEpoch 10/30\n==================================================\nBatch 0/429, Loss: 0.0084\nBatch 50/429, Loss: 0.0016\nBatch 100/429, Loss: 0.0003\nBatch 150/429, Loss: 0.0028\nBatch 200/429, Loss: 0.0371\nBatch 250/429, Loss: 0.1041\nBatch 300/429, Loss: 0.0266\nBatch 350/429, Loss: 0.0030\nBatch 400/429, Loss: 0.0027\n\nResults:\nTrain - Loss: 0.0297, Acc: 0.9831\nVal   - Loss: 0.0894, Acc: 0.9843, Balanced: 0.9742\nLR: 2.50e-05\n\n==================================================\nEpoch 11/30\n==================================================\nBatch 0/429, Loss: 0.0021\nBatch 50/429, Loss: 0.0110\nBatch 100/429, Loss: 0.0023\nBatch 150/429, Loss: 0.0008\nBatch 200/429, Loss: 0.0007\nBatch 250/429, Loss: 0.0007\nBatch 300/429, Loss: 0.0001\nBatch 350/429, Loss: 0.0429\nBatch 400/429, Loss: 0.0732\n\nResults:\nTrain - Loss: 0.0329, Acc: 0.9831\nVal   - Loss: 0.0727, Acc: 0.9878, Balanced: 0.9758\nLR: 1.73e-05\n\n==================================================\nEpoch 12/30\n==================================================\nBatch 0/429, Loss: 0.0419\nBatch 50/429, Loss: 0.0001\nBatch 100/429, Loss: 0.0204\nBatch 150/429, Loss: 0.0011\nBatch 200/429, Loss: 0.0158\nBatch 250/429, Loss: 0.0000\nBatch 300/429, Loss: 0.0004\nBatch 350/429, Loss: 0.3115\nBatch 400/429, Loss: 0.0033\n\nResults:\nTrain - Loss: 0.0210, Acc: 0.9867\nVal   - Loss: 0.0743, Acc: 0.9889, Balanced: 0.9779\nLR: 1.03e-05\n\n==================================================\nEpoch 13/30\n==================================================\nBatch 0/429, Loss: 0.0035\nBatch 50/429, Loss: 0.0026\nBatch 100/429, Loss: 0.0164\nBatch 150/429, Loss: 0.0002\nBatch 200/429, Loss: 0.0002\nBatch 250/429, Loss: 0.0004\nBatch 300/429, Loss: 0.0000\nBatch 350/429, Loss: 0.0096\nBatch 400/429, Loss: 0.0088\n\nResults:\nTrain - Loss: 0.0184, Acc: 0.9889\nVal   - Loss: 0.0753, Acc: 0.9872, Balanced: 0.9780\nLR: 4.77e-06\n\n==================================================\nEpoch 14/30\n==================================================\nBatch 0/429, Loss: 0.0000\nBatch 50/429, Loss: 0.0005\nBatch 100/429, Loss: 0.0006\nBatch 150/429, Loss: 0.0020\nBatch 200/429, Loss: 0.0199\nBatch 250/429, Loss: 0.0000\nBatch 300/429, Loss: 0.0396\nBatch 350/429, Loss: 0.0353\nBatch 400/429, Loss: 0.0056\n\nResults:\nTrain - Loss: 0.0170, Acc: 0.9873\nVal   - Loss: 0.0745, Acc: 0.9860, Balanced: 0.9774\nLR: 1.22e-06\n\n==================================================\nEpoch 15/30\n==================================================\nBatch 0/429, Loss: 0.0139\nBatch 50/429, Loss: 0.0001\nBatch 100/429, Loss: 0.0002\nBatch 150/429, Loss: 0.0001\nBatch 200/429, Loss: 0.0002\nBatch 250/429, Loss: 0.0075\nBatch 300/429, Loss: 0.0017\nBatch 350/429, Loss: 0.0102\nBatch 400/429, Loss: 0.0003\n\nResults:\nTrain - Loss: 0.0200, Acc: 0.9898\nVal   - Loss: 0.0712, Acc: 0.9889, Balanced: 0.9812\nLR: 5.00e-05\n✓ New best: 0.9812\n\n==================================================\nEpoch 16/30\n==================================================\nBatch 0/429, Loss: 0.0001\nBatch 50/429, Loss: 0.0070\nBatch 100/429, Loss: 0.0000\nBatch 150/429, Loss: 0.0001\nBatch 200/429, Loss: 0.0279\nBatch 250/429, Loss: 0.0021\nBatch 300/429, Loss: 0.0113\nBatch 350/429, Loss: 0.0004\nBatch 400/429, Loss: 0.0004\n\nResults:\nTrain - Loss: 0.0309, Acc: 0.9832\nVal   - Loss: 0.0584, Acc: 0.9872, Balanced: 0.9813\nLR: 4.97e-05\n✓ New best: 0.9813\n\n==================================================\nEpoch 17/30\n==================================================\nBatch 0/429, Loss: 0.0375\nBatch 50/429, Loss: 0.0008\nBatch 100/429, Loss: 0.0008\nBatch 150/429, Loss: 0.0301\nBatch 200/429, Loss: 0.2761\nBatch 250/429, Loss: 0.0011\nBatch 300/429, Loss: 0.0069\nBatch 350/429, Loss: 0.0095\nBatch 400/429, Loss: 0.0002\n\nResults:\nTrain - Loss: 0.0231, Acc: 0.9869\nVal   - Loss: 0.0814, Acc: 0.9878, Balanced: 0.9758\nLR: 4.88e-05\n\n==================================================\nEpoch 18/30\n==================================================\nBatch 0/429, Loss: 0.0001\nBatch 50/429, Loss: 0.0002\nBatch 100/429, Loss: 0.0004\nBatch 150/429, Loss: 0.0053\nBatch 200/429, Loss: 0.2848\nBatch 250/429, Loss: 0.0062\nBatch 300/429, Loss: 0.0009\nBatch 350/429, Loss: 0.0009\nBatch 400/429, Loss: 0.0001\n\nResults:\nTrain - Loss: 0.0203, Acc: 0.9902\nVal   - Loss: 0.1176, Acc: 0.9872, Balanced: 0.9723\nLR: 4.73e-05\n\n==================================================\nEpoch 19/30\n==================================================\nBatch 0/429, Loss: 0.0009\nBatch 50/429, Loss: 0.0004\nBatch 100/429, Loss: 0.0014\nBatch 150/429, Loss: 0.0004\nBatch 200/429, Loss: 0.0000\nBatch 250/429, Loss: 0.0002\nBatch 300/429, Loss: 0.0002\nBatch 350/429, Loss: 0.0000\nBatch 400/429, Loss: 0.1822\n\nResults:\nTrain - Loss: 0.0173, Acc: 0.9911\nVal   - Loss: 0.0671, Acc: 0.9901, Balanced: 0.9834\nLR: 4.52e-05\n✓ New best: 0.9834\n\n==================================================\nEpoch 20/30\n==================================================\nBatch 0/429, Loss: 0.0095\nBatch 50/429, Loss: 0.0000\nBatch 100/429, Loss: 0.0000\nBatch 150/429, Loss: 0.0000\nBatch 200/429, Loss: 0.0014\nBatch 250/429, Loss: 0.0002\nBatch 300/429, Loss: 0.0018\nBatch 350/429, Loss: 0.0001\nBatch 400/429, Loss: 0.0000\n\nResults:\nTrain - Loss: 0.0182, Acc: 0.9905\nVal   - Loss: 0.0989, Acc: 0.9872, Balanced: 0.9755\nLR: 4.27e-05\n\n==================================================\nEpoch 21/30\n==================================================\nBatch 0/429, Loss: 0.0069\nBatch 50/429, Loss: 0.0011\nBatch 100/429, Loss: 0.0049\nBatch 150/429, Loss: 0.0010\nBatch 200/429, Loss: 0.0241\nBatch 250/429, Loss: 0.0001\nBatch 300/429, Loss: 0.0013\nBatch 350/429, Loss: 0.0000\nBatch 400/429, Loss: 0.0394\n\nResults:\nTrain - Loss: 0.0124, Acc: 0.9920\nVal   - Loss: 0.0820, Acc: 0.9883, Balanced: 0.9736\nLR: 3.97e-05\n\n==================================================\nEpoch 22/30\n==================================================\nBatch 0/429, Loss: 0.0000\nBatch 50/429, Loss: 0.0001\nBatch 100/429, Loss: 0.0009\nBatch 150/429, Loss: 0.0020\nBatch 200/429, Loss: 0.0001\nBatch 250/429, Loss: 0.0007\nBatch 300/429, Loss: 0.0020\nBatch 350/429, Loss: 0.0000\nBatch 400/429, Loss: 0.0000\n\nResults:\nTrain - Loss: 0.0168, Acc: 0.9923\nVal   - Loss: 0.0971, Acc: 0.9808, Balanced: 0.9661\nLR: 3.63e-05\n\n==================================================\nEpoch 23/30\n==================================================\nBatch 0/429, Loss: 0.0000\nBatch 50/429, Loss: 0.0007\nBatch 100/429, Loss: 0.0001\nBatch 150/429, Loss: 0.0002\nBatch 200/429, Loss: 0.0037\nBatch 250/429, Loss: 0.0000\nBatch 300/429, Loss: 0.0007\nBatch 350/429, Loss: 0.0000\nBatch 400/429, Loss: 0.0001\n\nResults:\nTrain - Loss: 0.0084, Acc: 0.9946\nVal   - Loss: 0.1192, Acc: 0.9889, Balanced: 0.9722\nLR: 3.27e-05\n\n==================================================\nEpoch 24/30\n==================================================\nBatch 0/429, Loss: 0.0001\nBatch 50/429, Loss: 0.0001\nBatch 100/429, Loss: 0.0043\nBatch 150/429, Loss: 0.0000\nBatch 200/429, Loss: 0.0000\nBatch 250/429, Loss: 0.0005\nBatch 300/429, Loss: 0.0001\nBatch 350/429, Loss: 0.0008\nBatch 400/429, Loss: 0.0009\n\nResults:\nTrain - Loss: 0.0067, Acc: 0.9959\nVal   - Loss: 0.1307, Acc: 0.9872, Balanced: 0.9658\nLR: 2.89e-05\n\n==================================================\nEpoch 25/30\n==================================================\nBatch 0/429, Loss: 0.0001\nBatch 50/429, Loss: 0.0001\nBatch 100/429, Loss: 0.0002\nBatch 150/429, Loss: 0.0000\nBatch 200/429, Loss: 0.0000\nBatch 250/429, Loss: 0.0000\nBatch 300/429, Loss: 0.0003\nBatch 350/429, Loss: 0.0001\nBatch 400/429, Loss: 0.0067\n\nResults:\nTrain - Loss: 0.0089, Acc: 0.9953\nVal   - Loss: 0.0621, Acc: 0.9895, Balanced: 0.9806\nLR: 2.50e-05\n\n==================================================\nEpoch 26/30\n==================================================\nBatch 0/429, Loss: 0.0001\nBatch 50/429, Loss: 0.0000\nBatch 100/429, Loss: 0.0000\nBatch 150/429, Loss: 0.0000\nBatch 200/429, Loss: 0.0000\nBatch 250/429, Loss: 0.0000\nBatch 300/429, Loss: 0.0002\nBatch 350/429, Loss: 0.0002\nBatch 400/429, Loss: 0.0004\n\nResults:\nTrain - Loss: 0.0057, Acc: 0.9971\nVal   - Loss: 0.0915, Acc: 0.9889, Balanced: 0.9787\nLR: 2.11e-05\n\n==================================================\nEpoch 27/30\n==================================================\nBatch 0/429, Loss: 0.0002\nBatch 50/429, Loss: 0.0000\nBatch 100/429, Loss: 0.0002\nBatch 150/429, Loss: 0.0014\nBatch 200/429, Loss: 0.0001\nBatch 250/429, Loss: 0.0001\nBatch 300/429, Loss: 0.0013\nBatch 350/429, Loss: 0.0123\nBatch 400/429, Loss: 0.0000\n\nResults:\nTrain - Loss: 0.0050, Acc: 0.9980\nVal   - Loss: 0.1147, Acc: 0.9872, Balanced: 0.9690\nLR: 1.73e-05\n\n==================================================\nEpoch 28/30\n==================================================\nBatch 0/429, Loss: 0.0109\nBatch 50/429, Loss: 0.0000\nBatch 100/429, Loss: 0.0000\nBatch 150/429, Loss: 0.1052\nBatch 200/429, Loss: 0.0001\nBatch 250/429, Loss: 0.0000\nBatch 300/429, Loss: 0.0000\nBatch 350/429, Loss: 0.0000\nBatch 400/429, Loss: 0.0000\n\nResults:\nTrain - Loss: 0.0052, Acc: 0.9969\nVal   - Loss: 0.1280, Acc: 0.9860, Balanced: 0.9685\nLR: 1.37e-05\n\n==================================================\nEpoch 29/30\n==================================================\nBatch 0/429, Loss: 0.0002\nBatch 50/429, Loss: 0.0000\nBatch 100/429, Loss: 0.0000\nBatch 150/429, Loss: 0.0000\nBatch 200/429, Loss: 0.0000\nBatch 250/429, Loss: 0.0001\nBatch 300/429, Loss: 0.0000\nBatch 350/429, Loss: 0.0001\nBatch 400/429, Loss: 0.0002\n\nResults:\nTrain - Loss: 0.0053, Acc: 0.9966\nVal   - Loss: 0.1079, Acc: 0.9883, Balanced: 0.9703\nLR: 1.03e-05\n\nEarly stopping at epoch 29\n\n============================================================\nTRAINING COMPLETE - Best: 0.9834\n============================================================\n\n============================================================\nGENERATING SUBMISSION\n============================================================\nLoaded model: 0.9834\nClasses: ['COVID', 'Normal', 'Viral Pneumonia']\nUsing TTA: False\n\nProcessing 6382 images...\nProgress: 0/6382\nProgress: 500/6382\nProgress: 1000/6382\nProgress: 1500/6382\nProgress: 2000/6382\nProgress: 2500/6382\nProgress: 3000/6382\nProgress: 3500/6382\nProgress: 4000/6382\nProgress: 4500/6382\nProgress: 5000/6382\nProgress: 5500/6382\nProgress: 6000/6382\n\n✓ Submission complete!\nTotal: 6382\n\nDistribution:\nCOVID: 1977 (31.0%)\nNormal: 3717 (58.2%)\nViral Pneumonia: 688 (10.8%)\n\nConfidence - Mean: 0.9938, Std: 0.0389\n\n✓ Complete!\nBest score: 0.9834\nFiles: best_chest_xray_model(2).pth, submission(2).csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"**EFFNET-B0**","metadata":{}},{"cell_type":"code","source":"import os\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Subset, WeightedRandomSampler\nfrom torchvision import datasets, transforms, models\nfrom torchvision.models import efficientnet_b0, efficientnet_b3\nfrom sklearn.model_selection import StratifiedShuffleSplit\nfrom sklearn.metrics import classification_report, confusion_matrix, balanced_accuracy_score, f1_score\nfrom collections import Counter\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport random\nimport time\n\n# -----------------------\n# Configuration\n# -----------------------\nclass Config:\n    train_dir = \"/kaggle/input/final-srifoton-25-machine-learning-competition/train/train\"\n    test_dir = \"/kaggle/input/final-srifoton-25-machine-learning-competition/test/test\"\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    batch_size = 32\n    learning_rate = 1e-4\n    weight_decay = 1e-4\n    num_epochs = 25\n    patience = 8\n    img_size = 224\n    model_name = \"efficientnet_b0\"  # options: efficientnet_b0, efficientnet_b3, resnet50\n    best_model_path = f\"best_{model_name}_chest_xray.pth\"\n    submission_file = f\"submission_{model_name}.csv\"\n    use_amp = True  # mixed precision\n    seed = 42\n    num_workers = 2\n    print(f\"Device: {device}\")\n    print(f\"Image size: {img_size}\")\n\nconfig = Config()\n\n# -----------------------\n# reproducibility\n# -----------------------\ndef seed_everything(seed=42):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(seed)\n\nseed_everything(config.seed)\n\n# -----------------------\n# Transforms\n# -----------------------\ntransform_train = transforms.Compose([\n    transforms.Resize((config.img_size, config.img_size)),\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.RandomRotation(degrees=10),\n    transforms.ColorJitter(brightness=0.12, contrast=0.12, saturation=0.12),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\ntransform_val = transforms.Compose([\n    transforms.Resize((config.img_size, config.img_size)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\ntransform_test = transform_val\n\n# -----------------------\n# Utilities: analyze distribution\n# -----------------------\ndef analyze_class_distribution(dataset_path):\n    class_counts = {}\n    total = 0\n    for class_name in sorted(os.listdir(dataset_path)):\n        class_path = os.path.join(dataset_path, class_name)\n        if os.path.isdir(class_path):\n            count = len([f for f in os.listdir(class_path) if f.lower().endswith((\".png\", \".jpg\", \".jpeg\"))])\n            class_counts[class_name] = count\n            total += count\n    print(\"\\n\" + \"=\"*40)\n    print(\"CLASS DISTRIBUTION ANALYSIS\")\n    print(\"=\"*40)\n    for class_name, count in sorted(class_counts.items()):\n        percentage = (count / total) * 100 if total>0 else 0\n        print(f\"{class_name}: {count:,} samples ({percentage:.1f}%)\")\n    print(f\"Total: {total:,} samples\")\n    print(\"=\"*40)\n    return class_counts, total\n\n# -----------------------\n# Weighted sampler creator (handles Subset too)\n# -----------------------\ndef create_weighted_sampler_from_targets(targets):\n    counts = Counter(targets)\n    num_classes = len(counts)\n    total = sum(counts.values())\n    class_weights = {cls: total / (num_classes * cnt) for cls, cnt in counts.items()}\n    sample_weights = [class_weights[t] for t in targets]\n    print(\"\\nClass weights for sampling:\")\n    for cls, w in sorted(class_weights.items()):\n        print(f\"Class {cls}: {w:.3f}\")\n    sampler = WeightedRandomSampler(weights=sample_weights, num_samples=len(sample_weights), replacement=True)\n    return sampler\n\n# -----------------------\n# Model builder\n# -----------------------\nclass ChestXrayClassifier(nn.Module):\n    def __init__(self, num_classes=3, backbone_name=\"efficientnet_b0\", pretrained=True):\n        super().__init__()\n        self.backbone_name = backbone_name\n        if backbone_name == \"efficientnet_b0\":\n            backbone = efficientnet_b0(pretrained=pretrained)\n            num_features = backbone.classifier[1].in_features\n            backbone.classifier = nn.Identity()\n            self.backbone = backbone\n        elif backbone_name == \"efficientnet_b3\":\n            try:\n                backbone = efficientnet_b3(pretrained=pretrained)\n                num_features = backbone.classifier[1].in_features\n                backbone.classifier = nn.Identity()\n                self.backbone = backbone\n            except Exception:\n                # fallback\n                backbone = efficientnet_b0(pretrained=pretrained)\n                num_features = backbone.classifier[1].in_features\n                backbone.classifier = nn.Identity()\n                self.backbone = backbone\n        elif backbone_name == \"resnet50\":\n            backbone = models.resnet50(pretrained=pretrained)\n            num_features = backbone.fc.in_features\n            backbone.fc = nn.Identity()\n            self.backbone = backbone\n        else:\n            raise ValueError(\"Unsupported backbone\")\n\n        self.classifier = nn.Sequential(\n            nn.Dropout(0.5),\n            nn.Linear(num_features, 512),\n            nn.BatchNorm1d(512),\n            nn.ReLU(inplace=True),\n            nn.Dropout(0.3),\n            nn.Linear(512, 256),\n            nn.BatchNorm1d(256),\n            nn.ReLU(inplace=True),\n            nn.Dropout(0.2),\n            nn.Linear(256, num_classes)\n        )\n        self._init_classifier()\n\n    def _init_classifier(self):\n        for m in self.classifier.modules():\n            if isinstance(m, nn.Linear):\n                nn.init.xavier_uniform_(m.weight)\n                if m.bias is not None:\n                    nn.init.constant_(m.bias, 0)\n\n    def forward(self, x):\n        features = self.backbone(x)\n        out = self.classifier(features)\n        return out\n\n# -----------------------\n# Loss & metrics\n# -----------------------\ndef calculate_class_weights_from_targets(targets):\n    counts = Counter(targets)\n    num_classes = len(counts)\n    total = sum(counts.values())\n    weights = [total / (num_classes * counts[i]) for i in range(num_classes)]\n    return torch.FloatTensor(weights)\n\n# -----------------------\n# Robust torch.load helper (handles weights_only issue)\n# -----------------------\ndef robust_torch_load(path, map_location=None):\n    try:\n        # try default\n        return torch.load(path, map_location=map_location)\n    except Exception as e:\n        # fallback: try with weights_only=False (available in PyTorch >=2.6)\n        try:\n            # This may be required in newer torch to bypass safe globals restriction\n            return torch.load(path, map_location=map_location, weights_only=False)\n        except TypeError:\n            # older torch doesn't support weights_only param -> re-raise original\n            raise e\n        except Exception as e2:\n            raise e2\n\n# -----------------------\n# Training/validation loops (with AMP)\n# -----------------------\ndef train_epoch(model, dataloader, criterion, optimizer, device, scaler=None):\n    model.train()\n    total_loss = 0.0\n    correct = 0\n    total = 0\n    for batch_idx, (inputs, targets) in enumerate(dataloader):\n        inputs, targets = inputs.to(device), targets.to(device)\n        optimizer.zero_grad()\n        if scaler is not None:\n            with torch.cuda.amp.autocast():\n                outputs = model(inputs)\n                loss = criterion(outputs, targets)\n            scaler.scale(loss).backward()\n            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n            scaler.step(optimizer)\n            scaler.update()\n        else:\n            outputs = model(inputs)\n            loss = criterion(outputs, targets)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n            optimizer.step()\n        total_loss += loss.item()\n        _, preds = torch.max(outputs, 1)\n        correct += (preds == targets).sum().item()\n        total += targets.size(0)\n        if batch_idx % 50 == 0:\n            print(f'Batch {batch_idx}/{len(dataloader)}, Loss: {loss.item():.4f}')\n    avg_loss = total_loss / len(dataloader)\n    acc = correct / total\n    return avg_loss, acc\n\ndef validate_epoch(model, dataloader, criterion, device):\n    model.eval()\n    total_loss = 0.0\n    correct = 0\n    total = 0\n    all_preds = []\n    all_targets = []\n    with torch.no_grad():\n        for inputs, targets in dataloader:\n            inputs, targets = inputs.to(device), targets.to(device)\n            outputs = model(inputs)\n            loss = criterion(outputs, targets)\n            total_loss += loss.item()\n            _, preds = torch.max(outputs, 1)\n            correct += (preds == targets).sum().item()\n            total += targets.size(0)\n            all_preds.extend(preds.cpu().numpy())\n            all_targets.extend(targets.cpu().numpy())\n    avg_loss = total_loss / len(dataloader)\n    acc = correct / total\n    balanced_acc = balanced_accuracy_score(all_targets, all_preds)\n    f1 = f1_score(all_targets, all_preds, average=\"macro\")\n    return avg_loss, acc, balanced_acc, f1, all_preds, all_targets\n\n# -----------------------\n# Main training\n# -----------------------\ndef train_model():\n    print(\"\\n\" + \"=\"*60)\n    print(\"STARTING TRAINING PROCESS\")\n    print(\"=\"*60)\n\n    # analyze dataset\n    class_counts, total_samples = analyze_class_distribution(config.train_dir)\n\n    # load full folder dataset (for labels & stratified split)\n    full_dataset_for_split = datasets.ImageFolder(root=config.train_dir, transform=transform_val)\n    class_names = full_dataset_for_split.classes\n    num_classes = len(class_names)\n    print(f\"Classes: {class_names}\")\n    print(f\"Number of classes: {num_classes}\")\n\n    # gather targets for stratified split\n    targets = [y for _, y in full_dataset_for_split.samples]  # note: ImageFolder.samples gives (path, class_idx)\n    targets = [t for _, t in full_dataset_for_split.samples]  # alternative safe line\n    # actually above line wrong; fix:\n    targets = [s[1] for s in full_dataset_for_split.samples]\n\n    sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=config.seed)\n    train_idx, val_idx = next(sss.split(np.zeros(len(targets)), targets))\n\n    # create train & val datasets using same ImageFolder but different transforms\n    full_dataset_train_transformed = datasets.ImageFolder(root=config.train_dir, transform=transform_train)\n    full_dataset_val_transformed = datasets.ImageFolder(root=config.train_dir, transform=transform_val)\n\n    train_dataset = Subset(full_dataset_train_transformed, train_idx)\n    val_dataset = Subset(full_dataset_val_transformed, val_idx)\n\n    print(f\"Training samples: {len(train_dataset):,}\")\n    print(f\"Validation samples: {len(val_dataset):,}\")\n\n    # build sampler from train targets\n    train_targets = [full_dataset_train_transformed.samples[i][1] for i in train_idx]\n    train_sampler = create_weighted_sampler_from_targets(train_targets)\n\n    train_loader = DataLoader(train_dataset, batch_size=config.batch_size, sampler=train_sampler, num_workers=config.num_workers, pin_memory=True)\n    val_loader = DataLoader(val_dataset, batch_size=config.batch_size, shuffle=False, num_workers=config.num_workers, pin_memory=True)\n\n    # build model\n    model = ChestXrayClassifier(num_classes=num_classes, backbone_name=config.model_name, pretrained=True)\n    model = model.to(config.device)\n\n    total_params = sum(p.numel() for p in model.parameters())\n    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n    print(f\"Total parameters: {total_params:,}\")\n    print(f\"Trainable parameters: {trainable_params:,}\")\n\n    # class weights for criterion\n    class_weights_tensor = calculate_class_weights_from_targets(train_targets).to(config.device)\n    criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\n\n    optimizer = optim.AdamW(model.parameters(), lr=config.learning_rate, weight_decay=config.weight_decay)\n\n    # scheduler: use ReduceLROnPlateau with a simple CosineWarm restarter (optional). For simplicity keep ReduceLROnPlateau\n    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=4, verbose=True, min_lr=1e-7)\n\n    scaler = torch.cuda.amp.GradScaler() if (config.use_amp and config.device.type == \"cuda\") else None\n\n    best_balanced_acc = 0.0\n    patience_counter = 0\n\n    for epoch in range(config.num_epochs):\n        print(f\"\\nEpoch {epoch+1}/{config.num_epochs}\")\n        print(\"-\" * 50)\n        start = time.time()\n        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, config.device, scaler=scaler)\n        val_loss, val_acc, val_balanced_acc, val_f1, val_preds, val_targets = validate_epoch(model, val_loader, criterion, config.device)\n        scheduler.step(val_balanced_acc)\n        current_lr = optimizer.param_groups[0]['lr']\n        elapsed = time.time() - start\n\n        print(f\"\\nEpoch {epoch+1} Results (time: {elapsed:.1f}s):\")\n        print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}\")\n        print(f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f} | Val Balanced Acc: {val_balanced_acc:.4f} | Val F1: {val_f1:.4f}\")\n        print(f\"Learning Rate: {current_lr:.2e}\")\n\n        # save checkpoint (save only state_dicts to minimize pickle complexity)\n        if val_balanced_acc > best_balanced_acc:\n            best_balanced_acc = val_balanced_acc\n            checkpoint = {\n                'epoch': epoch,\n                'model_state_dict': model.state_dict(),\n                'optimizer_state_dict': optimizer.state_dict(),\n                'best_balanced_acc': best_balanced_acc,\n                'class_names': class_names\n            }\n            # SALVING: use torch.save of dict (this is standard)\n            torch.save(checkpoint, config.best_model_path)\n            print(f\"✅ New best model saved! Balanced Accuracy: {best_balanced_acc:.4f}\")\n            patience_counter = 0\n        else:\n            patience_counter += 1\n\n        if patience_counter >= config.patience:\n            print(f\"\\nEarly stopping triggered after {config.patience} epochs without improvement\")\n            break\n\n    print(\"\\n\" + \"=\"*60)\n    print(\"TRAINING COMPLETED!\")\n    print(f\"Best Balanced Accuracy: {best_balanced_acc:.4f}\")\n    print(\"=\"*60)\n\n    # load best checkpoint robustly\n    try:\n        checkpoint = robust_torch_load(config.best_model_path, map_location=config.device)\n        if 'model_state_dict' in checkpoint:\n            model.load_state_dict(checkpoint['model_state_dict'])\n        else:\n            # if somehow full model was saved\n            try:\n                model.load_state_dict(checkpoint)\n            except Exception as e:\n                raise RuntimeError(\"Failed to load model_state_dict from checkpoint.\") from e\n    except Exception as e:\n        # If still failing, raise clear informative error\n        print(\"FATAL: Failed to load checkpoint. Exception:\")\n        raise\n\n    # final validate and report\n    _, _, _, final_f1, final_preds, final_targets = validate_epoch(model, val_loader, criterion, config.device)\n\n    print(\"\\n\" + \"=\"*40)\n    print(\"FINAL VALIDATION REPORT\")\n    print(\"=\"*40)\n    print(classification_report(final_targets, final_preds, target_names=class_names, digits=4))\n    print(f\"\\nFinal Macro F1 Score: {final_f1:.4f}\")\n\n    cm = confusion_matrix(final_targets, final_preds)\n    plt.figure(figsize=(8, 6))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n    plt.title('Confusion Matrix - Final Validation')\n    plt.xlabel('Predicted')\n    plt.ylabel('Actual')\n    plt.tight_layout()\n    plt.savefig(f'confusion_matrix_{config.model_name}.png', dpi=300, bbox_inches='tight')\n    plt.show()\n\n    return model, class_names, best_balanced_acc\n\n# -----------------------\n# main\n# -----------------------\nif __name__ == \"__main__\":\n    print(\"🔬 Chest X-Ray Classification - EfficientNet Solution (fixed + improvements)\")\n    print(\"=\" * 60)\n    try:\n        model, class_names, best_score = train_model()\n        print(\"\\n🎉 Process completed successfully!\")\n        print(f\"📈 Best validation score: {best_score:.4f}\")\n        print(\"📁 Files generated:\")\n        print(f\"   - {config.best_model_path}\")\n        print(f\"   - confusion_matrix_{config.model_name}.png\")\n        print(f\"   - {config.submission_file}\")\n    except Exception as e:\n        print(\"\\n❌ Error occurred:\")\n        import traceback\n        traceback.print_exc()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T15:38:37.883898Z","iopub.execute_input":"2025-09-30T15:38:37.884254Z","iopub.status.idle":"2025-09-30T15:52:08.925112Z","shell.execute_reply.started":"2025-09-30T15:38:37.884234Z","shell.execute_reply":"2025-09-30T15:52:08.924250Z"},"jupyter":{"source_hidden":true,"outputs_hidden":true},"collapsed":true},"outputs":[{"name":"stdout","text":"Device: cuda\nImage size: 224\n🔬 Chest X-Ray Classification - EfficientNet Solution (fixed + improvements)\n============================================================\n\n============================================================\nSTARTING TRAINING PROCESS\n============================================================\n\n========================================\nCLASS DISTRIBUTION ANALYSIS\n========================================\nCOVID: 1,596 samples (18.6%)\nNormal: 6,310 samples (73.6%)\nViral Pneumonia: 666 samples (7.8%)\nTotal: 8,572 samples\n========================================\nClasses: ['COVID', 'Normal', 'Viral Pneumonia']\nNumber of classes: 3\nTraining samples: 6,857\nValidation samples: 1,715\n\nClass weights for sampling:\nClass 0: 1.790\nClass 1: 0.453\nClass 2: 4.288\nTotal parameters: 4,797,055\nTrainable parameters: 4,797,055\n\nEpoch 1/25\n--------------------------------------------------\nBatch 0/215, Loss: 1.1724\nBatch 50/215, Loss: 0.5192\nBatch 100/215, Loss: 0.2943\nBatch 150/215, Loss: 0.1688\nBatch 200/215, Loss: 0.1206\n\nEpoch 1 Results (time: 35.8s):\nTrain Loss: 0.3332 | Train Acc: 0.7197\nVal Loss: 0.2033 | Val Acc: 0.9020 | Val Balanced Acc: 0.9322 | Val F1: 0.8465\nLearning Rate: 1.00e-04\n✅ New best model saved! Balanced Accuracy: 0.9322\n\nEpoch 2/25\n--------------------------------------------------\nBatch 0/215, Loss: 0.0420\nBatch 50/215, Loss: 0.0645\nBatch 100/215, Loss: 0.0546\nBatch 150/215, Loss: 0.0958\nBatch 200/215, Loss: 0.0176\n\nEpoch 2 Results (time: 34.7s):\nTrain Loss: 0.0910 | Train Acc: 0.9296\nVal Loss: 0.1128 | Val Acc: 0.9656 | Val Balanced Acc: 0.9697 | Val F1: 0.9383\nLearning Rate: 1.00e-04\n✅ New best model saved! Balanced Accuracy: 0.9697\n\nEpoch 3/25\n--------------------------------------------------\nBatch 0/215, Loss: 0.1308\nBatch 50/215, Loss: 0.0248\nBatch 100/215, Loss: 0.0965\nBatch 150/215, Loss: 0.1068\nBatch 200/215, Loss: 0.0031\n\nEpoch 3 Results (time: 34.2s):\nTrain Loss: 0.0689 | Train Acc: 0.9492\nVal Loss: 0.0732 | Val Acc: 0.9720 | Val Balanced Acc: 0.9812 | Val F1: 0.9580\nLearning Rate: 1.00e-04\n✅ New best model saved! Balanced Accuracy: 0.9812\n\nEpoch 4/25\n--------------------------------------------------\nBatch 0/215, Loss: 0.1381\nBatch 50/215, Loss: 0.0264\nBatch 100/215, Loss: 0.0221\nBatch 150/215, Loss: 0.0076\nBatch 200/215, Loss: 0.0172\n\nEpoch 4 Results (time: 34.7s):\nTrain Loss: 0.0461 | Train Acc: 0.9695\nVal Loss: 0.0869 | Val Acc: 0.9720 | Val Balanced Acc: 0.9796 | Val F1: 0.9493\nLearning Rate: 1.00e-04\n\nEpoch 5/25\n--------------------------------------------------\nBatch 0/215, Loss: 0.0383\nBatch 50/215, Loss: 0.0336\nBatch 100/215, Loss: 0.0059\nBatch 150/215, Loss: 0.0029\nBatch 200/215, Loss: 0.0008\n\nEpoch 5 Results (time: 34.3s):\nTrain Loss: 0.0503 | Train Acc: 0.9751\nVal Loss: 0.0738 | Val Acc: 0.9749 | Val Balanced Acc: 0.9825 | Val F1: 0.9580\nLearning Rate: 1.00e-04\n✅ New best model saved! Balanced Accuracy: 0.9825\n\nEpoch 6/25\n--------------------------------------------------\nBatch 0/215, Loss: 0.0023\nBatch 50/215, Loss: 0.0014\nBatch 100/215, Loss: 0.0073\nBatch 150/215, Loss: 0.0028\nBatch 200/215, Loss: 0.2197\n\nEpoch 6 Results (time: 35.1s):\nTrain Loss: 0.0372 | Train Acc: 0.9826\nVal Loss: 0.0948 | Val Acc: 0.9854 | Val Balanced Acc: 0.9856 | Val F1: 0.9767\nLearning Rate: 1.00e-04\n✅ New best model saved! Balanced Accuracy: 0.9856\n\nEpoch 7/25\n--------------------------------------------------\nBatch 0/215, Loss: 0.0001\nBatch 50/215, Loss: 0.0045\nBatch 100/215, Loss: 0.0003\nBatch 150/215, Loss: 0.0001\nBatch 200/215, Loss: 0.0092\n\nEpoch 7 Results (time: 35.3s):\nTrain Loss: 0.0441 | Train Acc: 0.9851\nVal Loss: 0.1850 | Val Acc: 0.9883 | Val Balanced Acc: 0.9772 | Val F1: 0.9795\nLearning Rate: 1.00e-04\n\nEpoch 8/25\n--------------------------------------------------\nBatch 0/215, Loss: 0.0007\nBatch 50/215, Loss: 0.0274\nBatch 100/215, Loss: 0.2239\nBatch 150/215, Loss: 0.0000\nBatch 200/215, Loss: 0.5655\n\nEpoch 8 Results (time: 35.6s):\nTrain Loss: 0.0626 | Train Acc: 0.9812\nVal Loss: 0.1473 | Val Acc: 0.9854 | Val Balanced Acc: 0.9820 | Val F1: 0.9759\nLearning Rate: 1.00e-04\n\nEpoch 9/25\n--------------------------------------------------\nBatch 0/215, Loss: 0.0007\nBatch 50/215, Loss: 0.0009\nBatch 100/215, Loss: 0.0002\nBatch 150/215, Loss: 0.0009\nBatch 200/215, Loss: 0.0000\n\nEpoch 9 Results (time: 35.5s):\nTrain Loss: 0.0444 | Train Acc: 0.9844\nVal Loss: 0.1223 | Val Acc: 0.9872 | Val Balanced Acc: 0.9849 | Val F1: 0.9776\nLearning Rate: 1.00e-04\n\nEpoch 10/25\n--------------------------------------------------\nBatch 0/215, Loss: 0.0000\nBatch 50/215, Loss: 0.0001\nBatch 100/215, Loss: 0.0000\nBatch 150/215, Loss: 0.0000\nBatch 200/215, Loss: 0.0000\n\nEpoch 10 Results (time: 35.7s):\nTrain Loss: 0.0520 | Train Acc: 0.9869\nVal Loss: 0.0944 | Val Acc: 0.9860 | Val Balanced Acc: 0.9861 | Val F1: 0.9794\nLearning Rate: 1.00e-04\n✅ New best model saved! Balanced Accuracy: 0.9861\n\nEpoch 11/25\n--------------------------------------------------\nBatch 0/215, Loss: 0.0310\nBatch 50/215, Loss: 0.0000\nBatch 100/215, Loss: 0.0000\nBatch 150/215, Loss: 0.0071\nBatch 200/215, Loss: 0.0043\n\nEpoch 11 Results (time: 35.2s):\nTrain Loss: 0.0355 | Train Acc: 0.9882\nVal Loss: 0.1946 | Val Acc: 0.9901 | Val Balanced Acc: 0.9758 | Val F1: 0.9828\nLearning Rate: 1.00e-04\n\nEpoch 12/25\n--------------------------------------------------\nBatch 0/215, Loss: 0.0123\nBatch 50/215, Loss: 0.2592\nBatch 100/215, Loss: 0.0012\nBatch 150/215, Loss: 0.0000\nBatch 200/215, Loss: 0.0003\n\nEpoch 12 Results (time: 34.7s):\nTrain Loss: 0.0217 | Train Acc: 0.9915\nVal Loss: 0.1582 | Val Acc: 0.9901 | Val Balanced Acc: 0.9848 | Val F1: 0.9821\nLearning Rate: 1.00e-04\n\nEpoch 13/25\n--------------------------------------------------\nBatch 0/215, Loss: 0.0000\nBatch 50/215, Loss: 0.0002\nBatch 100/215, Loss: 0.0000\nBatch 150/215, Loss: 0.0003\nBatch 200/215, Loss: 0.0493\n\nEpoch 13 Results (time: 34.9s):\nTrain Loss: 0.0251 | Train Acc: 0.9929\nVal Loss: 0.1857 | Val Acc: 0.9883 | Val Balanced Acc: 0.9758 | Val F1: 0.9791\nLearning Rate: 1.00e-04\n\nEpoch 14/25\n--------------------------------------------------\nBatch 0/215, Loss: 0.0000\nBatch 50/215, Loss: 0.0001\nBatch 100/215, Loss: 0.0001\nBatch 150/215, Loss: 0.0000\nBatch 200/215, Loss: 0.0014\n\nEpoch 14 Results (time: 34.4s):\nTrain Loss: 0.0146 | Train Acc: 0.9945\nVal Loss: 0.2301 | Val Acc: 0.9901 | Val Balanced Acc: 0.9765 | Val F1: 0.9832\nLearning Rate: 1.00e-04\n\nEpoch 15/25\n--------------------------------------------------\nBatch 0/215, Loss: 0.0000\nBatch 50/215, Loss: 0.0000\nBatch 100/215, Loss: 0.0000\nBatch 150/215, Loss: 0.0000\nBatch 200/215, Loss: 0.0001\n\nEpoch 15 Results (time: 34.2s):\nTrain Loss: 0.0143 | Train Acc: 0.9965\nVal Loss: 0.1093 | Val Acc: 0.9860 | Val Balanced Acc: 0.9898 | Val F1: 0.9733\nLearning Rate: 1.00e-04\n✅ New best model saved! Balanced Accuracy: 0.9898\n\nEpoch 16/25\n--------------------------------------------------\nBatch 0/215, Loss: 0.0000\nBatch 50/215, Loss: 0.0000\nBatch 100/215, Loss: 0.0000\nBatch 150/215, Loss: 0.0000\nBatch 200/215, Loss: 0.0000\n\nEpoch 16 Results (time: 34.6s):\nTrain Loss: 0.0122 | Train Acc: 0.9946\nVal Loss: 0.2195 | Val Acc: 0.9895 | Val Balanced Acc: 0.9712 | Val F1: 0.9801\nLearning Rate: 1.00e-04\n\nEpoch 17/25\n--------------------------------------------------\nBatch 0/215, Loss: 0.0077\nBatch 50/215, Loss: 0.0000\nBatch 100/215, Loss: 0.0600\nBatch 150/215, Loss: 0.0000\nBatch 200/215, Loss: 0.0018\n\nEpoch 17 Results (time: 34.5s):\nTrain Loss: 0.0232 | Train Acc: 0.9961\nVal Loss: 0.1493 | Val Acc: 0.9872 | Val Balanced Acc: 0.9837 | Val F1: 0.9791\nLearning Rate: 1.00e-04\n\nEpoch 18/25\n--------------------------------------------------\nBatch 0/215, Loss: 0.0000\nBatch 50/215, Loss: 0.0000\nBatch 100/215, Loss: 0.0000\nBatch 150/215, Loss: 0.0000\nBatch 200/215, Loss: 0.0000\n\nEpoch 18 Results (time: 34.7s):\nTrain Loss: 0.0115 | Train Acc: 0.9975\nVal Loss: 0.1199 | Val Acc: 0.9895 | Val Balanced Acc: 0.9869 | Val F1: 0.9801\nLearning Rate: 1.00e-04\n\nEpoch 19/25\n--------------------------------------------------\nBatch 0/215, Loss: 0.0000\nBatch 50/215, Loss: 0.0000\nBatch 100/215, Loss: 0.0000\nBatch 150/215, Loss: 0.0000\nBatch 200/215, Loss: 0.0000\n\nEpoch 19 Results (time: 34.2s):\nTrain Loss: 0.0025 | Train Acc: 0.9985\nVal Loss: 0.1372 | Val Acc: 0.9913 | Val Balanced Acc: 0.9824 | Val F1: 0.9846\nLearning Rate: 1.00e-04\n\nEpoch 20/25\n--------------------------------------------------\nBatch 0/215, Loss: 0.0000\nBatch 50/215, Loss: 0.0000\nBatch 100/215, Loss: 0.0000\nBatch 150/215, Loss: 0.0000\nBatch 200/215, Loss: 0.0000\n\nEpoch 20 Results (time: 34.2s):\nTrain Loss: 0.0031 | Train Acc: 0.9987\nVal Loss: 0.1346 | Val Acc: 0.9889 | Val Balanced Acc: 0.9858 | Val F1: 0.9784\nLearning Rate: 5.00e-05\n\nEpoch 21/25\n--------------------------------------------------\nBatch 0/215, Loss: 0.0000\nBatch 50/215, Loss: 0.0000\nBatch 100/215, Loss: 0.0000\nBatch 150/215, Loss: 0.0000\nBatch 200/215, Loss: 0.0000\n\nEpoch 21 Results (time: 34.4s):\nTrain Loss: 0.0043 | Train Acc: 0.9984\nVal Loss: 0.1466 | Val Acc: 0.9901 | Val Balanced Acc: 0.9833 | Val F1: 0.9813\nLearning Rate: 5.00e-05\n\nEpoch 22/25\n--------------------------------------------------\nBatch 0/215, Loss: 0.0000\nBatch 50/215, Loss: 0.0000\nBatch 100/215, Loss: 0.0000\nBatch 150/215, Loss: 0.0000\nBatch 200/215, Loss: 0.0000\n\nEpoch 22 Results (time: 34.5s):\nTrain Loss: 0.0065 | Train Acc: 0.9990\nVal Loss: 0.2158 | Val Acc: 0.9913 | Val Balanced Acc: 0.9800 | Val F1: 0.9853\nLearning Rate: 5.00e-05\n\nEpoch 23/25\n--------------------------------------------------\nBatch 0/215, Loss: 0.0000\nBatch 50/215, Loss: 0.0000\nBatch 100/215, Loss: 0.0000\nBatch 150/215, Loss: 0.0000\nBatch 200/215, Loss: 0.0000\n\nEpoch 23 Results (time: 34.3s):\nTrain Loss: 0.0006 | Train Acc: 0.9999\nVal Loss: 0.1467 | Val Acc: 0.9907 | Val Balanced Acc: 0.9844 | Val F1: 0.9837\nLearning Rate: 5.00e-05\n\nEarly stopping triggered after 8 epochs without improvement\n\n============================================================\nTRAINING COMPLETED!\nBest Balanced Accuracy: 0.9898\n============================================================\n\n========================================\nFINAL VALIDATION REPORT\n========================================\n                 precision    recall  f1-score   support\n\n          COVID     0.9874    0.9843    0.9859       319\n         Normal     0.9968    0.9850    0.9908      1263\nViral Pneumonia     0.8926    1.0000    0.9433       133\n\n       accuracy                         0.9860      1715\n      macro avg     0.9589    0.9898    0.9733      1715\n   weighted avg     0.9870    0.9860    0.9862      1715\n\n\nFinal Macro F1 Score: 0.9733\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 800x600 with 2 Axes>","image/png":"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\n"},"metadata":{}},{"name":"stdout","text":"\n🎉 Process completed successfully!\n📈 Best validation score: 0.9898\n📁 Files generated:\n   - best_efficientnet_b0_chest_xray.pth\n   - confusion_matrix_efficientnet_b0.png\n   - submission_efficientnet_b0.csv\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"**ENSEMBLE RESNET50 DAN B3**","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, random_split\nfrom torchvision import transforms, models, datasets\nfrom PIL import Image\nimport pandas as pd\nimport numpy as np\nimport os\nfrom tqdm import tqdm\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n\n# ==================== CONFIGURATION ====================\nclass Config:\n    # Path ke model weights\n    EFFNET_MODEL_PATH = '/kaggle/input/effnetb3/pytorch/default/1/best_chest_xray_model(2) Effnet B-3 (9834).pth' \n    RESNET_MODEL_PATH = '/kaggle/input/resnet50/pytorch/default/1/best_chest_xray_model Resnet-50 (9912).pth'\n    \n    # Path data\n    TRAIN_DIR = '/kaggle/input/final-srifoton-25-machine-learning-competition/train/train'\n    TEST_DIR = '/kaggle/input/final-srifoton-25-machine-learning-competition/test/test'\n    \n    # Hyperparameters\n    BATCH_SIZE = 32\n    NUM_CLASSES = 3\n    IMG_SIZE = 224\n    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    \n    # Bobot ensemble\n    RESNET_WEIGHT = 0.55  \n    EFFNET_WEIGHT = 0.45\n    \n    # Label mapping\n    CLASS_NAMES = ['COVID', 'Normal', 'Viral Pneumonia']\n    MODE = 'eval'\n\n# ==================== CUSTOM MODEL ARCHITECTURES ====================\nclass EfficientNetWrapper(nn.Module):\n    \"\"\"Wrapper EfficientNet sesuai EXACT dengan training code\"\"\"\n    def __init__(self, num_classes=3):\n        super().__init__()\n        self.backbone = models.efficientnet_b3(pretrained=False)\n        num_features = self.backbone.classifier[1].in_features\n        \n        # EXACT struktur dari training code\n        self.backbone.classifier = nn.Sequential(\n            nn.Dropout(0.4),\n            nn.Linear(num_features, 768),\n            nn.BatchNorm1d(768),\n            nn.ReLU(inplace=True),\n            nn.Dropout(0.3),\n            nn.Linear(768, 384),\n            nn.BatchNorm1d(384),\n            nn.ReLU(inplace=True),\n            nn.Dropout(0.2),\n            nn.Linear(384, num_classes)\n        )\n    \n    def forward(self, x):\n        return self.backbone(x)\n\nclass ResNetWrapper(nn.Module):\n    \"\"\"Wrapper ResNet sesuai dengan training code\"\"\"\n    def __init__(self, num_classes=3):\n        super().__init__()\n        self.backbone = models.resnet50(pretrained=False)\n        num_features = self.backbone.fc.in_features\n        self.backbone.fc = nn.Identity()\n        \n        self.classifier = nn.Sequential(\n            nn.Dropout(0.5),\n            nn.Linear(num_features, 512),\n            nn.BatchNorm1d(512),\n            nn.ReLU(inplace=True),\n            nn.Dropout(0.3),\n            nn.Linear(512, 256),\n            nn.BatchNorm1d(256),\n            nn.ReLU(inplace=True),\n            nn.Dropout(0.2),\n            nn.Linear(256, num_classes)\n        )\n    \n    def forward(self, x):\n        features = self.backbone(x)\n        return self.classifier(features)\n\n# ==================== DATASET ====================\nclass TestDataset(torch.utils.data.Dataset):\n    def __init__(self, test_dir, transform=None):\n        self.test_dir = test_dir\n        self.transform = transform\n        self.image_files = sorted([f for f in os.listdir(test_dir) \n                                   if f.lower().endswith(('.png', '.jpg', '.jpeg'))])\n        \n    def __len__(self):\n        return len(self.image_files)\n    \n    def __getitem__(self, idx):\n        img_name = self.image_files[idx]\n        img_path = os.path.join(self.test_dir, img_name)\n        image = Image.open(img_path).convert('RGB')\n        \n        if self.transform:\n            image = self.transform(image)\n        \n        img_id = os.path.splitext(img_name)[0]\n        return image, img_id\n\ndef create_validation_split(train_dir, transform, val_split=0.2):\n    print(f\"\\n📂 Loading train dataset...\")\n    full_dataset = datasets.ImageFolder(root=train_dir, transform=transform)\n    class_names = full_dataset.classes\n    \n    print(f\"✓ Total samples: {len(full_dataset)}\")\n    print(f\"✓ Classes: {class_names}\")\n    \n    train_size = int(0.8 * len(full_dataset))\n    val_size = len(full_dataset) - train_size\n    \n    _, val_dataset = random_split(\n        full_dataset, \n        [train_size, val_size],\n        generator=torch.Generator().manual_seed(42)\n    )\n    \n    print(f\"✓ Validation samples: {len(val_dataset)} (20%)\")\n    \n    val_loader = DataLoader(\n        val_dataset,\n        batch_size=Config.BATCH_SIZE,\n        shuffle=False,\n        num_workers=2,\n        pin_memory=True\n    )\n    \n    return val_loader, class_names\n\n# ==================== MODEL LOADING ====================\ndef load_efficientnet_b3(model_path, num_classes=3, device='cuda'):\n    print(f\"\\n🔄 Loading EfficientNet-B3...\")\n    \n    checkpoint = torch.load(model_path, map_location=device, weights_only=False)\n    \n    if isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:\n        state_dict = checkpoint['model_state_dict']\n    else:\n        state_dict = checkpoint\n    \n    print(\"  → Using custom wrapper architecture (768→384→classes)\")\n    model = EfficientNetWrapper(num_classes=num_classes)\n    model.load_state_dict(state_dict)\n    model = model.to(device)\n    model.eval()\n    \n    print(f\"✓ EfficientNet-B3 loaded successfully\")\n    return model\n\ndef load_resnet50(model_path, num_classes=3, device='cuda'):\n    print(f\"\\n🔄 Loading ResNet-50...\")\n    \n    checkpoint = torch.load(model_path, map_location=device, weights_only=False)\n    \n    if isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:\n        state_dict = checkpoint['model_state_dict']\n    else:\n        state_dict = checkpoint\n    \n    # Cek apakah pakai wrapper\n    sample_key = list(state_dict.keys())[0]\n    \n    if 'backbone' in sample_key:\n        print(\"  → Detected: Custom wrapper architecture\")\n        model = ResNetWrapper(num_classes=num_classes)\n    else:\n        print(\"  → Detected: Standard torchvision architecture\")\n        model = models.resnet50(pretrained=False)\n        in_features = model.fc.in_features\n        model.fc = nn.Linear(in_features, num_classes)\n    \n    model.load_state_dict(state_dict)\n    model = model.to(device)\n    model.eval()\n    \n    print(f\"✓ ResNet-50 loaded successfully\")\n    return model\n\n# ==================== INFERENCE ====================\ndef get_predictions(model, dataloader, device, return_labels=False):\n    all_probs = []\n    all_ids_or_labels = []\n    \n    with torch.no_grad():\n        for batch in tqdm(dataloader, desc=\"  Predicting\", leave=False):\n            if return_labels:\n                images, labels = batch\n                images = images.to(device)\n            else:\n                images, img_ids = batch\n                images = images.to(device)\n            \n            outputs = model(images)\n            probs = torch.softmax(outputs, dim=1)\n            \n            all_probs.append(probs.cpu().numpy())\n            \n            if return_labels:\n                all_ids_or_labels.extend(labels.cpu().numpy())\n            else:\n                all_ids_or_labels.extend(img_ids)\n    \n    all_probs = np.vstack(all_probs)\n    return all_probs, all_ids_or_labels\n\n# ==================== ENSEMBLE ====================\ndef ensemble_soft_voting(probs1, probs2, weight1, weight2):\n    ensemble_probs = weight1 * probs1 + weight2 * probs2\n    predictions = np.argmax(ensemble_probs, axis=1)\n    return predictions, ensemble_probs\n\n# ==================== EVALUATION ====================\ndef evaluate_ensemble(effnet_probs, resnet_probs, true_labels, weight1, weight2):\n    print(\"\\n\" + \"=\"*60)\n    print(\"EVALUATION ON VALIDATION SET\")\n    print(\"=\"*60)\n    \n    effnet_preds = np.argmax(effnet_probs, axis=1)\n    resnet_preds = np.argmax(resnet_probs, axis=1)\n    ensemble_preds, _ = ensemble_soft_voting(effnet_probs, resnet_probs, weight1, weight2)\n    \n    effnet_acc = accuracy_score(true_labels, effnet_preds) * 100\n    resnet_acc = accuracy_score(true_labels, resnet_preds) * 100\n    ensemble_acc = accuracy_score(true_labels, ensemble_preds) * 100\n    \n    print(f\"\\n📊 ACCURACY COMPARISON:\")\n    print(f\"  EfficientNet-B3 : {effnet_acc:.2f}%\")\n    print(f\"  ResNet-50       : {resnet_acc:.2f}%\")\n    print(f\"  ENSEMBLE        : {ensemble_acc:.2f}%\")\n    \n    improvement = ensemble_acc - max(effnet_acc, resnet_acc)\n    if improvement > 0:\n        print(f\"\\n✅ Ensemble Improvement: +{improvement:.2f}%\")\n    else:\n        print(f\"\\n⚠️  Ensemble tidak meningkat: {improvement:.2f}%\")\n    \n    print(f\"\\n📋 CLASSIFICATION REPORT (ENSEMBLE):\")\n    print(classification_report(true_labels, ensemble_preds, \n                               target_names=Config.CLASS_NAMES, \n                               digits=4))\n    \n    print(f\"\\n🔢 CONFUSION MATRIX (ENSEMBLE):\")\n    cm = confusion_matrix(true_labels, ensemble_preds)\n    print(\"\\n           Predicted\")\n    print(f\"           {Config.CLASS_NAMES[0]:^10} {Config.CLASS_NAMES[1]:^10} {Config.CLASS_NAMES[2]:^10}\")\n    for i, class_name in enumerate(Config.CLASS_NAMES):\n        print(f\"Actual {class_name:10}\", end=\" \")\n        for j in range(len(Config.CLASS_NAMES)):\n            print(f\"{cm[i][j]:^10}\", end=\" \")\n        print()\n    \n    return ensemble_acc\n\n# ==================== SUBMISSION ====================\ndef create_submission(ids, predictions, filename='ensemble_effnet_resnet_submission.csv'):\n    class_to_idx = {name: idx for idx, name in enumerate(Config.CLASS_NAMES)}\n    \n    if isinstance(predictions[0], str):\n        numeric_predictions = [class_to_idx[pred] for pred in predictions]\n    else:\n        numeric_predictions = predictions\n    \n    submission_df = pd.DataFrame({\n        'Id': ids,\n        'Predicted': numeric_predictions\n    })\n    \n    submission_df = submission_df.sort_values('Id').reset_index(drop=True)\n    submission_df.to_csv(filename, index=False)\n    \n    print(f\"\\n✅ Submission saved: {filename}\")\n    print(f\"   Total predictions: {len(submission_df)}\")\n    \n    print(\"\\n📊 Distribusi Prediksi:\")\n    for class_idx, class_name in enumerate(Config.CLASS_NAMES):\n        count = (submission_df['Predicted'] == class_idx).sum()\n        percentage = (count / len(submission_df)) * 100\n        print(f\"   {class_name} (Class {class_idx}): {count} ({percentage:.2f}%)\")\n    \n    print(\"\\n📄 Sample (10 baris pertama):\")\n    print(submission_df.head(10).to_string(index=False))\n    \n    return submission_df\n\n# ==================== MAIN ====================\ndef main():\n    print(\"=\"*60)\n    print(\"ENSEMBLE MODEL - SOFT VOTING\")\n    print(\"EfficientNet-B3 + ResNet-50\")\n    print(\"=\"*60)\n    print(f\"Device: {Config.DEVICE}\")\n\n    transform = transforms.Compose([\n        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], \n                           std=[0.229, 0.224, 0.225])\n    ])\n    \n    # Load models\n    print(\"\\n\" + \"=\"*60)\n    print(\"[STEP 1] LOADING MODELS\")\n    print(\"=\"*60)\n    effnet_model = load_efficientnet_b3(Config.EFFNET_MODEL_PATH, \n                                        Config.NUM_CLASSES, \n                                        Config.DEVICE)\n    resnet_model = load_resnet50(Config.RESNET_MODEL_PATH, \n                                 Config.NUM_CLASSES, \n                                 Config.DEVICE)\n    \n    # ==================== EVALUATION MODE ====================\n    print(\"\\n\" + \"=\"*60)\n    print(\"[STEP 2] EVALUATION ON VALIDATION SET\")\n    print(\"=\"*60)\n    \n    val_loader, class_names = create_validation_split(\n        Config.TRAIN_DIR, transform, val_split=0.2\n    )\n    \n    print(\"\\n[2.1] Getting predictions from EfficientNet-B3...\")\n    effnet_probs, true_labels = get_predictions(\n        effnet_model, val_loader, \n        Config.DEVICE, return_labels=True\n    )\n    \n    print(\"\\n[2.2] Getting predictions from ResNet-50...\")\n    resnet_probs, _ = get_predictions(\n        resnet_model, val_loader, \n        Config.DEVICE, return_labels=True\n    )\n    \n    print(\"\\n[2.3] Evaluating ensemble...\")\n    print(f\"      Weights: EfficientNet={Config.EFFNET_WEIGHT}, ResNet={Config.RESNET_WEIGHT}\")\n    \n    ensemble_acc = evaluate_ensemble(\n        effnet_probs, resnet_probs, \n        true_labels,\n        Config.EFFNET_WEIGHT, \n        Config.RESNET_WEIGHT\n    )\n    \n    print(\"\\n\" + \"=\"*60)\n    print(f\"ENSEMBLE ACCURACY ON VALIDATION: {ensemble_acc:.2f}%\")\n    print(\"=\"*60)\n    \n    # ==================== SUBMISSION MODE ====================\n    print(\"\\n\" + \"=\"*60)\n    print(\"[STEP 3] GENERATING SUBMISSION FILE\")\n    print(\"=\"*60)\n    \n    test_dataset = TestDataset(Config.TEST_DIR, transform=transform)\n    test_loader = DataLoader(\n        test_dataset, \n        batch_size=Config.BATCH_SIZE, \n        shuffle=False,\n        num_workers=2,\n        pin_memory=True\n    )\n    print(f\"Total test images: {len(test_dataset)}\")\n    \n    print(\"\\n[3.1] Getting predictions from EfficientNet-B3...\")\n    effnet_probs_test, img_ids = get_predictions(effnet_model, test_loader, Config.DEVICE)\n    \n    print(\"\\n[3.2] Getting predictions from ResNet-50...\")\n    resnet_probs_test, _ = get_predictions(resnet_model, test_loader, Config.DEVICE)\n    \n    print(\"\\n[3.3] Ensemble soft voting...\")\n    print(f\"      Weights: EfficientNet={Config.EFFNET_WEIGHT}, ResNet={Config.RESNET_WEIGHT}\")\n    \n    final_predictions, _ = ensemble_soft_voting(\n        effnet_probs_test, \n        resnet_probs_test,\n        Config.EFFNET_WEIGHT,\n        Config.RESNET_WEIGHT\n    )\n    \n    print(\"\\n[3.4] Creating submission file...\")\n    create_submission(img_ids, final_predictions)\n    \n    # ==================== FINAL SUMMARY ====================\n    print(\"\\n\" + \"=\"*60)\n    print(\"ENSEMBLE COMPLETE!\")\n    print(\"=\"*60)\n    print(f\"\\nValidation Accuracy: {ensemble_acc:.2f}%\")\n    print(f\"\\nFiles generated:\")\n    print(f\"  - ensemble_effnet_resnet_submission.csv (ready for Kaggle)\")\n    print(\"\\nNext steps:\")\n    print(f\"  1. Review validation accuracy above\")\n    print(f\"  2. If satisfied, upload CSV to Kaggle\")\n    print(f\"  3. If not satisfied, adjust weights (RESNET_WEIGHT/EFFNET_WEIGHT)\")\n    print(\"=\"*60)\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-01T03:59:18.695910Z","iopub.execute_input":"2025-10-01T03:59:18.696191Z","iopub.status.idle":"2025-10-01T04:01:08.374022Z","shell.execute_reply.started":"2025-10-01T03:59:18.696168Z","shell.execute_reply":"2025-10-01T04:01:08.373251Z"},"jupyter":{"source_hidden":true,"outputs_hidden":true},"collapsed":true},"outputs":[{"name":"stdout","text":"============================================================\nENSEMBLE MODEL - SOFT VOTING\nEfficientNet-B3 + ResNet-50\n============================================================\nDevice: cuda\n\n============================================================\n[STEP 1] LOADING MODELS\n============================================================\n\n🔄 Loading EfficientNet-B3...\n  → Using custom wrapper architecture (768→384→classes)\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"✓ EfficientNet-B3 loaded successfully\n\n🔄 Loading ResNet-50...\n  → Detected: Custom wrapper architecture\n✓ ResNet-50 loaded successfully\n\n============================================================\n[STEP 2] EVALUATION ON VALIDATION SET\n============================================================\n\n📂 Loading train dataset...\n✓ Total samples: 8572\n✓ Classes: ['COVID', 'Normal', 'Viral Pneumonia']\n✓ Validation samples: 1715 (20%)\n\n[2.1] Getting predictions from EfficientNet-B3...\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"\n[2.2] Getting predictions from ResNet-50...\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"\n[2.3] Evaluating ensemble...\n      Weights: EfficientNet=0.45, ResNet=0.55\n\n============================================================\nEVALUATION ON VALIDATION SET\n============================================================\n\n📊 ACCURACY COMPARISON:\n  EfficientNet-B3 : 91.72%\n  ResNet-50       : 99.65%\n  ENSEMBLE        : 99.77%\n\n✅ Ensemble Improvement: +0.12%\n\n📋 CLASSIFICATION REPORT (ENSEMBLE):\n                 precision    recall  f1-score   support\n\n          COVID     0.9905    1.0000    0.9952       313\n         Normal     1.0000    0.9969    0.9984      1279\nViral Pneumonia     0.9919    1.0000    0.9960       123\n\n       accuracy                         0.9977      1715\n      macro avg     0.9941    0.9990    0.9965      1715\n   weighted avg     0.9977    0.9977    0.9977      1715\n\n\n🔢 CONFUSION MATRIX (ENSEMBLE):\n\n           Predicted\n             COVID      Normal   Viral Pneumonia\nActual COVID         313         0          0      \nActual Normal         3         1275        1      \nActual Viral Pneumonia     0          0         123     \n\n============================================================\nENSEMBLE ACCURACY ON VALIDATION: 99.77%\n============================================================\n\n============================================================\n[STEP 3] GENERATING SUBMISSION FILE\n============================================================\nTotal test images: 6382\n\n[3.1] Getting predictions from EfficientNet-B3...\n","output_type":"stream"},{"name":"stderr","text":"                                                               \r","output_type":"stream"},{"name":"stdout","text":"\n[3.2] Getting predictions from ResNet-50...\n","output_type":"stream"},{"name":"stderr","text":"                                                               ","output_type":"stream"},{"name":"stdout","text":"\n[3.3] Ensemble soft voting...\n      Weights: EfficientNet=0.45, ResNet=0.55\n\n[3.4] Creating submission file...\n\n✅ Submission saved: ensemble_effnet_resnet_submission.csv\n   Total predictions: 6382\n\n📊 Distribusi Prediksi:\n   COVID (Class 0): 1943 (30.45%)\n   Normal (Class 1): 3751 (58.77%)\n   Viral Pneumonia (Class 2): 688 (10.78%)\n\n📄 Sample (10 baris pertama):\n       Id  Predicted\ntest_0001          1\ntest_0002          0\ntest_0003          0\ntest_0004          1\ntest_0005          1\ntest_0006          1\ntest_0007          1\ntest_0008          1\ntest_0009          0\ntest_0010          1\n\n============================================================\nENSEMBLE COMPLETE!\n============================================================\n\nValidation Accuracy: 99.77%\n\nFiles generated:\n  - ensemble_effnet_resnet_submission.csv (ready for Kaggle)\n\nNext steps:\n  1. Review validation accuracy above\n  2. If satisfied, upload CSV to Kaggle\n  3. If not satisfied, adjust weights (RESNET_WEIGHT/EFFNET_WEIGHT)\n============================================================\n","output_type":"stream"},{"name":"stderr","text":"\r","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"**ENSEMBLE RESNET 50 DAN B0**","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, random_split\nfrom torchvision import transforms, models, datasets\nfrom PIL import Image\nimport pandas as pd\nimport numpy as np\nimport os\nfrom tqdm import tqdm\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n\n# ==================== CONFIGURATION ====================\nclass Config:\n    # Path ke model weights\n    EFFNET_MODEL_PATH = '/kaggle/input/effnet-b0/pytorch/default/1/best_efficientnet_b0_chest_xray(98.98).pth' \n    RESNET_MODEL_PATH = '/kaggle/input/resnet50/pytorch/default/1/best_chest_xray_model Resnet-50 (9912).pth'\n    \n    # Path data\n    TRAIN_DIR = '/kaggle/input/final-srifoton-25-machine-learning-competition/train/train'\n    TEST_DIR = '/kaggle/input/final-srifoton-25-machine-learning-competition/test/test'\n    \n    # Hyperparameters\n    BATCH_SIZE = 32\n    NUM_CLASSES = 3\n    IMG_SIZE = 224\n    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    \n    # Bobot ensemble\n    RESNET_WEIGHT = 0.55  \n    EFFNET_WEIGHT = 0.45\n    \n    # Label mapping\n    CLASS_NAMES = ['COVID', 'Normal', 'Viral Pneumonia']\n    MODE = 'eval'\n\n# ==================== CUSTOM MODEL ARCHITECTURES ====================\nclass EfficientNetB0Wrapper(nn.Module):\n    \"\"\"EXACT wrapper sesuai training code Anda: 512→256→3\"\"\"\n    def __init__(self, num_classes=3):\n        super().__init__()\n        # EfficientNet-B0 backbone\n        backbone = models.efficientnet_b0(pretrained=False)\n        num_features = backbone.classifier[1].in_features  # 1280 for B0\n        backbone.classifier = nn.Identity()\n        self.backbone = backbone\n        \n        # EXACT struktur dari training code Anda\n        self.classifier = nn.Sequential(\n            nn.Dropout(0.5),\n            nn.Linear(num_features, 512),\n            nn.BatchNorm1d(512),\n            nn.ReLU(inplace=True),\n            nn.Dropout(0.3),\n            nn.Linear(512, 256),\n            nn.BatchNorm1d(256),\n            nn.ReLU(inplace=True),\n            nn.Dropout(0.2),\n            nn.Linear(256, num_classes)\n        )\n    \n    def forward(self, x):\n        features = self.backbone(x)\n        return self.classifier(features)\n\nclass ResNetWrapper(nn.Module):\n    \"\"\"Wrapper ResNet sesuai dengan training code\"\"\"\n    def __init__(self, num_classes=3):\n        super().__init__()\n        self.backbone = models.resnet50(pretrained=False)\n        num_features = self.backbone.fc.in_features\n        self.backbone.fc = nn.Identity()\n        \n        self.classifier = nn.Sequential(\n            nn.Dropout(0.5),\n            nn.Linear(num_features, 512),\n            nn.BatchNorm1d(512),\n            nn.ReLU(inplace=True),\n            nn.Dropout(0.3),\n            nn.Linear(512, 256),\n            nn.BatchNorm1d(256),\n            nn.ReLU(inplace=True),\n            nn.Dropout(0.2),\n            nn.Linear(256, num_classes)\n        )\n    \n    def forward(self, x):\n        features = self.backbone(x)\n        return self.classifier(features)\n\n# ==================== DATASET ====================\nclass TestDataset(torch.utils.data.Dataset):\n    def __init__(self, test_dir, transform=None):\n        self.test_dir = test_dir\n        self.transform = transform\n        self.image_files = sorted([f for f in os.listdir(test_dir) \n                                   if f.lower().endswith(('.png', '.jpg', '.jpeg'))])\n        \n    def __len__(self):\n        return len(self.image_files)\n    \n    def __getitem__(self, idx):\n        img_name = self.image_files[idx]\n        img_path = os.path.join(self.test_dir, img_name)\n        image = Image.open(img_path).convert('RGB')\n        \n        if self.transform:\n            image = self.transform(image)\n        \n        img_id = os.path.splitext(img_name)[0]\n        return image, img_id\n\ndef create_validation_split(train_dir, transform, val_split=0.2):\n    print(f\"\\n📂 Loading train dataset...\")\n    full_dataset = datasets.ImageFolder(root=train_dir, transform=transform)\n    class_names = full_dataset.classes\n    \n    print(f\"✓ Total samples: {len(full_dataset)}\")\n    print(f\"✓ Classes: {class_names}\")\n    \n    train_size = int(0.8 * len(full_dataset))\n    val_size = len(full_dataset) - train_size\n    \n    _, val_dataset = random_split(\n        full_dataset, \n        [train_size, val_size],\n        generator=torch.Generator().manual_seed(42)\n    )\n    \n    print(f\"✓ Validation samples: {len(val_dataset)} (20%)\")\n    \n    val_loader = DataLoader(\n        val_dataset,\n        batch_size=Config.BATCH_SIZE,\n        shuffle=False,\n        num_workers=2,\n        pin_memory=True\n    )\n    \n    return val_loader, class_names\n\n# ==================== MODEL LOADING ====================\ndef load_efficientnet_b0(model_path, num_classes=3, device='cuda'):\n    print(f\"\\n🔄 Loading EfficientNet-B0...\")\n    \n    checkpoint = torch.load(model_path, map_location=device, weights_only=False)\n    \n    # Handle different checkpoint formats\n    if isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:\n        state_dict = checkpoint['model_state_dict']\n        print(f\"  → Checkpoint info: Epoch {checkpoint.get('epoch', 'N/A')}, \"\n              f\"Balanced Acc: {checkpoint.get('best_balanced_acc', 'N/A'):.4f}\")\n    else:\n        state_dict = checkpoint\n    \n    print(\"  → Using custom wrapper architecture (512→256→classes)\")\n    model = EfficientNetB0Wrapper(num_classes=num_classes)\n    \n    # Load state dict\n    model.load_state_dict(state_dict, strict=True)\n    model = model.to(device)\n    model.eval()\n    \n    print(f\"✓ EfficientNet-B0 loaded successfully\")\n    return model\n\ndef load_resnet50(model_path, num_classes=3, device='cuda'):\n    print(f\"\\n🔄 Loading ResNet-50...\")\n    \n    checkpoint = torch.load(model_path, map_location=device, weights_only=False)\n    \n    if isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:\n        state_dict = checkpoint['model_state_dict']\n    else:\n        state_dict = checkpoint\n    \n    # Cek apakah pakai wrapper\n    sample_key = list(state_dict.keys())[0]\n    \n    if 'backbone' in sample_key:\n        print(\"  → Detected: Custom wrapper architecture\")\n        model = ResNetWrapper(num_classes=num_classes)\n    else:\n        print(\"  → Detected: Standard torchvision architecture\")\n        model = models.resnet50(pretrained=False)\n        in_features = model.fc.in_features\n        model.fc = nn.Linear(in_features, num_classes)\n    \n    model.load_state_dict(state_dict)\n    model = model.to(device)\n    model.eval()\n    \n    print(f\"✓ ResNet-50 loaded successfully\")\n    return model\n\n# ==================== INFERENCE ====================\ndef get_predictions(model, dataloader, device, return_labels=False):\n    all_probs = []\n    all_ids_or_labels = []\n    \n    with torch.no_grad():\n        for batch in tqdm(dataloader, desc=\"  Predicting\", leave=False):\n            if return_labels:\n                images, labels = batch\n                images = images.to(device)\n            else:\n                images, img_ids = batch\n                images = images.to(device)\n            \n            outputs = model(images)\n            probs = torch.softmax(outputs, dim=1)\n            \n            all_probs.append(probs.cpu().numpy())\n            \n            if return_labels:\n                all_ids_or_labels.extend(labels.cpu().numpy())\n            else:\n                all_ids_or_labels.extend(img_ids)\n    \n    all_probs = np.vstack(all_probs)\n    return all_probs, all_ids_or_labels\n\n# ==================== ENSEMBLE ====================\ndef ensemble_soft_voting(probs1, probs2, weight1, weight2):\n    ensemble_probs = weight1 * probs1 + weight2 * probs2\n    predictions = np.argmax(ensemble_probs, axis=1)\n    return predictions, ensemble_probs\n\n# ==================== EVALUATION ====================\ndef evaluate_ensemble(effnet_probs, resnet_probs, true_labels, weight1, weight2):\n    print(\"\\n\" + \"=\"*60)\n    print(\"EVALUATION ON VALIDATION SET\")\n    print(\"=\"*60)\n    \n    effnet_preds = np.argmax(effnet_probs, axis=1)\n    resnet_preds = np.argmax(resnet_probs, axis=1)\n    ensemble_preds, _ = ensemble_soft_voting(effnet_probs, resnet_probs, weight1, weight2)\n    \n    effnet_acc = accuracy_score(true_labels, effnet_preds) * 100\n    resnet_acc = accuracy_score(true_labels, resnet_preds) * 100\n    ensemble_acc = accuracy_score(true_labels, ensemble_preds) * 100\n    \n    print(f\"\\n📊 ACCURACY COMPARISON:\")\n    print(f\"  EfficientNet-B0 : {effnet_acc:.2f}%\")\n    print(f\"  ResNet-50       : {resnet_acc:.2f}%\")\n    print(f\"  ENSEMBLE        : {ensemble_acc:.2f}%\")\n    \n    improvement = ensemble_acc - max(effnet_acc, resnet_acc)\n    if improvement > 0:\n        print(f\"\\n✅ Ensemble Improvement: +{improvement:.2f}%\")\n    else:\n        print(f\"\\n⚠️  Ensemble tidak meningkat: {improvement:.2f}%\")\n    \n    print(f\"\\n📋 CLASSIFICATION REPORT (ENSEMBLE):\")\n    print(classification_report(true_labels, ensemble_preds, \n                               target_names=Config.CLASS_NAMES, \n                               digits=4))\n    \n    print(f\"\\n🔢 CONFUSION MATRIX (ENSEMBLE):\")\n    cm = confusion_matrix(true_labels, ensemble_preds)\n    print(\"\\n           Predicted\")\n    print(f\"           {Config.CLASS_NAMES[0]:^10} {Config.CLASS_NAMES[1]:^10} {Config.CLASS_NAMES[2]:^10}\")\n    for i, class_name in enumerate(Config.CLASS_NAMES):\n        print(f\"Actual {class_name:10}\", end=\" \")\n        for j in range(len(Config.CLASS_NAMES)):\n            print(f\"{cm[i][j]:^10}\", end=\" \")\n        print()\n    \n    return ensemble_acc\n\n# ==================== SUBMISSION ====================\ndef create_submission(ids, predictions, filename='ensemble_effnetB0_resnet50_submission.csv'):\n    class_to_idx = {name: idx for idx, name in enumerate(Config.CLASS_NAMES)}\n    \n    if isinstance(predictions[0], str):\n        numeric_predictions = [class_to_idx[pred] for pred in predictions]\n    else:\n        numeric_predictions = predictions\n    \n    submission_df = pd.DataFrame({\n        'Id': ids,\n        'Predicted': numeric_predictions\n    })\n    \n    submission_df = submission_df.sort_values('Id').reset_index(drop=True)\n    submission_df.to_csv(filename, index=False)\n    \n    print(f\"\\n✅ Submission saved: {filename}\")\n    print(f\"   Total predictions: {len(submission_df)}\")\n    \n    print(\"\\n📊 Distribusi Prediksi:\")\n    for class_idx, class_name in enumerate(Config.CLASS_NAMES):\n        count = (submission_df['Predicted'] == class_idx).sum()\n        percentage = (count / len(submission_df)) * 100\n        print(f\"   {class_name} (Class {class_idx}): {count} ({percentage:.2f}%)\")\n    \n    print(\"\\n📄 Sample (10 baris pertama):\")\n    print(submission_df.head(10).to_string(index=False))\n    \n    return submission_df\n\n# ==================== MAIN ====================\ndef main():\n    print(\"=\"*60)\n    print(\"ENSEMBLE MODEL - SOFT VOTING\")\n    print(\"EfficientNet-B0 + ResNet-50\")\n    print(\"=\"*60)\n    print(f\"Device: {Config.DEVICE}\")\n\n    # Transform sesuai training code Anda\n    transform = transforms.Compose([\n        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], \n                           std=[0.229, 0.224, 0.225])\n    ])\n    \n    # Load models\n    print(\"\\n\" + \"=\"*60)\n    print(\"[STEP 1] LOADING MODELS\")\n    print(\"=\"*60)\n    effnet_model = load_efficientnet_b0(Config.EFFNET_MODEL_PATH, \n                                        Config.NUM_CLASSES, \n                                        Config.DEVICE)\n    resnet_model = load_resnet50(Config.RESNET_MODEL_PATH, \n                                 Config.NUM_CLASSES, \n                                 Config.DEVICE)\n    \n    # ==================== EVALUATION MODE ====================\n    print(\"\\n\" + \"=\"*60)\n    print(\"[STEP 2] EVALUATION ON VALIDATION SET\")\n    print(\"=\"*60)\n    \n    val_loader, class_names = create_validation_split(\n        Config.TRAIN_DIR, transform, val_split=0.2\n    )\n    \n    print(\"\\n[2.1] Getting predictions from EfficientNet-B0...\")\n    effnet_probs, true_labels = get_predictions(\n        effnet_model, val_loader, \n        Config.DEVICE, return_labels=True\n    )\n    \n    print(\"\\n[2.2] Getting predictions from ResNet-50...\")\n    resnet_probs, _ = get_predictions(\n        resnet_model, val_loader, \n        Config.DEVICE, return_labels=True\n    )\n    \n    print(\"\\n[2.3] Evaluating ensemble...\")\n    print(f\"      Weights: EfficientNet={Config.EFFNET_WEIGHT}, ResNet={Config.RESNET_WEIGHT}\")\n    \n    ensemble_acc = evaluate_ensemble(\n        effnet_probs, resnet_probs, \n        true_labels,\n        Config.EFFNET_WEIGHT, \n        Config.RESNET_WEIGHT\n    )\n    \n    print(\"\\n\" + \"=\"*60)\n    print(f\"ENSEMBLE ACCURACY ON VALIDATION: {ensemble_acc:.2f}%\")\n    print(\"=\"*60)\n    \n    # ==================== SUBMISSION MODE ====================\n    print(\"\\n\" + \"=\"*60)\n    print(\"[STEP 3] GENERATING SUBMISSION FILE\")\n    print(\"=\"*60)\n    \n    test_dataset = TestDataset(Config.TEST_DIR, transform=transform)\n    test_loader = DataLoader(\n        test_dataset, \n        batch_size=Config.BATCH_SIZE, \n        shuffle=False,\n        num_workers=2,\n        pin_memory=True\n    )\n    print(f\"Total test images: {len(test_dataset)}\")\n    \n    print(\"\\n[3.1] Getting predictions from EfficientNet-B0...\")\n    effnet_probs_test, img_ids = get_predictions(effnet_model, test_loader, Config.DEVICE)\n    \n    print(\"\\n[3.2] Getting predictions from ResNet-50...\")\n    resnet_probs_test, _ = get_predictions(resnet_model, test_loader, Config.DEVICE)\n    \n    print(\"\\n[3.3] Ensemble soft voting...\")\n    print(f\"      Weights: EfficientNet={Config.EFFNET_WEIGHT}, ResNet={Config.RESNET_WEIGHT}\")\n    \n    final_predictions, _ = ensemble_soft_voting(\n        effnet_probs_test, \n        resnet_probs_test,\n        Config.EFFNET_WEIGHT,\n        Config.RESNET_WEIGHT\n    )\n    \n    print(\"\\n[3.4] Creating submission file...\")\n    create_submission(img_ids, final_predictions)\n    \n    # ==================== FINAL SUMMARY ====================\n    print(\"\\n\" + \"=\"*60)\n    print(\"ENSEMBLE COMPLETE!\")\n    print(\"=\"*60)\n    print(f\"\\nValidation Accuracy: {ensemble_acc:.2f}%\")\n    print(f\"\\nFiles generated:\")\n    print(f\"  - ensemble_effnetB0_resnet50_submission.csv (ready for Kaggle)\")\n    print(\"\\nNext steps:\")\n    print(f\"  1. Review validation accuracy above\")\n    print(f\"  2. If satisfied, upload CSV to Kaggle\")\n    print(f\"  3. If not satisfied, adjust weights (RESNET_WEIGHT/EFFNET_WEIGHT)\")\n    print(\"=\"*60)\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-01T04:09:58.439165Z","iopub.execute_input":"2025-10-01T04:09:58.439843Z","iopub.status.idle":"2025-10-01T04:10:49.184397Z","shell.execute_reply.started":"2025-10-01T04:09:58.439818Z","shell.execute_reply":"2025-10-01T04:10:49.183531Z"},"jupyter":{"source_hidden":true,"outputs_hidden":true},"collapsed":true},"outputs":[{"name":"stdout","text":"============================================================\nENSEMBLE MODEL - SOFT VOTING\nEfficientNet-B0 + ResNet-50\n============================================================\nDevice: cuda\n\n============================================================\n[STEP 1] LOADING MODELS\n============================================================\n\n🔄 Loading EfficientNet-B0...\n  → Checkpoint info: Epoch 14, Balanced Acc: 0.9898\n  → Using custom wrapper architecture (512→256→classes)\n✓ EfficientNet-B0 loaded successfully\n\n🔄 Loading ResNet-50...\n  → Detected: Custom wrapper architecture\n✓ ResNet-50 loaded successfully\n\n============================================================\n[STEP 2] EVALUATION ON VALIDATION SET\n============================================================\n\n📂 Loading train dataset...\n✓ Total samples: 8572\n✓ Classes: ['COVID', 'Normal', 'Viral Pneumonia']\n✓ Validation samples: 1715 (20%)\n\n[2.1] Getting predictions from EfficientNet-B0...\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"\n[2.2] Getting predictions from ResNet-50...\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"\n[2.3] Evaluating ensemble...\n      Weights: EfficientNet=0.45, ResNet=0.55\n\n============================================================\nEVALUATION ON VALIDATION SET\n============================================================\n\n📊 ACCURACY COMPARISON:\n  EfficientNet-B0 : 99.18%\n  ResNet-50       : 99.65%\n  ENSEMBLE        : 99.59%\n\n⚠️  Ensemble tidak meningkat: -0.06%\n\n📋 CLASSIFICATION REPORT (ENSEMBLE):\n                 precision    recall  f1-score   support\n\n          COVID     0.9905    0.9968    0.9936       313\n         Normal     0.9992    0.9953    0.9973      1279\nViral Pneumonia     0.9762    1.0000    0.9880       123\n\n       accuracy                         0.9959      1715\n      macro avg     0.9886    0.9974    0.9929      1715\n   weighted avg     0.9960    0.9959    0.9959      1715\n\n\n🔢 CONFUSION MATRIX (ENSEMBLE):\n\n           Predicted\n             COVID      Normal   Viral Pneumonia\nActual COVID         312         1          0      \nActual Normal         3         1273        3      \nActual Viral Pneumonia     0          0         123     \n\n============================================================\nENSEMBLE ACCURACY ON VALIDATION: 99.59%\n============================================================\n\n============================================================\n[STEP 3] GENERATING SUBMISSION FILE\n============================================================\nTotal test images: 6382\n\n[3.1] Getting predictions from EfficientNet-B0...\n","output_type":"stream"},{"name":"stderr","text":"                                                               \r","output_type":"stream"},{"name":"stdout","text":"\n[3.2] Getting predictions from ResNet-50...\n","output_type":"stream"},{"name":"stderr","text":"                                                               ","output_type":"stream"},{"name":"stdout","text":"\n[3.3] Ensemble soft voting...\n      Weights: EfficientNet=0.45, ResNet=0.55\n\n[3.4] Creating submission file...\n\n✅ Submission saved: ensemble_effnetB0_resnet50_submission.csv\n   Total predictions: 6382\n\n📊 Distribusi Prediksi:\n   COVID (Class 0): 1953 (30.60%)\n   Normal (Class 1): 3723 (58.34%)\n   Viral Pneumonia (Class 2): 706 (11.06%)\n\n📄 Sample (10 baris pertama):\n       Id  Predicted\ntest_0001          1\ntest_0002          0\ntest_0003          0\ntest_0004          1\ntest_0005          1\ntest_0006          1\ntest_0007          1\ntest_0008          1\ntest_0009          0\ntest_0010          1\n\n============================================================\nENSEMBLE COMPLETE!\n============================================================\n\nValidation Accuracy: 99.59%\n\nFiles generated:\n  - ensemble_effnetB0_resnet50_submission.csv (ready for Kaggle)\n\nNext steps:\n  1. Review validation accuracy above\n  2. If satisfied, upload CSV to Kaggle\n  3. If not satisfied, adjust weights (RESNET_WEIGHT/EFFNET_WEIGHT)\n============================================================\n","output_type":"stream"},{"name":"stderr","text":"\r","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"**ENSEMBLE RESNET 50, B0, DAN B3**","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, random_split\nfrom torchvision import transforms, models, datasets\nfrom PIL import Image\nimport pandas as pd\nimport numpy as np\nimport os\nfrom tqdm import tqdm\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n\n# ==================== CONFIGURATION ====================\nclass Config:\n    # Path ke model weights\n    EFFNET_B0_MODEL_PATH = '/kaggle/input/effnet-b0/pytorch/default/1/best_efficientnet_b0_chest_xray(98.98).pth' \n    EFFNET_B3_MODEL_PATH = '/kaggle/input/effnetb3/pytorch/default/1/best_chest_xray_model(2) Effnet B-3 (9834).pth'\n    RESNET_MODEL_PATH = '/kaggle/input/resnet50/pytorch/default/1/best_chest_xray_model Resnet-50 (9912).pth'\n    \n    # Path data\n    TRAIN_DIR = '/kaggle/input/final-srifoton-25-machine-learning-competition/train/train'\n    TEST_DIR = '/kaggle/input/final-srifoton-25-machine-learning-competition/test/test'\n    \n    # Hyperparameters\n    BATCH_SIZE = 32\n    NUM_CLASSES = 3\n    IMG_SIZE = 224  \n    IMG_SIZE_B3 = 384  \n    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    \n    # Bobot ensemble (total harus = 1.0)\n    EFFNET_B0_WEIGHT = 0.30  \n    EFFNET_B3_WEIGHT = 0.35  \n    RESNET_WEIGHT = 0.35\n    \n    # Label mapping\n    CLASS_NAMES = ['COVID', 'Normal', 'Viral Pneumonia']\n\n# ==================== CUSTOM MODEL ARCHITECTURES ====================\nclass EfficientNetB0Wrapper(nn.Module):\n    \"\"\"EfficientNet-B0: 512→256→3\"\"\"\n    def __init__(self, num_classes=3):\n        super().__init__()\n        backbone = models.efficientnet_b0(pretrained=False)\n        num_features = backbone.classifier[1].in_features  # 1280\n        backbone.classifier = nn.Identity()\n        self.backbone = backbone\n        \n        self.classifier = nn.Sequential(\n            nn.Dropout(0.5),\n            nn.Linear(num_features, 512),\n            nn.BatchNorm1d(512),\n            nn.ReLU(inplace=True),\n            nn.Dropout(0.3),\n            nn.Linear(512, 256),\n            nn.BatchNorm1d(256),\n            nn.ReLU(inplace=True),\n            nn.Dropout(0.2),\n            nn.Linear(256, num_classes)\n        )\n    \n    def forward(self, x):\n        features = self.backbone(x)\n        return self.classifier(features)\n\nclass EfficientNetB3Wrapper(nn.Module):\n    \"\"\"EfficientNet-B3: 768→384→3\"\"\"\n    def __init__(self, num_classes=3):\n        super().__init__()\n        self.backbone = models.efficientnet_b3(pretrained=False)\n        num_features = self.backbone.classifier[1].in_features  # 1536\n        \n        # B3 structure dari training code Anda\n        self.backbone.classifier = nn.Sequential(\n            nn.Dropout(0.4),\n            nn.Linear(num_features, 768),\n            nn.BatchNorm1d(768),\n            nn.ReLU(inplace=True),\n            nn.Dropout(0.3),\n            nn.Linear(768, 384),\n            nn.BatchNorm1d(384),\n            nn.ReLU(inplace=True),\n            nn.Dropout(0.2),\n            nn.Linear(384, num_classes)\n        )\n    \n    def forward(self, x):\n        return self.backbone(x)\n\nclass ResNetWrapper(nn.Module):\n    \"\"\"ResNet-50: 512→256→3\"\"\"\n    def __init__(self, num_classes=3):\n        super().__init__()\n        self.backbone = models.resnet50(pretrained=False)\n        num_features = self.backbone.fc.in_features\n        self.backbone.fc = nn.Identity()\n        \n        self.classifier = nn.Sequential(\n            nn.Dropout(0.5),\n            nn.Linear(num_features, 512),\n            nn.BatchNorm1d(512),\n            nn.ReLU(inplace=True),\n            nn.Dropout(0.3),\n            nn.Linear(512, 256),\n            nn.BatchNorm1d(256),\n            nn.ReLU(inplace=True),\n            nn.Dropout(0.2),\n            nn.Linear(256, num_classes)\n        )\n    \n    def forward(self, x):\n        features = self.backbone(x)\n        return self.classifier(features)\n\n# ==================== DATASET WITH DUAL TRANSFORMS ====================\nclass DualTransformDataset(torch.utils.data.Dataset):\n    \"\"\"Dataset yang support 2 ukuran image berbeda\"\"\"\n    def __init__(self, base_dataset, transform_224, transform_384):\n        self.base_dataset = base_dataset\n        self.transform_224 = transform_224\n        self.transform_384 = transform_384\n    \n    def __len__(self):\n        return len(self.base_dataset)\n    \n    def __getitem__(self, idx):\n        img, label = self.base_dataset[idx]\n        # Kembalikan both transforms\n        img_224 = self.transform_224(img) if not torch.is_tensor(img) else img\n        img_384 = self.transform_384(img) if not torch.is_tensor(img) else img\n        return img_224, img_384, label\n\nclass TestDataset(torch.utils.data.Dataset):\n    def __init__(self, test_dir, transform_224, transform_384):\n        self.test_dir = test_dir\n        self.transform_224 = transform_224\n        self.transform_384 = transform_384\n        self.image_files = sorted([f for f in os.listdir(test_dir) \n                                   if f.lower().endswith(('.png', '.jpg', '.jpeg'))])\n        \n    def __len__(self):\n        return len(self.image_files)\n    \n    def __getitem__(self, idx):\n        img_name = self.image_files[idx]\n        img_path = os.path.join(self.test_dir, img_name)\n        image = Image.open(img_path).convert('RGB')\n        \n        img_224 = self.transform_224(image)\n        img_384 = self.transform_384(image)\n        \n        img_id = os.path.splitext(img_name)[0]\n        return img_224, img_384, img_id\n\ndef create_validation_split(train_dir, transform_224, transform_384, val_split=0.2):\n    print(f\"\\n📂 Loading train dataset...\")\n    \n    # Load base dataset tanpa transform\n    full_dataset = datasets.ImageFolder(root=train_dir)\n    class_names = full_dataset.classes\n    \n    print(f\"✓ Total samples: {len(full_dataset)}\")\n    print(f\"✓ Classes: {class_names}\")\n    \n    train_size = int(0.8 * len(full_dataset))\n    val_size = len(full_dataset) - train_size\n    \n    _, val_indices_dataset = random_split(\n        full_dataset, \n        [train_size, val_size],\n        generator=torch.Generator().manual_seed(42)\n    )\n    \n    # Wrap dengan dual transform\n    val_dataset = DualTransformDataset(val_indices_dataset, transform_224, transform_384)\n    \n    print(f\"✓ Validation samples: {len(val_dataset)} (20%)\")\n    \n    val_loader = DataLoader(\n        val_dataset,\n        batch_size=Config.BATCH_SIZE,\n        shuffle=False,\n        num_workers=2,\n        pin_memory=True\n    )\n    \n    return val_loader, class_names\n\n# ==================== MODEL LOADING ====================\ndef load_efficientnet_b0(model_path, num_classes=3, device='cuda'):\n    print(f\"\\n🔄 Loading EfficientNet-B0...\")\n    checkpoint = torch.load(model_path, map_location=device, weights_only=False)\n    \n    if isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:\n        state_dict = checkpoint['model_state_dict']\n        print(f\"  → Checkpoint: Balanced Acc {checkpoint.get('best_balanced_acc', 'N/A'):.4f}\")\n    else:\n        state_dict = checkpoint\n    \n    model = EfficientNetB0Wrapper(num_classes=num_classes)\n    model.load_state_dict(state_dict, strict=True)\n    model = model.to(device)\n    model.eval()\n    \n    print(f\"✓ EfficientNet-B0 loaded (512→256→3)\")\n    return model\n\ndef load_efficientnet_b3(model_path, num_classes=3, device='cuda'):\n    print(f\"\\n🔄 Loading EfficientNet-B3...\")\n    checkpoint = torch.load(model_path, map_location=device, weights_only=False)\n    \n    if isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:\n        state_dict = checkpoint['model_state_dict']\n        print(f\"  → Checkpoint: Balanced Acc {checkpoint.get('best_balanced_acc', 'N/A'):.4f}\")\n    else:\n        state_dict = checkpoint\n    \n    model = EfficientNetB3Wrapper(num_classes=num_classes)\n    model.load_state_dict(state_dict, strict=True)\n    model = model.to(device)\n    model.eval()\n    \n    print(f\"✓ EfficientNet-B3 loaded (768→384→3)\")\n    return model\n\ndef load_resnet50(model_path, num_classes=3, device='cuda'):\n    print(f\"\\n🔄 Loading ResNet-50...\")\n    checkpoint = torch.load(model_path, map_location=device, weights_only=False)\n    \n    if isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:\n        state_dict = checkpoint['model_state_dict']\n    else:\n        state_dict = checkpoint\n    \n    sample_key = list(state_dict.keys())[0]\n    \n    if 'backbone' in sample_key:\n        model = ResNetWrapper(num_classes=num_classes)\n    else:\n        model = models.resnet50(pretrained=False)\n        in_features = model.fc.in_features\n        model.fc = nn.Linear(in_features, num_classes)\n    \n    model.load_state_dict(state_dict)\n    model = model.to(device)\n    model.eval()\n    \n    print(f\"✓ ResNet-50 loaded\")\n    return model\n\n# ==================== INFERENCE ====================\ndef get_predictions_triple(model_b0, model_b3, model_resnet, dataloader, device, return_labels=False):\n    \"\"\"Get predictions from all 3 models\"\"\"\n    all_probs_b0 = []\n    all_probs_b3 = []\n    all_probs_resnet = []\n    all_ids_or_labels = []\n    \n    with torch.no_grad():\n        for batch in tqdm(dataloader, desc=\"  Predicting\", leave=False):\n            if return_labels:\n                img_224, img_384, labels = batch\n                img_224 = img_224.to(device)\n                img_384 = img_384.to(device)\n            else:\n                img_224, img_384, img_ids = batch\n                img_224 = img_224.to(device)\n                img_384 = img_384.to(device)\n            \n            # B0 and ResNet use 224x224\n            outputs_b0 = model_b0(img_224)\n            outputs_resnet = model_resnet(img_224)\n            \n            # B3 uses 384x384\n            outputs_b3 = model_b3(img_384)\n            \n            probs_b0 = torch.softmax(outputs_b0, dim=1)\n            probs_b3 = torch.softmax(outputs_b3, dim=1)\n            probs_resnet = torch.softmax(outputs_resnet, dim=1)\n            \n            all_probs_b0.append(probs_b0.cpu().numpy())\n            all_probs_b3.append(probs_b3.cpu().numpy())\n            all_probs_resnet.append(probs_resnet.cpu().numpy())\n            \n            if return_labels:\n                all_ids_or_labels.extend(labels.cpu().numpy())\n            else:\n                all_ids_or_labels.extend(img_ids)\n    \n    all_probs_b0 = np.vstack(all_probs_b0)\n    all_probs_b3 = np.vstack(all_probs_b3)\n    all_probs_resnet = np.vstack(all_probs_resnet)\n    \n    return all_probs_b0, all_probs_b3, all_probs_resnet, all_ids_or_labels\n\n# ==================== ENSEMBLE ====================\ndef ensemble_weighted_voting(probs_b0, probs_b3, probs_resnet, w_b0, w_b3, w_resnet):\n    \"\"\"Weighted ensemble of 3 models\"\"\"\n    ensemble_probs = w_b0 * probs_b0 + w_b3 * probs_b3 + w_resnet * probs_resnet\n    predictions = np.argmax(ensemble_probs, axis=1)\n    return predictions, ensemble_probs\n\n# ==================== EVALUATION ====================\ndef evaluate_triple_ensemble(probs_b0, probs_b3, probs_resnet, true_labels, w_b0, w_b3, w_resnet):\n    print(\"\\n\" + \"=\"*70)\n    print(\"EVALUATION ON VALIDATION SET - TRIPLE ENSEMBLE\")\n    print(\"=\"*70)\n    \n    # Individual predictions\n    preds_b0 = np.argmax(probs_b0, axis=1)\n    preds_b3 = np.argmax(probs_b3, axis=1)\n    preds_resnet = np.argmax(probs_resnet, axis=1)\n    \n    # Ensemble prediction\n    ensemble_preds, _ = ensemble_weighted_voting(probs_b0, probs_b3, probs_resnet, w_b0, w_b3, w_resnet)\n    \n    # Calculate accuracies\n    acc_b0 = accuracy_score(true_labels, preds_b0) * 100\n    acc_b3 = accuracy_score(true_labels, preds_b3) * 100\n    acc_resnet = accuracy_score(true_labels, preds_resnet) * 100\n    acc_ensemble = accuracy_score(true_labels, ensemble_preds) * 100\n    \n    print(f\"\\n📊 ACCURACY COMPARISON:\")\n    print(f\"  EfficientNet-B0 : {acc_b0:.2f}%\")\n    print(f\"  EfficientNet-B3 : {acc_b3:.2f}%\")\n    print(f\"  ResNet-50       : {acc_resnet:.2f}%\")\n    print(f\"  {'─'*40}\")\n    print(f\"  TRIPLE ENSEMBLE : {acc_ensemble:.2f}%\")\n    \n    best_individual = max(acc_b0, acc_b3, acc_resnet)\n    improvement = acc_ensemble - best_individual\n    \n    if improvement > 0:\n        print(f\"\\n✅ Ensemble Improvement: +{improvement:.2f}%\")\n    else:\n        print(f\"\\n⚠️  Ensemble: {improvement:.2f}%\")\n    \n    print(f\"\\n📋 CLASSIFICATION REPORT (ENSEMBLE):\")\n    print(classification_report(true_labels, ensemble_preds, \n                               target_names=Config.CLASS_NAMES, \n                               digits=4))\n    \n    print(f\"\\n🔢 CONFUSION MATRIX (ENSEMBLE):\")\n    cm = confusion_matrix(true_labels, ensemble_preds)\n    print(\"\\n           Predicted\")\n    print(f\"           {Config.CLASS_NAMES[0]:^15} {Config.CLASS_NAMES[1]:^15} {Config.CLASS_NAMES[2]:^15}\")\n    for i, class_name in enumerate(Config.CLASS_NAMES):\n        print(f\"Actual {class_name:15}\", end=\" \")\n        for j in range(len(Config.CLASS_NAMES)):\n            print(f\"{cm[i][j]:^15}\", end=\" \")\n        print()\n    \n    return acc_ensemble\n\n# ==================== SUBMISSION ====================\ndef create_submission(ids, predictions, filename='triple_ensemble_submission.csv'):\n    submission_df = pd.DataFrame({\n        'Id': ids,\n        'Predicted': predictions\n    })\n    \n    submission_df = submission_df.sort_values('Id').reset_index(drop=True)\n    submission_df.to_csv(filename, index=False)\n    \n    print(f\"\\n✅ Submission saved: {filename}\")\n    print(f\"   Total predictions: {len(submission_df)}\")\n    \n    print(\"\\n📊 Distribusi Prediksi:\")\n    for class_idx, class_name in enumerate(Config.CLASS_NAMES):\n        count = (submission_df['Predicted'] == class_idx).sum()\n        percentage = (count / len(submission_df)) * 100\n        print(f\"   {class_name} (Class {class_idx}): {count} ({percentage:.2f}%)\")\n    \n    print(\"\\n📄 Sample (10 baris pertama):\")\n    print(submission_df.head(10).to_string(index=False))\n    \n    return submission_df\n\n# ==================== MAIN ====================\ndef main():\n    print(\"=\"*70)\n    print(\"TRIPLE ENSEMBLE MODEL - WEIGHTED SOFT VOTING\")\n    print(\"EfficientNet-B0 + EfficientNet-B3 + ResNet-50\")\n    print(\"=\"*70)\n    print(f\"Device: {Config.DEVICE}\")\n    print(f\"\\nWeights: B0={Config.EFFNET_B0_WEIGHT}, B3={Config.EFFNET_B3_WEIGHT}, ResNet={Config.RESNET_WEIGHT}\")\n    \n    # Transforms untuk 2 ukuran berbeda\n    transform_224 = transforms.Compose([\n        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], \n                           std=[0.229, 0.224, 0.225])\n    ])\n    \n    transform_384 = transforms.Compose([\n        transforms.Resize((Config.IMG_SIZE_B3, Config.IMG_SIZE_B3)),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], \n                           std=[0.229, 0.224, 0.225])\n    ])\n    \n    # Load models\n    print(\"\\n\" + \"=\"*70)\n    print(\"[STEP 1] LOADING ALL THREE MODELS\")\n    print(\"=\"*70)\n    \n    model_b0 = load_efficientnet_b0(Config.EFFNET_B0_MODEL_PATH, \n                                     Config.NUM_CLASSES, \n                                     Config.DEVICE)\n    \n    model_b3 = load_efficientnet_b3(Config.EFFNET_B3_MODEL_PATH, \n                                     Config.NUM_CLASSES, \n                                     Config.DEVICE)\n    \n    model_resnet = load_resnet50(Config.RESNET_MODEL_PATH, \n                                  Config.NUM_CLASSES, \n                                  Config.DEVICE)\n    \n    # ==================== EVALUATION ====================\n    print(\"\\n\" + \"=\"*70)\n    print(\"[STEP 2] EVALUATION ON VALIDATION SET\")\n    print(\"=\"*70)\n    \n    val_loader, class_names = create_validation_split(\n        Config.TRAIN_DIR, transform_224, transform_384, val_split=0.2\n    )\n    \n    print(\"\\n[2.1] Getting predictions from all models...\")\n    probs_b0, probs_b3, probs_resnet, true_labels = get_predictions_triple(\n        model_b0, model_b3, model_resnet, val_loader, \n        Config.DEVICE, return_labels=True\n    )\n    \n    print(\"\\n[2.2] Evaluating triple ensemble...\")\n    ensemble_acc = evaluate_triple_ensemble(\n        probs_b0, probs_b3, probs_resnet, \n        true_labels,\n        Config.EFFNET_B0_WEIGHT,\n        Config.EFFNET_B3_WEIGHT,\n        Config.RESNET_WEIGHT\n    )\n    \n    print(\"\\n\" + \"=\"*70)\n    print(f\"TRIPLE ENSEMBLE ACCURACY: {ensemble_acc:.2f}%\")\n    print(\"=\"*70)\n    \n    # ==================== SUBMISSION ====================\n    print(\"\\n\" + \"=\"*70)\n    print(\"[STEP 3] GENERATING SUBMISSION FILE\")\n    print(\"=\"*70)\n    \n    test_dataset = TestDataset(Config.TEST_DIR, transform_224, transform_384)\n    test_loader = DataLoader(\n        test_dataset, \n        batch_size=Config.BATCH_SIZE, \n        shuffle=False,\n        num_workers=2,\n        pin_memory=True\n    )\n    print(f\"Total test images: {len(test_dataset)}\")\n    \n    print(\"\\n[3.1] Getting predictions from all models...\")\n    probs_b0_test, probs_b3_test, probs_resnet_test, img_ids = get_predictions_triple(\n        model_b0, model_b3, model_resnet, test_loader, Config.DEVICE\n    )\n    \n    print(\"\\n[3.2] Triple ensemble weighted voting...\")\n    final_predictions, _ = ensemble_weighted_voting(\n        probs_b0_test, \n        probs_b3_test,\n        probs_resnet_test,\n        Config.EFFNET_B0_WEIGHT,\n        Config.EFFNET_B3_WEIGHT,\n        Config.RESNET_WEIGHT\n    )\n    \n    print(\"\\n[3.3] Creating submission file...\")\n    create_submission(img_ids, final_predictions)\n    \n    # ==================== FINAL SUMMARY ====================\n    print(\"\\n\" + \"=\"*70)\n    print(\"TRIPLE ENSEMBLE COMPLETE!\")\n    print(\"=\"*70)\n    print(f\"\\nValidation Accuracy: {ensemble_acc:.2f}%\")\n    print(f\"\\nModel Weights:\")\n    print(f\"  - EfficientNet-B0: {Config.EFFNET_B0_WEIGHT*100:.1f}%\")\n    print(f\"  - EfficientNet-B3: {Config.EFFNET_B3_WEIGHT*100:.1f}%\")\n    print(f\"  - ResNet-50:       {Config.RESNET_WEIGHT*100:.1f}%\")\n    print(f\"\\nFiles generated:\")\n    print(f\"  - triple_ensemble_submission.csv\")\n    print(\"\\nTips untuk tuning:\")\n    print(f\"  - Adjust weights di Config class\")\n    print(f\"  - Model dengan accuracy tertinggi bisa diberi weight lebih besar\")\n    print(\"=\"*70)\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-01T04:18:49.913032Z","iopub.execute_input":"2025-10-01T04:18:49.913698Z","iopub.status.idle":"2025-10-01T04:20:18.363556Z","shell.execute_reply.started":"2025-10-01T04:18:49.913674Z","shell.execute_reply":"2025-10-01T04:20:18.362612Z"},"jupyter":{"source_hidden":true,"outputs_hidden":true},"collapsed":true},"outputs":[{"name":"stdout","text":"======================================================================\nTRIPLE ENSEMBLE MODEL - WEIGHTED SOFT VOTING\nEfficientNet-B0 + EfficientNet-B3 + ResNet-50\n======================================================================\nDevice: cuda\n\nWeights: B0=0.3, B3=0.35, ResNet=0.35\n\n======================================================================\n[STEP 1] LOADING ALL THREE MODELS\n======================================================================\n\n🔄 Loading EfficientNet-B0...\n  → Checkpoint: Balanced Acc 0.9898\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"✓ EfficientNet-B0 loaded (512→256→3)\n\n🔄 Loading EfficientNet-B3...\n  → Checkpoint: Balanced Acc 0.9834\n✓ EfficientNet-B3 loaded (768→384→3)\n\n🔄 Loading ResNet-50...\n✓ ResNet-50 loaded\n\n======================================================================\n[STEP 2] EVALUATION ON VALIDATION SET\n======================================================================\n\n📂 Loading train dataset...\n✓ Total samples: 8572\n✓ Classes: ['COVID', 'Normal', 'Viral Pneumonia']\n✓ Validation samples: 1715 (20%)\n\n[2.1] Getting predictions from all models...\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"\n[2.2] Evaluating triple ensemble...\n\n======================================================================\nEVALUATION ON VALIDATION SET - TRIPLE ENSEMBLE\n======================================================================\n\n📊 ACCURACY COMPARISON:\n  EfficientNet-B0 : 99.18%\n  EfficientNet-B3 : 99.01%\n  ResNet-50       : 99.65%\n  ────────────────────────────────────────\n  TRIPLE ENSEMBLE : 99.42%\n\n⚠️  Ensemble: -0.23%\n\n📋 CLASSIFICATION REPORT (ENSEMBLE):\n                 precision    recall  f1-score   support\n\n          COVID     0.9874    1.0000    0.9937       313\n         Normal     1.0000    0.9922    0.9961      1279\nViral Pneumonia     0.9535    1.0000    0.9762       123\n\n       accuracy                         0.9942      1715\n      macro avg     0.9803    0.9974    0.9886      1715\n   weighted avg     0.9944    0.9942    0.9942      1715\n\n\n🔢 CONFUSION MATRIX (ENSEMBLE):\n\n           Predicted\n                COVID          Normal      Viral Pneumonia\nActual COVID                 313              0               0        \nActual Normal                 4             1269              6        \nActual Viral Pneumonia        0               0              123       \n\n======================================================================\nTRIPLE ENSEMBLE ACCURACY: 99.42%\n======================================================================\n\n======================================================================\n[STEP 3] GENERATING SUBMISSION FILE\n======================================================================\nTotal test images: 6382\n\n[3.1] Getting predictions from all models...\n","output_type":"stream"},{"name":"stderr","text":"                                                               \r","output_type":"stream"},{"name":"stdout","text":"\n[3.2] Triple ensemble weighted voting...\n\n[3.3] Creating submission file...\n\n✅ Submission saved: triple_ensemble_submission.csv\n   Total predictions: 6382\n\n📊 Distribusi Prediksi:\n   COVID (Class 0): 1976 (30.96%)\n   Normal (Class 1): 3706 (58.07%)\n   Viral Pneumonia (Class 2): 700 (10.97%)\n\n📄 Sample (10 baris pertama):\n       Id  Predicted\ntest_0001          1\ntest_0002          0\ntest_0003          0\ntest_0004          1\ntest_0005          1\ntest_0006          1\ntest_0007          1\ntest_0008          1\ntest_0009          0\ntest_0010          1\n\n======================================================================\nTRIPLE ENSEMBLE COMPLETE!\n======================================================================\n\nValidation Accuracy: 99.42%\n\nModel Weights:\n  - EfficientNet-B0: 30.0%\n  - EfficientNet-B3: 35.0%\n  - ResNet-50:       35.0%\n\nFiles generated:\n  - triple_ensemble_submission.csv\n\nTips untuk tuning:\n  - Adjust weights di Config class\n  - Model dengan accuracy tertinggi bisa diberi weight lebih besar\n======================================================================\n","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"**DENSENET-121**","metadata":{}},{"cell_type":"code","source":"import os\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, random_split, WeightedRandomSampler\nfrom torchvision import datasets, transforms, models\nfrom sklearn.metrics import classification_report, confusion_matrix, balanced_accuracy_score, f1_score\nimport pandas as pd\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nfrom collections import Counter\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# ==========================\n# Configuration\n# ==========================\nclass Config:\n    train_dir = \"/kaggle/input/final-srifoton-25-machine-learning-competition/train/train\"\n    test_dir = \"/kaggle/input/final-srifoton-25-machine-learning-competition/test/test\"\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    \n    batch_size = 32\n    learning_rate = 1e-4\n    weight_decay = 1e-4\n    num_epochs = 25\n    patience = 8\n    img_size = 224\n    \n    print(f\"Device: {device}\")\n    print(f\"Image size: {img_size}\")\n\nconfig = Config()\n\n# ==========================\n# Data Transforms\n# ==========================\ntransform_train = transforms.Compose([\n    transforms.Resize((config.img_size, config.img_size)),\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.RandomRotation(degrees=10),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\ntransform_val = transforms.Compose([\n    transforms.Resize((config.img_size, config.img_size)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\ntransform_test = transform_val\n\n# ==========================\n# Helper Functions\n# ==========================\ndef analyze_class_distribution(dataset_path):\n    class_counts = {}\n    total = 0\n    \n    for class_name in os.listdir(dataset_path):\n        class_path = os.path.join(dataset_path, class_name)\n        if os.path.isdir(class_path):\n            count = len([f for f in os.listdir(class_path) \n                        if f.lower().endswith(('.png', '.jpg', '.jpeg'))])\n            class_counts[class_name] = count\n            total += count\n    \n    print(\"\\n\" + \"=\"*40)\n    print(\"CLASS DISTRIBUTION ANALYSIS\")\n    print(\"=\"*40)\n    for class_name, count in sorted(class_counts.items()):\n        percentage = (count / total) * 100\n        print(f\"{class_name}: {count:,} samples ({percentage:.1f}%)\")\n    print(f\"Total: {total:,} samples\")\n    print(\"=\"*40)\n    \n    return class_counts, total\n\ndef create_weighted_sampler(dataset):\n    class_counts = Counter()\n    for i in range(len(dataset)):\n        _, label = dataset[i]\n        class_counts[label] += 1\n    \n    class_weights = {}\n    total_samples = sum(class_counts.values())\n    \n    for class_idx, count in class_counts.items():\n        class_weights[class_idx] = total_samples / (len(class_counts) * count)\n    \n    sample_weights = []\n    for i in range(len(dataset)):\n        _, label = dataset[i]\n        sample_weights.append(class_weights[label])\n    \n    print(\"\\nClass weights for sampling:\")\n    for class_idx, weight in class_weights.items():\n        print(f\"Class {class_idx}: {weight:.3f}\")\n    \n    return WeightedRandomSampler(\n        weights=sample_weights,\n        num_samples=len(sample_weights),\n        replacement=True\n    )\n\n# ==========================\n# Model (DenseNet-121)\n# ==========================\nclass ChestXrayClassifier(nn.Module):\n    def __init__(self, num_classes=3, pretrained=True):\n        super(ChestXrayClassifier, self).__init__()\n        \n        # Load DenseNet-121 backbone\n        self.backbone = models.densenet121(pretrained=pretrained)\n        num_features = self.backbone.classifier.in_features\n        \n        # Remove original classifier\n        self.backbone.classifier = nn.Identity()\n        \n        # Custom classifier head (sama dengan ResNet untuk konsistensi)\n        self.classifier = nn.Sequential(\n            nn.Dropout(0.5),\n            nn.Linear(num_features, 512),\n            nn.BatchNorm1d(512),\n            nn.ReLU(inplace=True),\n            \n            nn.Dropout(0.3),\n            nn.Linear(512, 256),\n            nn.BatchNorm1d(256),\n            nn.ReLU(inplace=True),\n            \n            nn.Dropout(0.2),\n            nn.Linear(256, num_classes)\n        )\n        \n        self._init_classifier()\n    \n    def _init_classifier(self):\n        for m in self.classifier.modules():\n            if isinstance(m, nn.Linear):\n                nn.init.xavier_uniform_(m.weight)\n                nn.init.constant_(m.bias, 0)\n    \n    def forward(self, x):\n        features = self.backbone(x)\n        return self.classifier(features)\n\n# ==========================\n# Training Functions\n# ==========================\ndef calculate_class_weights(dataset):\n    class_counts = Counter()\n    for i in range(len(dataset)):\n        _, label = dataset[i]\n        class_counts[label] += 1\n    \n    total = sum(class_counts.values())\n    weights = []\n    \n    for i in range(len(class_counts)):\n        weight = total / (len(class_counts) * class_counts[i])\n        weights.append(weight)\n    \n    return torch.FloatTensor(weights)\n\ndef train_epoch(model, dataloader, criterion, optimizer, device):\n    model.train()\n    total_loss = 0.0\n    correct_predictions = 0\n    total_samples = 0\n    \n    for batch_idx, (inputs, targets) in enumerate(dataloader):\n        inputs, targets = inputs.to(device), targets.to(device)\n        \n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = criterion(outputs, targets)\n        \n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n        optimizer.step()\n        \n        total_loss += loss.item()\n        _, predicted = torch.max(outputs.data, 1)\n        total_samples += targets.size(0)\n        correct_predictions += (predicted == targets).sum().item()\n        \n        if batch_idx % 50 == 0:\n            print(f'Batch {batch_idx}/{len(dataloader)}, Loss: {loss.item():.4f}')\n    \n    avg_loss = total_loss / len(dataloader)\n    accuracy = correct_predictions / total_samples\n    \n    return avg_loss, accuracy\n\ndef validate_epoch(model, dataloader, criterion, device):\n    model.eval()\n    total_loss = 0.0\n    correct_predictions = 0\n    total_samples = 0\n    all_predictions = []\n    all_targets = []\n    \n    with torch.no_grad():\n        for inputs, targets in dataloader:\n            inputs, targets = inputs.to(device), targets.to(device)\n            \n            outputs = model(inputs)\n            loss = criterion(outputs, targets)\n            \n            total_loss += loss.item()\n            _, predicted = torch.max(outputs.data, 1)\n            total_samples += targets.size(0)\n            correct_predictions += (predicted == targets).sum().item()\n            \n            all_predictions.extend(predicted.cpu().numpy())\n            all_targets.extend(targets.cpu().numpy())\n    \n    avg_loss = total_loss / len(dataloader)\n    accuracy = correct_predictions / total_samples\n    balanced_acc = balanced_accuracy_score(all_targets, all_predictions)\n    f1 = f1_score(all_targets, all_predictions, average='macro')\n    \n    return avg_loss, accuracy, balanced_acc, f1, all_predictions, all_targets\n\n# ==========================\n# Main Training\n# ==========================\ndef train_model():\n    print(\"\\n\" + \"=\"*60)\n    print(\"TRAINING DENSENET-121 FOR CHEST X-RAY CLASSIFICATION\")\n    print(\"=\"*60)\n    \n    # Load and analyze dataset\n    temp_dataset = datasets.ImageFolder(root=config.train_dir, transform=transform_val)\n    analyze_class_distribution(config.train_dir)\n    class_names = temp_dataset.classes\n    num_classes = len(class_names)\n    \n    print(f\"\\nClasses: {class_names}\")\n    \n    # Create datasets\n    full_dataset = datasets.ImageFolder(root=config.train_dir, transform=transform_train)\n    train_size = int(0.8 * len(full_dataset))\n    val_size = len(full_dataset) - train_size\n    train_dataset, val_temp = random_split(full_dataset, [train_size, val_size],\n                                          generator=torch.Generator().manual_seed(42))\n    \n    # Validation dataset\n    val_full_dataset = datasets.ImageFolder(root=config.train_dir, transform=transform_val)\n    \n    class ValDataset:\n        def __init__(self, base_dataset, indices):\n            self.base_dataset = base_dataset\n            self.indices = indices\n        \n        def __len__(self):\n            return len(self.indices)\n        \n        def __getitem__(self, idx):\n            return self.base_dataset[self.indices[idx]]\n    \n    val_dataset = ValDataset(val_full_dataset, val_temp.indices)\n    \n    print(f\"\\nTrain: {len(train_dataset):,} | Val: {len(val_dataset):,}\")\n    \n    # Create samplers and loaders\n    train_sampler = create_weighted_sampler(train_dataset)\n    \n    train_loader = DataLoader(train_dataset, batch_size=config.batch_size,\n                            sampler=train_sampler, num_workers=2, pin_memory=True)\n    val_loader = DataLoader(val_dataset, batch_size=config.batch_size,\n                          shuffle=False, num_workers=2, pin_memory=True)\n    \n    # Initialize model\n    print(f\"\\nInitializing DenseNet-121...\")\n    model = ChestXrayClassifier(num_classes=num_classes, pretrained=True)\n    model = model.to(config.device)\n    \n    total_params = sum(p.numel() for p in model.parameters())\n    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n    print(f\"Total parameters: {total_params:,}\")\n    print(f\"Trainable parameters: {trainable_params:,}\")\n    \n    # Loss and optimizer\n    class_weights = calculate_class_weights(train_dataset).to(config.device)\n    print(f\"\\nClass weights: {class_weights}\")\n    criterion = nn.CrossEntropyLoss(weight=class_weights)\n    \n    optimizer = optim.AdamW(model.parameters(), lr=config.learning_rate, \n                           weight_decay=config.weight_decay)\n    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', \n                                                     factor=0.5, patience=4, \n                                                     verbose=True, min_lr=1e-7)\n    \n    # Training loop\n    print(f\"\\nStarting training for {config.num_epochs} epochs...\")\n    best_balanced_acc = 0.0\n    patience_counter = 0\n    \n    for epoch in range(config.num_epochs):\n        print(f\"\\n{'='*50}\")\n        print(f\"Epoch {epoch+1}/{config.num_epochs}\")\n        print('='*50)\n        \n        train_loss, train_acc = train_epoch(model, train_loader, criterion, \n                                           optimizer, config.device)\n        val_loss, val_acc, val_balanced_acc, val_f1, _, _ = validate_epoch(\n            model, val_loader, criterion, config.device)\n        \n        scheduler.step(val_balanced_acc)\n        current_lr = optimizer.param_groups[0]['lr']\n        \n        print(f\"\\nResults:\")\n        print(f\"Train - Loss: {train_loss:.4f}, Acc: {train_acc:.4f}\")\n        print(f\"Val   - Loss: {val_loss:.4f}, Acc: {val_acc:.4f}, \"\n              f\"Balanced: {val_balanced_acc:.4f}, F1: {val_f1:.4f}\")\n        print(f\"LR: {current_lr:.2e}\")\n        \n        if val_balanced_acc > best_balanced_acc:\n            best_balanced_acc = val_balanced_acc\n            torch.save({\n                'epoch': epoch,\n                'model_state_dict': model.state_dict(),\n                'optimizer_state_dict': optimizer.state_dict(),\n                'best_balanced_acc': best_balanced_acc,\n                'class_names': class_names\n            }, 'best_chest_xray_model_densenet121.pth')\n            print(f\"New best: Balanced Acc {best_balanced_acc:.4f}\")\n            patience_counter = 0\n        else:\n            patience_counter += 1\n        \n        if patience_counter >= config.patience:\n            print(f\"\\nEarly stopping at epoch {epoch+1}\")\n            break\n    \n    print(f\"\\n{'='*60}\")\n    print(f\"TRAINING COMPLETE - Best: {best_balanced_acc:.4f}\")\n    print('='*60)\n    \n    # Final validation\n    checkpoint = torch.load('best_chest_xray_model_densenet121.pth', \n                          map_location=config.device, \n                          weights_only=False)\n    model.load_state_dict(checkpoint['model_state_dict'])\n    \n    _, final_acc, final_balanced, final_f1, final_preds, final_targets = validate_epoch(\n        model, val_loader, criterion, config.device)\n    \n    print(\"\\n\" + \"=\"*40)\n    print(\"FINAL VALIDATION REPORT\")\n    print(\"=\"*40)\n    print(f\"Accuracy: {final_acc:.4f}\")\n    print(f\"Balanced Accuracy: {final_balanced:.4f}\")\n    print(f\"F1 Score (Macro): {final_f1:.4f}\")\n    print(\"\\nDetailed Report:\")\n    print(classification_report(final_targets, final_preds, \n                               target_names=class_names, digits=4))\n    \n    # Confusion Matrix\n    cm = confusion_matrix(final_targets, final_preds)\n    plt.figure(figsize=(8, 6))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n                xticklabels=class_names, yticklabels=class_names)\n    plt.title(f'Confusion Matrix - DenseNet-121\\nBalanced Acc: {final_balanced:.4f}')\n    plt.xlabel('Predicted')\n    plt.ylabel('Actual')\n    plt.tight_layout()\n    plt.savefig('confusion_matrix_densenet121.png', dpi=300, bbox_inches='tight')\n    plt.show()\n    \n    return model, class_names, best_balanced_acc\n\n# ==========================\n# Prediction Functions\n# ==========================\ndef predict_with_tta(model, image_path):\n    model.eval()\n    \n    tta_transforms = [\n        transform_test,\n        transforms.Compose([\n            transforms.Resize((config.img_size, config.img_size)),\n            transforms.RandomHorizontalFlip(p=1.0),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n        ]),\n        transforms.Compose([\n            transforms.Resize((config.img_size, config.img_size)),\n            transforms.RandomRotation(degrees=5),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n        ])\n    ]\n    \n    predictions = []\n    \n    with torch.no_grad():\n        for transform in tta_transforms:\n            try:\n                image = Image.open(image_path).convert('RGB')\n                image_tensor = transform(image).unsqueeze(0).to(config.device)\n                \n                outputs = model(image_tensor)\n                probabilities = torch.softmax(outputs, dim=1)\n                predictions.append(probabilities.cpu().numpy())\n            except Exception:\n                continue\n    \n    if predictions:\n        return np.mean(predictions, axis=0)\n    else:\n        image = Image.open(image_path).convert('RGB')\n        image_tensor = transform_test(image).unsqueeze(0).to(config.device)\n        outputs = model(image_tensor)\n        probabilities = torch.softmax(outputs, dim=1)\n        return probabilities.cpu().numpy()\n\n# ==========================\n# Generate Submission\n# ==========================\ndef generate_submission():\n    print(\"\\n\" + \"=\"*60)\n    print(\"GENERATING SUBMISSION - DENSENET-121\")\n    print(\"=\"*60)\n    \n    checkpoint = torch.load('best_chest_xray_model_densenet121.pth', \n                          map_location=config.device,\n                          weights_only=False)\n    class_names = checkpoint['class_names']\n    \n    model = ChestXrayClassifier(num_classes=len(class_names), pretrained=False)\n    model.load_state_dict(checkpoint['model_state_dict'])\n    model = model.to(config.device)\n    model.eval()\n    \n    print(f\"Loaded model: Balanced Acc {checkpoint['best_balanced_acc']:.4f}\")\n    print(f\"Classes: {class_names}\")\n    \n    test_images = sorted([f for f in os.listdir(config.test_dir) \n                         if f.lower().endswith(('.png', '.jpg', '.jpeg'))])\n    \n    print(f\"\\nProcessing {len(test_images)} images...\")\n    \n    image_ids = []\n    predictions = []\n    confidences = []\n    \n    for i, img_name in enumerate(test_images):\n        if i % 500 == 0:\n            print(f\"Progress: {i}/{len(test_images)}\")\n        \n        img_path = os.path.join(config.test_dir, img_name)\n        \n        try:\n            prob_vector = predict_with_tta(model, img_path)\n            pred_class = np.argmax(prob_vector)\n            confidence = np.max(prob_vector)\n            \n            image_ids.append(os.path.splitext(img_name)[0])\n            predictions.append(pred_class)\n            confidences.append(confidence)\n            \n        except Exception as e:\n            print(f\"Error {img_name}: {e}\")\n            image_ids.append(os.path.splitext(img_name)[0])\n            predictions.append(1)\n            confidences.append(0.33)\n    \n    # Create submission\n    submission_df = pd.DataFrame({\n        'Id': image_ids,\n        'Predicted': predictions\n    })\n    \n    submission_df = submission_df.sort_values('Id').reset_index(drop=True)\n    submission_df.to_csv('submission_densenet121.csv', index=False)\n    \n    print(f\"\\nSubmission complete!\")\n    print(f\"Total: {len(submission_df)}\")\n    \n    print(\"\\nDistribution:\")\n    for idx in range(len(class_names)):\n        count = (submission_df['Predicted'] == idx).sum()\n        pct = count / len(submission_df) * 100\n        print(f\"{class_names[idx]} (Class {idx}): {count} ({pct:.1f}%)\")\n    \n    print(f\"\\nConfidence - Mean: {np.mean(confidences):.4f}, \"\n          f\"Std: {np.std(confidences):.4f}\")\n    \n    return submission_df\n\n# ==========================\n# Main Execution\n# ==========================\nif __name__ == \"__main__\":\n    print(\"DenseNet-121 Chest X-Ray Classifier\")\n    print(\"=\"*60)\n    \n    try:\n        model, class_names, best_score = train_model()\n        submission = generate_submission()\n        \n        print(\"\\nComplete!\")\n        print(f\"Best score: {best_score:.4f}\")\n        print(\"Files: best_chest_xray_model_densenet121.pth, submission_densenet121.csv\")\n        \n    except Exception as e:\n        print(f\"\\nError: {e}\")\n        import traceback\n        traceback.print_exc()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-01T04:28:08.258577Z","iopub.execute_input":"2025-10-01T04:28:08.259203Z","iopub.status.idle":"2025-10-01T04:55:57.248078Z","shell.execute_reply.started":"2025-10-01T04:28:08.259172Z","shell.execute_reply":"2025-10-01T04:55:57.247282Z"},"jupyter":{"source_hidden":true,"outputs_hidden":true},"collapsed":true},"outputs":[{"name":"stdout","text":"Device: cuda\nImage size: 224\nDenseNet-121 Chest X-Ray Classifier\n============================================================\n\n============================================================\nTRAINING DENSENET-121 FOR CHEST X-RAY CLASSIFICATION\n============================================================\n\n========================================\nCLASS DISTRIBUTION ANALYSIS\n========================================\nCOVID: 1,596 samples (18.6%)\nNormal: 6,310 samples (73.6%)\nViral Pneumonia: 666 samples (7.8%)\nTotal: 8,572 samples\n========================================\n\nClasses: ['COVID', 'Normal', 'Viral Pneumonia']\n\nTrain: 6,857 | Val: 1,715\n\nClass weights for sampling:\nClass 1: 0.454\nClass 2: 4.209\nClass 0: 1.782\n\nInitializing DenseNet-121...\n","output_type":"stream"},{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to /root/.cache/torch/hub/checkpoints/densenet121-a639ec97.pth\n100%|██████████| 30.8M/30.8M [00:00<00:00, 158MB/s]\n","output_type":"stream"},{"name":"stdout","text":"Total parameters: 7,612,291\nTrainable parameters: 7,612,291\n\nClass weights: tensor([1.7815, 0.4543, 4.2093], device='cuda:0')\n\nStarting training for 25 epochs...\n\n==================================================\nEpoch 1/25\n==================================================\nBatch 0/215, Loss: 1.5785\nBatch 50/215, Loss: 0.1646\nBatch 100/215, Loss: 0.1541\nBatch 150/215, Loss: 0.1277\nBatch 200/215, Loss: 0.0396\n\nResults:\nTrain - Loss: 0.2745, Acc: 0.8132\nVal   - Loss: 0.2258, Acc: 0.8548, Balanced: 0.9230, F1: 0.7949\nLR: 1.00e-04\nNew best: Balanced Acc 0.9230\n\n==================================================\nEpoch 2/25\n==================================================\nBatch 0/215, Loss: 0.0998\nBatch 50/215, Loss: 0.0486\nBatch 100/215, Loss: 0.0600\nBatch 150/215, Loss: 0.2411\nBatch 200/215, Loss: 0.0186\n\nResults:\nTrain - Loss: 0.0875, Acc: 0.9278\nVal   - Loss: 0.1194, Acc: 0.9545, Balanced: 0.9644, F1: 0.9184\nLR: 1.00e-04\nNew best: Balanced Acc 0.9644\n\n==================================================\nEpoch 3/25\n==================================================\nBatch 0/215, Loss: 0.0712\nBatch 50/215, Loss: 0.0076\nBatch 100/215, Loss: 0.5143\nBatch 150/215, Loss: 0.0028\nBatch 200/215, Loss: 0.0957\n\nResults:\nTrain - Loss: 0.0635, Acc: 0.9561\nVal   - Loss: 0.1687, Acc: 0.9668, Balanced: 0.9477, F1: 0.9467\nLR: 1.00e-04\n\n==================================================\nEpoch 4/25\n==================================================\nBatch 0/215, Loss: 0.0097\nBatch 50/215, Loss: 0.0034\nBatch 100/215, Loss: 0.0380\nBatch 150/215, Loss: 0.0021\nBatch 200/215, Loss: 0.0044\n\nResults:\nTrain - Loss: 0.0417, Acc: 0.9735\nVal   - Loss: 0.1215, Acc: 0.9691, Balanced: 0.9701, F1: 0.9434\nLR: 1.00e-04\nNew best: Balanced Acc 0.9701\n\n==================================================\nEpoch 5/25\n==================================================\nBatch 0/215, Loss: 0.0102\nBatch 50/215, Loss: 0.0141\nBatch 100/215, Loss: 0.0016\nBatch 150/215, Loss: 0.0337\nBatch 200/215, Loss: 0.0036\n\nResults:\nTrain - Loss: 0.0316, Acc: 0.9789\nVal   - Loss: 0.1307, Acc: 0.9778, Balanced: 0.9691, F1: 0.9622\nLR: 1.00e-04\n\n==================================================\nEpoch 6/25\n==================================================\nBatch 0/215, Loss: 0.0146\nBatch 50/215, Loss: 0.0291\nBatch 100/215, Loss: 0.0048\nBatch 150/215, Loss: 0.1379\nBatch 200/215, Loss: 0.0006\n\nResults:\nTrain - Loss: 0.0315, Acc: 0.9815\nVal   - Loss: 0.0936, Acc: 0.9732, Balanced: 0.9767, F1: 0.9485\nLR: 1.00e-04\nNew best: Balanced Acc 0.9767\n\n==================================================\nEpoch 7/25\n==================================================\nBatch 0/215, Loss: 0.1922\nBatch 50/215, Loss: 0.0016\nBatch 100/215, Loss: 0.0254\nBatch 150/215, Loss: 0.0022\nBatch 200/215, Loss: 0.0188\n\nResults:\nTrain - Loss: 0.0246, Acc: 0.9842\nVal   - Loss: 0.0935, Acc: 0.9697, Balanced: 0.9808, F1: 0.9457\nLR: 1.00e-04\nNew best: Balanced Acc 0.9808\n\n==================================================\nEpoch 8/25\n==================================================\nBatch 0/215, Loss: 0.0017\nBatch 50/215, Loss: 0.0028\nBatch 100/215, Loss: 0.0865\nBatch 150/215, Loss: 0.0019\nBatch 200/215, Loss: 0.0003\n\nResults:\nTrain - Loss: 0.0185, Acc: 0.9888\nVal   - Loss: 0.1177, Acc: 0.9720, Balanced: 0.9672, F1: 0.9566\nLR: 1.00e-04\n\n==================================================\nEpoch 9/25\n==================================================\nBatch 0/215, Loss: 0.0068\nBatch 50/215, Loss: 0.0056\nBatch 100/215, Loss: 0.0086\nBatch 150/215, Loss: 0.0163\nBatch 200/215, Loss: 0.0002\n\nResults:\nTrain - Loss: 0.0140, Acc: 0.9912\nVal   - Loss: 0.1636, Acc: 0.9773, Balanced: 0.9508, F1: 0.9572\nLR: 1.00e-04\n\n==================================================\nEpoch 10/25\n==================================================\nBatch 0/215, Loss: 0.0014\nBatch 50/215, Loss: 0.0020\nBatch 100/215, Loss: 0.0011\nBatch 150/215, Loss: 0.0027\nBatch 200/215, Loss: 0.0025\n\nResults:\nTrain - Loss: 0.0155, Acc: 0.9911\nVal   - Loss: 0.0961, Acc: 0.9843, Balanced: 0.9792, F1: 0.9704\nLR: 1.00e-04\n\n==================================================\nEpoch 11/25\n==================================================\nBatch 0/215, Loss: 0.0008\nBatch 50/215, Loss: 0.0144\nBatch 100/215, Loss: 0.0005\nBatch 150/215, Loss: 0.0069\nBatch 200/215, Loss: 0.0011\n\nResults:\nTrain - Loss: 0.0164, Acc: 0.9895\nVal   - Loss: 0.1315, Acc: 0.9831, Balanced: 0.9689, F1: 0.9693\nLR: 1.00e-04\n\n==================================================\nEpoch 12/25\n==================================================\nBatch 0/215, Loss: 0.0863\nBatch 50/215, Loss: 0.0008\nBatch 100/215, Loss: 0.0003\nBatch 150/215, Loss: 0.0110\nBatch 200/215, Loss: 0.0007\n\nResults:\nTrain - Loss: 0.0195, Acc: 0.9867\nVal   - Loss: 0.1544, Acc: 0.9603, Balanced: 0.9529, F1: 0.9444\nLR: 5.00e-05\n\n==================================================\nEpoch 13/25\n==================================================\nBatch 0/215, Loss: 0.0338\nBatch 50/215, Loss: 0.0008\nBatch 100/215, Loss: 0.0006\nBatch 150/215, Loss: 0.0018\nBatch 200/215, Loss: 0.0012\n\nResults:\nTrain - Loss: 0.0074, Acc: 0.9952\nVal   - Loss: 0.0808, Acc: 0.9837, Balanced: 0.9716, F1: 0.9704\nLR: 5.00e-05\n\n==================================================\nEpoch 14/25\n==================================================\nBatch 0/215, Loss: 0.0003\nBatch 50/215, Loss: 0.0002\nBatch 100/215, Loss: 0.0007\nBatch 150/215, Loss: 0.0072\nBatch 200/215, Loss: 0.0143\n\nResults:\nTrain - Loss: 0.0053, Acc: 0.9971\nVal   - Loss: 0.0889, Acc: 0.9837, Balanced: 0.9723, F1: 0.9712\nLR: 5.00e-05\n\n==================================================\nEpoch 15/25\n==================================================\nBatch 0/215, Loss: 0.0003\nBatch 50/215, Loss: 0.0001\nBatch 100/215, Loss: 0.0003\nBatch 150/215, Loss: 0.0001\nBatch 200/215, Loss: 0.0007\n\nResults:\nTrain - Loss: 0.0059, Acc: 0.9964\nVal   - Loss: 0.0649, Acc: 0.9872, Balanced: 0.9796, F1: 0.9761\nLR: 5.00e-05\n\nEarly stopping at epoch 15\n\n============================================================\nTRAINING COMPLETE - Best: 0.9808\n============================================================\n\n========================================\nFINAL VALIDATION REPORT\n========================================\nAccuracy: 0.9697\nBalanced Accuracy: 0.9808\nF1 Score (Macro): 0.9457\n\nDetailed Report:\n                 precision    recall  f1-score   support\n\n          COVID     0.9415    0.9776    0.9592       313\n         Normal     0.9960    0.9648    0.9801      1279\nViral Pneumonia     0.8146    1.0000    0.8978       123\n\n       accuracy                         0.9697      1715\n      macro avg     0.9174    0.9808    0.9457      1715\n   weighted avg     0.9730    0.9697    0.9704      1715\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 800x600 with 2 Axes>","image/png":"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\n"},"metadata":{}},{"name":"stdout","text":"\n============================================================\nGENERATING SUBMISSION - DENSENET-121\n============================================================\nLoaded model: Balanced Acc 0.9808\nClasses: ['COVID', 'Normal', 'Viral Pneumonia']\n\nProcessing 6382 images...\nProgress: 0/6382\nProgress: 500/6382\nProgress: 1000/6382\nProgress: 1500/6382\nProgress: 2000/6382\nProgress: 2500/6382\nProgress: 3000/6382\nProgress: 3500/6382\nProgress: 4000/6382\nProgress: 4500/6382\nProgress: 5000/6382\nProgress: 5500/6382\nProgress: 6000/6382\n\nSubmission complete!\nTotal: 6382\n\nDistribution:\nCOVID (Class 0): 2013 (31.5%)\nNormal (Class 1): 3628 (56.8%)\nViral Pneumonia (Class 2): 741 (11.6%)\n\nConfidence - Mean: 0.9800, Std: 0.0683\n\nComplete!\nBest score: 0.9808\nFiles: best_chest_xray_model_densenet121.pth, submission_densenet121.csv\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"**EFFNET V2S**","metadata":{}},{"cell_type":"code","source":"import os\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, random_split, WeightedRandomSampler\nfrom torchvision import datasets, transforms, models\nfrom sklearn.metrics import classification_report, confusion_matrix, balanced_accuracy_score, f1_score\nimport pandas as pd\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nfrom collections import Counter\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# ==========================\n# Configuration\n# ==========================\nclass Config:\n    train_dir = \"/kaggle/input/final-srifoton-25-machine-learning-competition/train/train\"\n    test_dir = \"/kaggle/input/final-srifoton-25-machine-learning-competition/test/test\"\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    \n    batch_size = 32\n    learning_rate = 1e-4\n    weight_decay = 1e-4\n    num_epochs = 25\n    patience = 8\n    img_size = 384  # EfficientNetV2-S works best with 384\n    \n    print(f\"Device: {device}\")\n    print(f\"Image size: {img_size}\")\n\nconfig = Config()\n\n# ==========================\n# Data Transforms\n# ==========================\ntransform_train = transforms.Compose([\n    transforms.Resize((config.img_size, config.img_size)),\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.RandomRotation(degrees=10),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n    transforms.RandomAffine(degrees=0, translate=(0.05, 0.05)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\ntransform_val = transforms.Compose([\n    transforms.Resize((config.img_size, config.img_size)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\ntransform_test = transform_val\n\n# ==========================\n# Helper Functions\n# ==========================\ndef analyze_class_distribution(dataset_path):\n    class_counts = {}\n    total = 0\n    \n    for class_name in os.listdir(dataset_path):\n        class_path = os.path.join(dataset_path, class_name)\n        if os.path.isdir(class_path):\n            count = len([f for f in os.listdir(class_path) \n                        if f.lower().endswith(('.png', '.jpg', '.jpeg'))])\n            class_counts[class_name] = count\n            total += count\n    \n    print(\"\\n\" + \"=\"*40)\n    print(\"CLASS DISTRIBUTION ANALYSIS\")\n    print(\"=\"*40)\n    for class_name, count in sorted(class_counts.items()):\n        percentage = (count / total) * 100\n        print(f\"{class_name}: {count:,} samples ({percentage:.1f}%)\")\n    print(f\"Total: {total:,} samples\")\n    print(\"=\"*40)\n    \n    return class_counts, total\n\ndef create_weighted_sampler(dataset):\n    class_counts = Counter()\n    for i in range(len(dataset)):\n        _, label = dataset[i]\n        class_counts[label] += 1\n    \n    class_weights = {}\n    total_samples = sum(class_counts.values())\n    \n    for class_idx, count in class_counts.items():\n        class_weights[class_idx] = total_samples / (len(class_counts) * count)\n    \n    sample_weights = []\n    for i in range(len(dataset)):\n        _, label = dataset[i]\n        sample_weights.append(class_weights[label])\n    \n    print(\"\\nClass weights for sampling:\")\n    for class_idx, weight in class_weights.items():\n        print(f\"Class {class_idx}: {weight:.3f}\")\n    \n    return WeightedRandomSampler(\n        weights=sample_weights,\n        num_samples=len(sample_weights),\n        replacement=True\n    )\n\n# ==========================\n# Model (EfficientNetV2-S)\n# ==========================\nclass ChestXrayClassifier(nn.Module):\n    def __init__(self, num_classes=3, pretrained=True):\n        super(ChestXrayClassifier, self).__init__()\n        \n        # Load EfficientNetV2-S backbone\n        self.backbone = models.efficientnet_v2_s(weights='DEFAULT' if pretrained else None)\n        num_features = self.backbone.classifier[1].in_features\n        \n        # Remove original classifier\n        self.backbone.classifier = nn.Identity()\n        \n        # Custom classifier head\n        self.classifier = nn.Sequential(\n            nn.Dropout(0.5),\n            nn.Linear(num_features, 512),\n            nn.BatchNorm1d(512),\n            nn.ReLU(inplace=True),\n            \n            nn.Dropout(0.3),\n            nn.Linear(512, 256),\n            nn.BatchNorm1d(256),\n            nn.ReLU(inplace=True),\n            \n            nn.Dropout(0.2),\n            nn.Linear(256, num_classes)\n        )\n        \n        self._init_classifier()\n    \n    def _init_classifier(self):\n        for m in self.classifier.modules():\n            if isinstance(m, nn.Linear):\n                nn.init.xavier_uniform_(m.weight)\n                nn.init.constant_(m.bias, 0)\n    \n    def forward(self, x):\n        features = self.backbone(x)\n        return self.classifier(features)\n\n# ==========================\n# Training Functions\n# ==========================\ndef calculate_class_weights(dataset):\n    class_counts = Counter()\n    for i in range(len(dataset)):\n        _, label = dataset[i]\n        class_counts[label] += 1\n    \n    total = sum(class_counts.values())\n    weights = []\n    \n    for i in range(len(class_counts)):\n        weight = total / (len(class_counts) * class_counts[i])\n        weights.append(weight)\n    \n    return torch.FloatTensor(weights)\n\ndef train_epoch(model, dataloader, criterion, optimizer, device, scaler=None):\n    model.train()\n    total_loss = 0.0\n    correct_predictions = 0\n    total_samples = 0\n    \n    for batch_idx, (inputs, targets) in enumerate(dataloader):\n        inputs, targets = inputs.to(device), targets.to(device)\n        \n        optimizer.zero_grad()\n        \n        # Mixed precision training\n        if scaler is not None:\n            with torch.cuda.amp.autocast():\n                outputs = model(inputs)\n                loss = criterion(outputs, targets)\n            \n            scaler.scale(loss).backward()\n            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n            scaler.step(optimizer)\n            scaler.update()\n        else:\n            outputs = model(inputs)\n            loss = criterion(outputs, targets)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n            optimizer.step()\n        \n        total_loss += loss.item()\n        _, predicted = torch.max(outputs.data, 1)\n        total_samples += targets.size(0)\n        correct_predictions += (predicted == targets).sum().item()\n        \n        if batch_idx % 50 == 0:\n            print(f'Batch {batch_idx}/{len(dataloader)}, Loss: {loss.item():.4f}')\n    \n    avg_loss = total_loss / len(dataloader)\n    accuracy = correct_predictions / total_samples\n    \n    return avg_loss, accuracy\n\ndef validate_epoch(model, dataloader, criterion, device):\n    model.eval()\n    total_loss = 0.0\n    correct_predictions = 0\n    total_samples = 0\n    all_predictions = []\n    all_targets = []\n    \n    with torch.no_grad():\n        for inputs, targets in dataloader:\n            inputs, targets = inputs.to(device), targets.to(device)\n            \n            outputs = model(inputs)\n            loss = criterion(outputs, targets)\n            \n            total_loss += loss.item()\n            _, predicted = torch.max(outputs.data, 1)\n            total_samples += targets.size(0)\n            correct_predictions += (predicted == targets).sum().item()\n            \n            all_predictions.extend(predicted.cpu().numpy())\n            all_targets.extend(targets.cpu().numpy())\n    \n    avg_loss = total_loss / len(dataloader)\n    accuracy = correct_predictions / total_samples\n    balanced_acc = balanced_accuracy_score(all_targets, all_predictions)\n    f1 = f1_score(all_targets, all_predictions, average='macro')\n    \n    return avg_loss, accuracy, balanced_acc, f1, all_predictions, all_targets\n\n# ==========================\n# Main Training\n# ==========================\ndef train_model():\n    print(\"\\n\" + \"=\"*60)\n    print(\"TRAINING EFFICIENTNETV2-S FOR CHEST X-RAY CLASSIFICATION\")\n    print(\"=\"*60)\n    \n    # Load and analyze dataset\n    temp_dataset = datasets.ImageFolder(root=config.train_dir, transform=transform_val)\n    analyze_class_distribution(config.train_dir)\n    class_names = temp_dataset.classes\n    num_classes = len(class_names)\n    \n    print(f\"\\nClasses: {class_names}\")\n    \n    # Create datasets\n    full_dataset = datasets.ImageFolder(root=config.train_dir, transform=transform_train)\n    train_size = int(0.8 * len(full_dataset))\n    val_size = len(full_dataset) - train_size\n    train_dataset, val_temp = random_split(full_dataset, [train_size, val_size],\n                                          generator=torch.Generator().manual_seed(42))\n    \n    # Validation dataset\n    val_full_dataset = datasets.ImageFolder(root=config.train_dir, transform=transform_val)\n    \n    class ValDataset:\n        def __init__(self, base_dataset, indices):\n            self.base_dataset = base_dataset\n            self.indices = indices\n        \n        def __len__(self):\n            return len(self.indices)\n        \n        def __getitem__(self, idx):\n            return self.base_dataset[self.indices[idx]]\n    \n    val_dataset = ValDataset(val_full_dataset, val_temp.indices)\n    \n    print(f\"\\nTrain: {len(train_dataset):,} | Val: {len(val_dataset):,}\")\n    \n    # Create samplers and loaders\n    train_sampler = create_weighted_sampler(train_dataset)\n    \n    train_loader = DataLoader(train_dataset, batch_size=config.batch_size,\n                            sampler=train_sampler, num_workers=2, pin_memory=True)\n    val_loader = DataLoader(val_dataset, batch_size=config.batch_size,\n                          shuffle=False, num_workers=2, pin_memory=True)\n    \n    # Initialize model\n    print(f\"\\nInitializing EfficientNetV2-S...\")\n    model = ChestXrayClassifier(num_classes=num_classes, pretrained=True)\n    model = model.to(config.device)\n    \n    total_params = sum(p.numel() for p in model.parameters())\n    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n    print(f\"Total parameters: {total_params:,}\")\n    print(f\"Trainable parameters: {trainable_params:,}\")\n    \n    # Loss and optimizer\n    class_weights = calculate_class_weights(train_dataset).to(config.device)\n    print(f\"\\nClass weights: {class_weights}\")\n    criterion = nn.CrossEntropyLoss(weight=class_weights)\n    \n    optimizer = optim.AdamW(model.parameters(), lr=config.learning_rate, \n                           weight_decay=config.weight_decay)\n    \n    # Cosine Annealing scheduler (better for EfficientNetV2)\n    scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=5, T_mult=2)\n    \n    # Mixed precision scaler\n    scaler = torch.cuda.amp.GradScaler() if config.device.type == 'cuda' else None\n    \n    # Training loop\n    print(f\"\\nStarting training for {config.num_epochs} epochs...\")\n    best_balanced_acc = 0.0\n    patience_counter = 0\n    \n    for epoch in range(config.num_epochs):\n        print(f\"\\n{'='*50}\")\n        print(f\"Epoch {epoch+1}/{config.num_epochs}\")\n        print('='*50)\n        \n        train_loss, train_acc = train_epoch(model, train_loader, criterion, \n                                           optimizer, config.device, scaler)\n        val_loss, val_acc, val_balanced_acc, val_f1, _, _ = validate_epoch(\n            model, val_loader, criterion, config.device)\n        \n        scheduler.step()\n        current_lr = optimizer.param_groups[0]['lr']\n        \n        print(f\"\\nResults:\")\n        print(f\"Train - Loss: {train_loss:.4f}, Acc: {train_acc:.4f}\")\n        print(f\"Val   - Loss: {val_loss:.4f}, Acc: {val_acc:.4f}, \"\n              f\"Balanced: {val_balanced_acc:.4f}, F1: {val_f1:.4f}\")\n        print(f\"LR: {current_lr:.2e}\")\n        \n        if val_balanced_acc > best_balanced_acc:\n            best_balanced_acc = val_balanced_acc\n            torch.save({\n                'epoch': epoch,\n                'model_state_dict': model.state_dict(),\n                'optimizer_state_dict': optimizer.state_dict(),\n                'best_balanced_acc': best_balanced_acc,\n                'class_names': class_names\n            }, 'best_chest_xray_model_effnetv2s.pth')\n            print(f\"New best: Balanced Acc {best_balanced_acc:.4f}\")\n            patience_counter = 0\n        else:\n            patience_counter += 1\n        \n        if patience_counter >= config.patience:\n            print(f\"\\nEarly stopping at epoch {epoch+1}\")\n            break\n    \n    print(f\"\\n{'='*60}\")\n    print(f\"TRAINING COMPLETE - Best: {best_balanced_acc:.4f}\")\n    print('='*60)\n    \n    # Final validation\n    checkpoint = torch.load('best_chest_xray_model_effnetv2s.pth', \n                          map_location=config.device, \n                          weights_only=False)\n    model.load_state_dict(checkpoint['model_state_dict'])\n    \n    _, final_acc, final_balanced, final_f1, final_preds, final_targets = validate_epoch(\n        model, val_loader, criterion, config.device)\n    \n    print(\"\\n\" + \"=\"*40)\n    print(\"FINAL VALIDATION REPORT\")\n    print(\"=\"*40)\n    print(f\"Accuracy: {final_acc:.4f}\")\n    print(f\"Balanced Accuracy: {final_balanced:.4f}\")\n    print(f\"F1 Score (Macro): {final_f1:.4f}\")\n    print(\"\\nDetailed Report:\")\n    print(classification_report(final_targets, final_preds, \n                               target_names=class_names, digits=4))\n    \n    # Confusion Matrix\n    cm = confusion_matrix(final_targets, final_preds)\n    plt.figure(figsize=(8, 6))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n                xticklabels=class_names, yticklabels=class_names)\n    plt.title(f'Confusion Matrix - EfficientNetV2-S\\nBalanced Acc: {final_balanced:.4f}')\n    plt.xlabel('Predicted')\n    plt.ylabel('Actual')\n    plt.tight_layout()\n    plt.savefig('confusion_matrix_effnetv2s.png', dpi=300, bbox_inches='tight')\n    plt.show()\n    \n    return model, class_names, best_balanced_acc\n\n# ==========================\n# Generate Submission\n# ==========================\ndef generate_submission():\n    print(\"\\n\" + \"=\"*60)\n    print(\"GENERATING SUBMISSION - EFFICIENTNETV2-S\")\n    print(\"=\"*60)\n    \n    checkpoint = torch.load('best_chest_xray_model_effnetv2s.pth', \n                          map_location=config.device,\n                          weights_only=False)\n    class_names = checkpoint['class_names']\n    \n    model = ChestXrayClassifier(num_classes=len(class_names), pretrained=False)\n    model.load_state_dict(checkpoint['model_state_dict'])\n    model = model.to(config.device)\n    model.eval()\n    \n    print(f\"Loaded model: Balanced Acc {checkpoint['best_balanced_acc']:.4f}\")\n    print(f\"Classes: {class_names}\")\n    \n    test_images = sorted([f for f in os.listdir(config.test_dir) \n                         if f.lower().endswith(('.png', '.jpg', '.jpeg'))])\n    \n    print(f\"\\nProcessing {len(test_images)} images...\")\n    \n    image_ids = []\n    predictions = []\n    confidences = []\n    \n    for i, img_name in enumerate(test_images):\n        if i % 500 == 0:\n            print(f\"Progress: {i}/{len(test_images)}\")\n        \n        img_path = os.path.join(config.test_dir, img_name)\n        \n        try:\n            image = Image.open(img_path).convert('RGB')\n            image_tensor = transform_test(image).unsqueeze(0).to(config.device)\n            \n            with torch.no_grad():\n                outputs = model(image_tensor)\n                probabilities = torch.softmax(outputs, dim=1)\n            \n            pred_class = torch.argmax(probabilities, dim=1).item()\n            confidence = torch.max(probabilities).item()\n            \n            image_ids.append(os.path.splitext(img_name)[0])\n            predictions.append(pred_class)\n            confidences.append(confidence)\n            \n        except Exception as e:\n            print(f\"Error {img_name}: {e}\")\n            image_ids.append(os.path.splitext(img_name)[0])\n            predictions.append(1)\n            confidences.append(0.33)\n    \n    # Create submission\n    submission_df = pd.DataFrame({\n        'Id': image_ids,\n        'Predicted': predictions\n    })\n    \n    submission_df = submission_df.sort_values('Id').reset_index(drop=True)\n    submission_df.to_csv('submission_effnetv2s.csv', index=False)\n    \n    print(f\"\\nSubmission complete!\")\n    print(f\"Total: {len(submission_df)}\")\n    \n    print(\"\\nDistribution:\")\n    for idx in range(len(class_names)):\n        count = (submission_df['Predicted'] == idx).sum()\n        pct = count / len(submission_df) * 100\n        print(f\"{class_names[idx]} (Class {idx}): {count} ({pct:.1f}%)\")\n    \n    print(f\"\\nConfidence - Mean: {np.mean(confidences):.4f}, \"\n          f\"Std: {np.std(confidences):.4f}\")\n    \n    return submission_df\n\n# ==========================\n# Main Execution\n# ==========================\nif __name__ == \"__main__\":\n    print(\"EfficientNetV2-S Chest X-Ray Classifier\")\n    print(\"=\"*60)\n    \n    try:\n        model, class_names, best_score = train_model()\n        submission = generate_submission()\n        \n        print(\"\\nComplete!\")\n        print(f\"Best score: {best_score:.4f}\")\n        print(\"Files: best_chest_xray_model_effnetv2s.pth, submission_effnetv2s.csv\")\n        \n    except Exception as e:\n        print(f\"\\nError: {e}\")\n        import traceback\n        traceback.print_exc()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-01T05:31:32.630997Z","iopub.execute_input":"2025-10-01T05:31:32.631331Z","iopub.status.idle":"2025-10-01T06:03:28.124237Z","shell.execute_reply.started":"2025-10-01T05:31:32.631306Z","shell.execute_reply":"2025-10-01T06:03:28.123517Z"},"jupyter":{"source_hidden":true,"outputs_hidden":true},"collapsed":true},"outputs":[{"name":"stdout","text":"Device: cuda\nImage size: 384\nEfficientNetV2-S Chest X-Ray Classifier\n============================================================\n\n============================================================\nTRAINING EFFICIENTNETV2-S FOR CHEST X-RAY CLASSIFICATION\n============================================================\n\n========================================\nCLASS DISTRIBUTION ANALYSIS\n========================================\nCOVID: 1,596 samples (18.6%)\nNormal: 6,310 samples (73.6%)\nViral Pneumonia: 666 samples (7.8%)\nTotal: 8,572 samples\n========================================\n\nClasses: ['COVID', 'Normal', 'Viral Pneumonia']\n\nTrain: 6,857 | Val: 1,715\n\nClass weights for sampling:\nClass 1: 0.454\nClass 2: 4.209\nClass 0: 1.782\n\nInitializing EfficientNetV2-S...\n","output_type":"stream"},{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/efficientnet_v2_s-dd5fe13b.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_v2_s-dd5fe13b.pth\n100%|██████████| 82.7M/82.7M [00:00<00:00, 186MB/s]\n","output_type":"stream"},{"name":"stdout","text":"Total parameters: 20,966,995\nTrainable parameters: 20,966,995\n\nClass weights: tensor([1.7815, 0.4543, 4.2093], device='cuda:0')\n\nStarting training for 25 epochs...\n\n==================================================\nEpoch 1/25\n==================================================\nBatch 0/215, Loss: 1.3806\nBatch 50/215, Loss: 0.1962\nBatch 100/215, Loss: 0.1291\nBatch 150/215, Loss: 0.0777\nBatch 200/215, Loss: 0.1969\n\nResults:\nTrain - Loss: 0.2738, Acc: 0.8117\nVal   - Loss: 0.1458, Acc: 0.9277, Balanced: 0.9564, F1: 0.9016\nLR: 9.05e-05\nNew best: Balanced Acc 0.9564\n\n==================================================\nEpoch 2/25\n==================================================\nBatch 0/215, Loss: 0.1052\nBatch 50/215, Loss: 0.0728\nBatch 100/215, Loss: 0.0335\nBatch 150/215, Loss: 0.0807\nBatch 200/215, Loss: 0.0259\n\nResults:\nTrain - Loss: 0.0715, Acc: 0.9580\nVal   - Loss: 0.1131, Acc: 0.9808, Balanced: 0.9655, F1: 0.9685\nLR: 6.55e-05\nNew best: Balanced Acc 0.9655\n\n==================================================\nEpoch 3/25\n==================================================\nBatch 0/215, Loss: 0.0311\nBatch 50/215, Loss: 0.0144\nBatch 100/215, Loss: 0.0350\nBatch 150/215, Loss: 0.0027\nBatch 200/215, Loss: 0.0063\n\nResults:\nTrain - Loss: 0.0377, Acc: 0.9767\nVal   - Loss: 0.1340, Acc: 0.9580, Balanced: 0.9772, F1: 0.9223\nLR: 3.45e-05\nNew best: Balanced Acc 0.9772\n\n==================================================\nEpoch 4/25\n==================================================\nBatch 0/215, Loss: 0.0800\nBatch 50/215, Loss: 0.0878\nBatch 100/215, Loss: 0.0487\nBatch 150/215, Loss: 0.0232\nBatch 200/215, Loss: 0.0159\n\nResults:\nTrain - Loss: 0.0340, Acc: 0.9824\nVal   - Loss: 0.1056, Acc: 0.9837, Balanced: 0.9748, F1: 0.9705\nLR: 9.55e-06\n\n==================================================\nEpoch 5/25\n==================================================\nBatch 0/215, Loss: 0.0004\nBatch 50/215, Loss: 0.0004\nBatch 100/215, Loss: 0.0235\nBatch 150/215, Loss: 0.0024\nBatch 200/215, Loss: 0.0203\n\nResults:\nTrain - Loss: 0.0297, Acc: 0.9873\nVal   - Loss: 0.1287, Acc: 0.9831, Balanced: 0.9729, F1: 0.9698\nLR: 1.00e-04\n\n==================================================\nEpoch 6/25\n==================================================\nBatch 0/215, Loss: 0.0194\nBatch 50/215, Loss: 0.0656\nBatch 100/215, Loss: 0.0011\nBatch 150/215, Loss: 0.0000\nBatch 200/215, Loss: 0.0908\n\nResults:\nTrain - Loss: 0.0641, Acc: 0.9781\nVal   - Loss: 0.2182, Acc: 0.9417, Balanced: 0.9544, F1: 0.9250\nLR: 9.76e-05\n\n==================================================\nEpoch 7/25\n==================================================\nBatch 0/215, Loss: 0.0015\nBatch 50/215, Loss: 0.0502\nBatch 100/215, Loss: 0.1250\nBatch 150/215, Loss: 0.0000\nBatch 200/215, Loss: 0.0002\n\nResults:\nTrain - Loss: 0.0744, Acc: 0.9794\nVal   - Loss: 0.1544, Acc: 0.9837, Balanced: 0.9813, F1: 0.9751\nLR: 9.05e-05\nNew best: Balanced Acc 0.9813\n\n==================================================\nEpoch 8/25\n==================================================\nBatch 0/215, Loss: 0.0000\nBatch 50/215, Loss: 0.1078\nBatch 100/215, Loss: 0.0000\nBatch 150/215, Loss: 0.2696\nBatch 200/215, Loss: 0.0544\n\nResults:\nTrain - Loss: 0.0496, Acc: 0.9857\nVal   - Loss: 0.2274, Acc: 0.9878, Balanced: 0.9717, F1: 0.9740\nLR: 7.94e-05\n\n==================================================\nEpoch 9/25\n==================================================\nBatch 0/215, Loss: 0.0000\nBatch 50/215, Loss: 0.0140\nBatch 100/215, Loss: 0.0000\nBatch 150/215, Loss: 0.0000\nBatch 200/215, Loss: 0.0000\n\nResults:\nTrain - Loss: 0.0374, Acc: 0.9908\nVal   - Loss: 0.3070, Acc: 0.9889, Balanced: 0.9673, F1: 0.9761\nLR: 6.55e-05\n\n==================================================\nEpoch 10/25\n==================================================\nBatch 0/215, Loss: 0.0000\nBatch 50/215, Loss: 0.0000\nBatch 100/215, Loss: 0.0000\nBatch 150/215, Loss: 0.0000\nBatch 200/215, Loss: 0.1207\n\nResults:\nTrain - Loss: 0.0270, Acc: 0.9934\nVal   - Loss: 0.2557, Acc: 0.9872, Balanced: 0.9706, F1: 0.9733\nLR: 5.00e-05\n\n==================================================\nEpoch 11/25\n==================================================\nBatch 0/215, Loss: 0.0000\nBatch 50/215, Loss: 0.1705\nBatch 100/215, Loss: 0.0000\nBatch 150/215, Loss: 0.0000\nBatch 200/215, Loss: 0.0000\n\nResults:\nTrain - Loss: 0.0215, Acc: 0.9939\nVal   - Loss: 0.2984, Acc: 0.9860, Balanced: 0.9727, F1: 0.9739\nLR: 3.45e-05\n\n==================================================\nEpoch 12/25\n==================================================\nBatch 0/215, Loss: 0.0806\nBatch 50/215, Loss: 0.0000\nBatch 100/215, Loss: 0.0001\nBatch 150/215, Loss: 0.0000\nBatch 200/215, Loss: 0.0000\n\nResults:\nTrain - Loss: 0.0106, Acc: 0.9964\nVal   - Loss: 0.2177, Acc: 0.9889, Balanced: 0.9796, F1: 0.9784\nLR: 2.06e-05\n\n==================================================\nEpoch 13/25\n==================================================\nBatch 0/215, Loss: 0.0000\nBatch 50/215, Loss: 0.0000\nBatch 100/215, Loss: 0.0000\nBatch 150/215, Loss: 0.0724\nBatch 200/215, Loss: 0.0000\n\nResults:\nTrain - Loss: 0.0198, Acc: 0.9966\nVal   - Loss: 0.4022, Acc: 0.9843, Balanced: 0.9604, F1: 0.9708\nLR: 9.55e-06\n\n==================================================\nEpoch 14/25\n==================================================\nBatch 0/215, Loss: 0.0000\nBatch 50/215, Loss: 0.0000\nBatch 100/215, Loss: 0.0000\nBatch 150/215, Loss: 0.0000\nBatch 200/215, Loss: 0.0000\n\nResults:\nTrain - Loss: 0.0152, Acc: 0.9974\nVal   - Loss: 0.3525, Acc: 0.9878, Balanced: 0.9652, F1: 0.9747\nLR: 2.45e-06\n\n==================================================\nEpoch 15/25\n==================================================\nBatch 0/215, Loss: 0.0000\nBatch 50/215, Loss: 0.0000\nBatch 100/215, Loss: 0.0000\nBatch 150/215, Loss: 0.0000\nBatch 200/215, Loss: 0.0000\n\nResults:\nTrain - Loss: 0.0117, Acc: 0.9978\nVal   - Loss: 0.3128, Acc: 0.9883, Balanced: 0.9679, F1: 0.9763\nLR: 1.00e-04\n\nEarly stopping at epoch 15\n\n============================================================\nTRAINING COMPLETE - Best: 0.9813\n============================================================\n\n========================================\nFINAL VALIDATION REPORT\n========================================\nAccuracy: 0.9837\nBalanced Accuracy: 0.9813\nF1 Score (Macro): 0.9751\n\nDetailed Report:\n                 precision    recall  f1-score   support\n\n          COVID     0.9453    0.9936    0.9688       313\n         Normal     0.9952    0.9828    0.9890      1279\nViral Pneumonia     0.9675    0.9675    0.9675       123\n\n       accuracy                         0.9837      1715\n      macro avg     0.9693    0.9813    0.9751      1715\n   weighted avg     0.9841    0.9837    0.9838      1715\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 800x600 with 2 Axes>","image/png":"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\n"},"metadata":{}},{"name":"stdout","text":"\n============================================================\nGENERATING SUBMISSION - EFFICIENTNETV2-S\n============================================================\nLoaded model: Balanced Acc 0.9813\nClasses: ['COVID', 'Normal', 'Viral Pneumonia']\n\nProcessing 6382 images...\nProgress: 0/6382\nProgress: 500/6382\nProgress: 1000/6382\nProgress: 1500/6382\nProgress: 2000/6382\nProgress: 2500/6382\nProgress: 3000/6382\nProgress: 3500/6382\nProgress: 4000/6382\nProgress: 4500/6382\nProgress: 5000/6382\nProgress: 5500/6382\nProgress: 6000/6382\n\nSubmission complete!\nTotal: 6382\n\nDistribution:\nCOVID (Class 0): 2031 (31.8%)\nNormal (Class 1): 3681 (57.7%)\nViral Pneumonia (Class 2): 670 (10.5%)\n\nConfidence - Mean: 0.9970, Std: 0.0283\n\nComplete!\nBest score: 0.9813\nFiles: best_chest_xray_model_effnetv2s.pth, submission_effnetv2s.csv\n","output_type":"stream"}],"execution_count":19},{"cell_type":"markdown","source":"**REGNET**","metadata":{}},{"cell_type":"code","source":"import os\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, random_split, WeightedRandomSampler, Subset\nfrom torchvision import datasets, transforms, models\nfrom sklearn.metrics import classification_report, confusion_matrix, balanced_accuracy_score, f1_score\nimport pandas as pd\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nfrom collections import Counter\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# ==========================\n# Configuration\n# ==========================\nclass Config:\n    train_dir = \"/kaggle/input/final-srifoton-25-machine-learning-competition/train/train\"\n    test_dir = \"/kaggle/input/final-srifoton-25-machine-learning-competition/test/test\"\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    \n    batch_size = 32\n    learning_rate = 1e-4\n    weight_decay = 1e-4\n    num_epochs = 25\n    patience = 8\n    img_size = 224\n    \n    print(f\"Device: {device}\")\n    print(f\"Image size: {img_size}\")\n\nconfig = Config()\n\n# ==========================\n# Data Transforms\n# ==========================\ntransform_train = transforms.Compose([\n    transforms.Resize((config.img_size, config.img_size)),\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.RandomRotation(degrees=10),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\ntransform_val = transforms.Compose([\n    transforms.Resize((config.img_size, config.img_size)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\ntransform_test = transform_val\n\n# ==========================\n# Helper Functions\n# ==========================\ndef analyze_class_distribution(dataset_path):\n    class_counts = {}\n    total = 0\n    \n    for class_name in os.listdir(dataset_path):\n        class_path = os.path.join(dataset_path, class_name)\n        if os.path.isdir(class_path):\n            count = len([f for f in os.listdir(class_path) \n                        if f.lower().endswith(('.png', '.jpg', '.jpeg'))])\n            class_counts[class_name] = count\n            total += count\n    \n    print(\"\\n\" + \"=\"*40)\n    print(\"CLASS DISTRIBUTION ANALYSIS\")\n    print(\"=\"*40)\n    for class_name, count in sorted(class_counts.items()):\n        percentage = (count / total) * 100 if total > 0 else 0\n        print(f\"{class_name}: {count:,} samples ({percentage:.1f}%)\")\n    print(f\"Total: {total:,} samples\")\n    print(\"=\"*40)\n    \n    return class_counts, total\n\ndef create_weighted_sampler(dataset):\n    \"\"\"\n    dataset can be an ImageFolder or a Subset of ImageFolder.\n    This function computes per-sample weights based on class frequency.\n    \"\"\"\n    # get label for each sample\n    labels = []\n    for i in range(len(dataset)):\n        _, label = dataset[i]\n        labels.append(label)\n    class_counts = Counter(labels)\n    total_samples = len(labels)\n    num_classes = len(class_counts)\n    \n    # avoid division by zero\n    class_weights = {cls: total_samples / (num_classes * count) if count > 0 else 0.0\n                     for cls, count in class_counts.items()}\n    \n    sample_weights = [class_weights[label] for label in labels]\n    \n    print(\"\\nClass weights for sampling:\")\n    for class_idx, weight in class_weights.items():\n        print(f\"Class {class_idx}: {weight:.3f}\")\n    \n    return WeightedRandomSampler(\n        weights=sample_weights,\n        num_samples=len(sample_weights),\n        replacement=True\n    )\n\n# ==========================\n# Model (RegNet - regnet_y_1_6gf)\n# ==========================\nclass ChestXrayClassifier(nn.Module):\n    def __init__(self, num_classes=3, pretrained=True):\n        super(ChestXrayClassifier, self).__init__()\n        \n        # Load RegNet backbone (y_1_6gf is a good-performance variant)\n        # If your torchvision version doesn't accept pretrained=True, replace with weights=...\n        self.backbone = models.regnet_y_1_6gf(pretrained=pretrained)\n        \n        # RegNet's final layer is `fc`\n        num_features = self.backbone.fc.in_features\n        \n        # Remove original classifier head\n        self.backbone.fc = nn.Identity()\n        \n        # Custom classifier head (kept similar to previous DenseNet head)\n        self.classifier = nn.Sequential(\n            nn.Dropout(0.5),\n            nn.Linear(num_features, 512),\n            nn.BatchNorm1d(512),\n            nn.ReLU(inplace=True),\n            \n            nn.Dropout(0.3),\n            nn.Linear(512, 256),\n            nn.BatchNorm1d(256),\n            nn.ReLU(inplace=True),\n            \n            nn.Dropout(0.2),\n            nn.Linear(256, num_classes)\n        )\n        \n        self._init_classifier()\n    \n    def _init_classifier(self):\n        for m in self.classifier.modules():\n            if isinstance(m, nn.Linear):\n                nn.init.xavier_uniform_(m.weight)\n                if m.bias is not None:\n                    nn.init.constant_(m.bias, 0)\n    \n    def forward(self, x):\n        features = self.backbone(x)\n        return self.classifier(features)\n\n# ==========================\n# Training Functions\n# ==========================\ndef calculate_class_weights(dataset):\n    \"\"\"\n    Calculate class weights for CrossEntropyLoss based on dataset labels.\n    Works with Subset or ImageFolder.\n    \"\"\"\n    labels = []\n    for i in range(len(dataset)):\n        _, label = dataset[i]\n        labels.append(label)\n    class_counts = Counter(labels)\n    total = sum(class_counts.values())\n    num_classes = len(class_counts)\n    \n    weights = []\n    for cls_idx in range(num_classes):\n        count = class_counts.get(cls_idx, 0)\n        weight = total / (num_classes * count) if count > 0 else 0.0\n        weights.append(weight)\n    \n    return torch.FloatTensor(weights)\n\ndef train_epoch(model, dataloader, criterion, optimizer, device):\n    model.train()\n    total_loss = 0.0\n    correct_predictions = 0\n    total_samples = 0\n    \n    for batch_idx, (inputs, targets) in enumerate(dataloader):\n        inputs, targets = inputs.to(device), targets.to(device)\n        \n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = criterion(outputs, targets)\n        \n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n        optimizer.step()\n        \n        total_loss += loss.item()\n        _, predicted = torch.max(outputs.data, 1)\n        total_samples += targets.size(0)\n        correct_predictions += (predicted == targets).sum().item()\n        \n        if batch_idx % 50 == 0:\n            print(f'Batch {batch_idx}/{len(dataloader)}, Loss: {loss.item():.4f}')\n    \n    avg_loss = total_loss / len(dataloader)\n    accuracy = correct_predictions / total_samples if total_samples > 0 else 0.0\n    \n    return avg_loss, accuracy\n\ndef validate_epoch(model, dataloader, criterion, device):\n    model.eval()\n    total_loss = 0.0\n    correct_predictions = 0\n    total_samples = 0\n    all_predictions = []\n    all_targets = []\n    \n    with torch.no_grad():\n        for inputs, targets in dataloader:\n            inputs, targets = inputs.to(device), targets.to(device)\n            \n            outputs = model(inputs)\n            loss = criterion(outputs, targets)\n            \n            total_loss += loss.item()\n            _, predicted = torch.max(outputs.data, 1)\n            total_samples += targets.size(0)\n            correct_predictions += (predicted == targets).sum().item()\n            \n            all_predictions.extend(predicted.cpu().numpy())\n            all_targets.extend(targets.cpu().numpy())\n    \n    avg_loss = total_loss / len(dataloader)\n    accuracy = correct_predictions / total_samples if total_samples > 0 else 0.0\n    balanced_acc = balanced_accuracy_score(all_targets, all_predictions) if len(all_targets) > 0 else 0.0\n    f1 = f1_score(all_targets, all_predictions, average='macro') if len(all_targets) > 0 else 0.0\n    \n    return avg_loss, accuracy, balanced_acc, f1, all_predictions, all_targets\n\n# ==========================\n# Main Training\n# ==========================\ndef train_model():\n    print(\"\\n\" + \"=\"*60)\n    print(\"TRAINING REGNET-Y-1_6GF FOR CHEST X-RAY CLASSIFICATION\")\n    print(\"=\"*60)\n    \n    # Load and analyze dataset\n    temp_dataset = datasets.ImageFolder(root=config.train_dir, transform=transform_val)\n    analyze_class_distribution(config.train_dir)\n    class_names = temp_dataset.classes\n    num_classes = len(class_names)\n    \n    print(f\"\\nClasses: {class_names}\")\n    \n    # Create datasets\n    full_dataset = datasets.ImageFolder(root=config.train_dir, transform=transform_train)\n    train_size = int(0.8 * len(full_dataset))\n    val_size = len(full_dataset) - train_size\n    train_dataset, val_temp = random_split(full_dataset, [train_size, val_size],\n                                          generator=torch.Generator().manual_seed(42))\n    \n    # Validation dataset (wrap underlying ImageFolder with val indices)\n    val_full_dataset = datasets.ImageFolder(root=config.train_dir, transform=transform_val)\n    \n    class ValDataset:\n        def __init__(self, base_dataset, indices):\n            self.base_dataset = base_dataset\n            self.indices = indices\n        \n        def __len__(self):\n            return len(self.indices)\n        \n        def __getitem__(self, idx):\n            return self.base_dataset[self.indices[idx]]\n    \n    val_dataset = ValDataset(val_full_dataset, val_temp.indices)\n    \n    print(f\"\\nTrain: {len(train_dataset):,} | Val: {len(val_dataset):,}\")\n    \n    # Create samplers and loaders\n    train_sampler = create_weighted_sampler(train_dataset)\n    \n    train_loader = DataLoader(train_dataset, batch_size=config.batch_size,\n                            sampler=train_sampler, num_workers=2, pin_memory=True)\n    val_loader = DataLoader(val_dataset, batch_size=config.batch_size,\n                          shuffle=False, num_workers=2, pin_memory=True)\n    \n    # Initialize model\n    print(f\"\\nInitializing RegNet (regnet_y_1_6gf)...\")\n    model = ChestXrayClassifier(num_classes=num_classes, pretrained=True)\n    model = model.to(config.device)\n    \n    total_params = sum(p.numel() for p in model.parameters())\n    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n    print(f\"Total parameters: {total_params:,}\")\n    print(f\"Trainable parameters: {trainable_params:,}\")\n    \n    # Loss and optimizer\n    class_weights = calculate_class_weights(train_dataset).to(config.device)\n    print(f\"\\nClass weights: {class_weights}\")\n    criterion = nn.CrossEntropyLoss(weight=class_weights)\n    \n    optimizer = optim.AdamW(model.parameters(), lr=config.learning_rate, \n                           weight_decay=config.weight_decay)\n    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', \n                                                     factor=0.5, patience=4, \n                                                     verbose=True, min_lr=1e-7)\n    \n    # Training loop\n    print(f\"\\nStarting training for {config.num_epochs} epochs...\")\n    best_balanced_acc = 0.0\n    patience_counter = 0\n    \n    for epoch in range(config.num_epochs):\n        print(f\"\\n{'='*50}\")\n        print(f\"Epoch {epoch+1}/{config.num_epochs}\")\n        print('='*50)\n        \n        train_loss, train_acc = train_epoch(model, train_loader, criterion, \n                                           optimizer, config.device)\n        val_loss, val_acc, val_balanced_acc, val_f1, _, _ = validate_epoch(\n            model, val_loader, criterion, config.device)\n        \n        scheduler.step(val_balanced_acc)\n        current_lr = optimizer.param_groups[0]['lr']\n        \n        print(f\"\\nResults:\")\n        print(f\"Train - Loss: {train_loss:.4f}, Acc: {train_acc:.4f}\")\n        print(f\"Val   - Loss: {val_loss:.4f}, Acc: {val_acc:.4f}, \"\n              f\"Balanced: {val_balanced_acc:.4f}, F1: {val_f1:.4f}\")\n        print(f\"LR: {current_lr:.2e}\")\n        \n        if val_balanced_acc > best_balanced_acc:\n            best_balanced_acc = val_balanced_acc\n            torch.save({\n                'epoch': epoch,\n                'model_state_dict': model.state_dict(),\n                'optimizer_state_dict': optimizer.state_dict(),\n                'best_balanced_acc': best_balanced_acc,\n                'class_names': class_names\n            }, 'best_chest_xray_model_regnet_y_1_6gf.pth')\n            print(f\"New best: Balanced Acc {best_balanced_acc:.4f}\")\n            patience_counter = 0\n        else:\n            patience_counter += 1\n        \n        if patience_counter >= config.patience:\n            print(f\"\\nEarly stopping at epoch {epoch+1}\")\n            break\n    \n    print(f\"\\n{'='*60}\")\n    print(f\"TRAINING COMPLETE - Best: {best_balanced_acc:.4f}\")\n    print('='*60)\n    \n    # Final validation - load best checkpoint\n    checkpoint = torch.load('best_chest_xray_model_regnet_y_1_6gf.pth', \n                          map_location=config.device)\n    model.load_state_dict(checkpoint['model_state_dict'])\n    \n    _, final_acc, final_balanced, final_f1, final_preds, final_targets = validate_epoch(\n        model, val_loader, criterion, config.device)\n    \n    print(\"\\n\" + \"=\"*40)\n    print(\"FINAL VALIDATION REPORT\")\n    print(\"=\"*40)\n    print(f\"Accuracy: {final_acc:.4f}\")\n    print(f\"Balanced Accuracy: {final_balanced:.4f}\")\n    print(f\"F1 Score (Macro): {final_f1:.4f}\")\n    print(\"\\nDetailed Report:\")\n    print(classification_report(final_targets, final_preds, \n                               target_names=class_names, digits=4))\n    \n    # Confusion Matrix\n    cm = confusion_matrix(final_targets, final_preds)\n    plt.figure(figsize=(8, 6))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n                xticklabels=class_names, yticklabels=class_names)\n    plt.title(f'Confusion Matrix - RegNet-Y-1_6GF\\nBalanced Acc: {final_balanced:.4f}')\n    plt.xlabel('Predicted')\n    plt.ylabel('Actual')\n    plt.tight_layout()\n    plt.savefig('confusion_matrix_regnet_y_1_6gf.png', dpi=300, bbox_inches='tight')\n    plt.show()\n    \n    return model, class_names, best_balanced_acc\n\n# ==========================\n# Prediction Functions\n# ==========================\ndef predict_with_tta(model, image_path):\n    model.eval()\n    \n    tta_transforms = [\n        transform_test,\n        transforms.Compose([\n            transforms.Resize((config.img_size, config.img_size)),\n            transforms.RandomHorizontalFlip(p=1.0),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n        ]),\n        transforms.Compose([\n            transforms.Resize((config.img_size, config.img_size)),\n            transforms.RandomRotation(degrees=5),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n        ])\n    ]\n    \n    predictions = []\n    \n    with torch.no_grad():\n        for transform in tta_transforms:\n            try:\n                image = Image.open(image_path).convert('RGB')\n                image_tensor = transform(image).unsqueeze(0).to(config.device)\n                \n                outputs = model(image_tensor)\n                probabilities = torch.softmax(outputs, dim=1)\n                predictions.append(probabilities.cpu().numpy())\n            except Exception:\n                continue\n    \n    if predictions:\n        return np.mean(predictions, axis=0)\n    else:\n        image = Image.open(image_path).convert('RGB')\n        image_tensor = transform_test(image).unsqueeze(0).to(config.device)\n        outputs = model(image_tensor)\n        probabilities = torch.softmax(outputs, dim=1)\n        return probabilities.cpu().numpy()\n\n# ==========================\n# Generate Submission\n# ==========================\ndef generate_submission():\n    print(\"\\n\" + \"=\"*60)\n    print(\"GENERATING SUBMISSION - REGNET-Y-1_6GF\")\n    print(\"=\"*60)\n    \n    checkpoint = torch.load('best_chest_xray_model_regnet_y_1_6gf.pth', \n                          map_location=config.device)\n    class_names = checkpoint['class_names']\n    \n    model = ChestXrayClassifier(num_classes=len(class_names), pretrained=False)\n    model.load_state_dict(checkpoint['model_state_dict'])\n    model = model.to(config.device)\n    model.eval()\n    \n    print(f\"Loaded model: Balanced Acc {checkpoint['best_balanced_acc']:.4f}\")\n    print(f\"Classes: {class_names}\")\n    \n    test_images = sorted([f for f in os.listdir(config.test_dir) \n                         if f.lower().endswith(('.png', '.jpg', '.jpeg'))])\n    \n    print(f\"\\nProcessing {len(test_images)} images...\")\n    \n    image_ids = []\n    predictions = []\n    confidences = []\n    \n    for i, img_name in enumerate(test_images):\n        if i % 500 == 0:\n            print(f\"Progress: {i}/{len(test_images)}\")\n        \n        img_path = os.path.join(config.test_dir, img_name)\n        \n        try:\n            prob_vector = predict_with_tta(model, img_path)\n            pred_class = np.argmax(prob_vector)\n            confidence = np.max(prob_vector)\n            \n            image_ids.append(os.path.splitext(img_name)[0])\n            predictions.append(pred_class)\n            confidences.append(confidence)\n            \n        except Exception as e:\n            print(f\"Error {img_name}: {e}\")\n            image_ids.append(os.path.splitext(img_name)[0])\n            predictions.append(1)\n            confidences.append(0.33)\n    \n    # Create submission\n    submission_df = pd.DataFrame({\n        'Id': image_ids,\n        'Predicted': predictions\n    })\n    \n    submission_df = submission_df.sort_values('Id').reset_index(drop=True)\n    submission_df.to_csv('submission_regnet_y_1_6gf.csv', index=False)\n    \n    print(f\"\\nSubmission complete!\")\n    print(f\"Total: {len(submission_df)}\")\n    \n    print(\"\\nDistribution:\")\n    for idx in range(len(class_names)):\n        count = (submission_df['Predicted'] == idx).sum()\n        pct = count / len(submission_df) * 100 if len(submission_df) > 0 else 0.0\n        print(f\"{class_names[idx]} (Class {idx}): {count} ({pct:.1f}%)\")\n    \n    print(f\"\\nConfidence - Mean: {np.mean(confidences):.4f}, \"\n          f\"Std: {np.std(confidences):.4f}\")\n    \n    return submission_df\n\n# ==========================\n# Main Execution\n# ==========================\nif __name__ == \"__main__\":\n    print(\"RegNet-Y-1_6GF Chest X-Ray Classifier\")\n    print(\"=\"*60)\n    \n    try:\n        model, class_names, best_score = train_model()\n        submission = generate_submission()\n        \n        print(\"\\nComplete!\")\n        print(f\"Best score: {best_score:.4f}\")\n        print(\"Files: best_chest_xray_model_regnet_y_1_6gf.pth, submission_regnet_y_1_6gf.csv\")\n        \n    except Exception as e:\n        print(f\"\\nError: {e}\")\n        import traceback\n        traceback.print_exc()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-01T08:13:42.905104Z","iopub.execute_input":"2025-10-01T08:13:42.905451Z","iopub.status.idle":"2025-10-01T08:35:37.777268Z","shell.execute_reply.started":"2025-10-01T08:13:42.905429Z","shell.execute_reply":"2025-10-01T08:35:37.776347Z"},"jupyter":{"outputs_hidden":true,"source_hidden":true},"collapsed":true},"outputs":[{"name":"stdout","text":"Device: cuda\nImage size: 224\nRegNet-Y-1_6GF Chest X-Ray Classifier\n============================================================\n\n============================================================\nTRAINING REGNET-Y-1_6GF FOR CHEST X-RAY CLASSIFICATION\n============================================================\n\n========================================\nCLASS DISTRIBUTION ANALYSIS\n========================================\nCOVID: 1,596 samples (18.6%)\nNormal: 6,310 samples (73.6%)\nViral Pneumonia: 666 samples (7.8%)\nTotal: 8,572 samples\n========================================\n\nClasses: ['COVID', 'Normal', 'Viral Pneumonia']\n\nTrain: 6,857 | Val: 1,715\n\nClass weights for sampling:\nClass 1: 0.454\nClass 2: 4.209\nClass 0: 1.782\n\nInitializing RegNet (regnet_y_1_6gf)...\n","output_type":"stream"},{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/regnet_y_1_6gf-b11a554e.pth\" to /root/.cache/torch/hub/checkpoints/regnet_y_1_6gf-b11a554e.pth\n100%|██████████| 43.2M/43.2M [00:00<00:00, 179MB/s] \n","output_type":"stream"},{"name":"stdout","text":"Total parameters: 10,902,233\nTrainable parameters: 10,902,233\n\nClass weights: tensor([1.7815, 0.4543, 4.2093], device='cuda:0')\n\nStarting training for 25 epochs...\n\n==================================================\nEpoch 1/25\n==================================================\nBatch 0/215, Loss: 1.0354\nBatch 50/215, Loss: 0.2368\nBatch 100/215, Loss: 0.1512\nBatch 150/215, Loss: 0.1683\nBatch 200/215, Loss: 0.0353\n\nResults:\nTrain - Loss: 0.2465, Acc: 0.7890\nVal   - Loss: 0.1842, Acc: 0.9668, Balanced: 0.9333, F1: 0.9485\nLR: 1.00e-04\nNew best: Balanced Acc 0.9333\n\n==================================================\nEpoch 2/25\n==================================================\nBatch 0/215, Loss: 0.0926\nBatch 50/215, Loss: 0.0212\nBatch 100/215, Loss: 0.1451\nBatch 150/215, Loss: 0.0838\nBatch 200/215, Loss: 0.0099\n\nResults:\nTrain - Loss: 0.0680, Acc: 0.9533\nVal   - Loss: 0.1013, Acc: 0.9697, Balanced: 0.9654, F1: 0.9551\nLR: 1.00e-04\nNew best: Balanced Acc 0.9654\n\n==================================================\nEpoch 3/25\n==================================================\nBatch 0/215, Loss: 0.0126\nBatch 50/215, Loss: 0.0270\nBatch 100/215, Loss: 0.0376\nBatch 150/215, Loss: 0.0030\nBatch 200/215, Loss: 0.0188\n\nResults:\nTrain - Loss: 0.0480, Acc: 0.9711\nVal   - Loss: 0.1526, Acc: 0.9697, Balanced: 0.9582, F1: 0.9481\nLR: 1.00e-04\n\n==================================================\nEpoch 4/25\n==================================================\nBatch 0/215, Loss: 0.1906\nBatch 50/215, Loss: 0.0019\nBatch 100/215, Loss: 0.0573\nBatch 150/215, Loss: 0.0034\nBatch 200/215, Loss: 0.0127\n\nResults:\nTrain - Loss: 0.0309, Acc: 0.9787\nVal   - Loss: 0.1156, Acc: 0.9726, Balanced: 0.9773, F1: 0.9501\nLR: 1.00e-04\nNew best: Balanced Acc 0.9773\n\n==================================================\nEpoch 5/25\n==================================================\nBatch 0/215, Loss: 0.0004\nBatch 50/215, Loss: 0.0087\nBatch 100/215, Loss: 0.0622\nBatch 150/215, Loss: 0.0029\nBatch 200/215, Loss: 0.0032\n\nResults:\nTrain - Loss: 0.0313, Acc: 0.9821\nVal   - Loss: 0.0837, Acc: 0.9819, Balanced: 0.9741, F1: 0.9676\nLR: 1.00e-04\n\n==================================================\nEpoch 6/25\n==================================================\nBatch 0/215, Loss: 0.0550\nBatch 50/215, Loss: 0.0188\nBatch 100/215, Loss: 0.0012\nBatch 150/215, Loss: 0.0036\nBatch 200/215, Loss: 0.0004\n\nResults:\nTrain - Loss: 0.0247, Acc: 0.9856\nVal   - Loss: 0.2141, Acc: 0.9796, Balanced: 0.9558, F1: 0.9645\nLR: 1.00e-04\n\n==================================================\nEpoch 7/25\n==================================================\nBatch 0/215, Loss: 0.0179\nBatch 50/215, Loss: 0.0009\nBatch 100/215, Loss: 0.0005\nBatch 150/215, Loss: 0.0073\nBatch 200/215, Loss: 0.0042\n\nResults:\nTrain - Loss: 0.0229, Acc: 0.9867\nVal   - Loss: 0.1404, Acc: 0.9860, Balanced: 0.9620, F1: 0.9727\nLR: 1.00e-04\n\n==================================================\nEpoch 8/25\n==================================================\nBatch 0/215, Loss: 0.0145\nBatch 50/215, Loss: 0.0157\nBatch 100/215, Loss: 0.1434\nBatch 150/215, Loss: 0.0005\nBatch 200/215, Loss: 0.0007\n\nResults:\nTrain - Loss: 0.0191, Acc: 0.9885\nVal   - Loss: 0.1305, Acc: 0.9831, Balanced: 0.9632, F1: 0.9714\nLR: 1.00e-04\n\n==================================================\nEpoch 9/25\n==================================================\nBatch 0/215, Loss: 0.0350\nBatch 50/215, Loss: 0.0018\nBatch 100/215, Loss: 0.0094\nBatch 150/215, Loss: 0.0010\nBatch 200/215, Loss: 0.0340\n\nResults:\nTrain - Loss: 0.0207, Acc: 0.9891\nVal   - Loss: 0.0931, Acc: 0.9854, Balanced: 0.9724, F1: 0.9735\nLR: 5.00e-05\n\n==================================================\nEpoch 10/25\n==================================================\nBatch 0/215, Loss: 0.0006\nBatch 50/215, Loss: 0.0001\nBatch 100/215, Loss: 0.0011\nBatch 150/215, Loss: 0.0061\nBatch 200/215, Loss: 0.0046\n\nResults:\nTrain - Loss: 0.0107, Acc: 0.9920\nVal   - Loss: 0.1451, Acc: 0.9848, Balanced: 0.9655, F1: 0.9729\nLR: 5.00e-05\n\n==================================================\nEpoch 11/25\n==================================================\nBatch 0/215, Loss: 0.0003\nBatch 50/215, Loss: 0.0923\nBatch 100/215, Loss: 0.0025\nBatch 150/215, Loss: 0.0002\nBatch 200/215, Loss: 0.0493\n\nResults:\nTrain - Loss: 0.0066, Acc: 0.9953\nVal   - Loss: 0.1208, Acc: 0.9854, Balanced: 0.9691, F1: 0.9742\nLR: 5.00e-05\n\n==================================================\nEpoch 12/25\n==================================================\nBatch 0/215, Loss: 0.0006\nBatch 50/215, Loss: 0.0001\nBatch 100/215, Loss: 0.0299\nBatch 150/215, Loss: 0.0008\nBatch 200/215, Loss: 0.0019\n\nResults:\nTrain - Loss: 0.0076, Acc: 0.9955\nVal   - Loss: 0.0998, Acc: 0.9866, Balanced: 0.9737, F1: 0.9749\nLR: 5.00e-05\n\nEarly stopping at epoch 12\n\n============================================================\nTRAINING COMPLETE - Best: 0.9773\n============================================================\n\nError: Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n\tWeightsUnpickler error: Unsupported global: GLOBAL numpy.core.multiarray.scalar was not an allowed global by default. Please use `torch.serialization.add_safe_globals([scalar])` or the `torch.serialization.safe_globals([scalar])` context manager to allowlist this global if you trust this class/function.\n\nCheck the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.\n","output_type":"stream"},{"name":"stderr","text":"Traceback (most recent call last):\n  File \"/tmp/ipykernel_36/2110193144.py\", line 517, in <cell line: 0>\n    model, class_names, best_score = train_model()\n                                     ^^^^^^^^^^^^^\n  File \"/tmp/ipykernel_36/2110193144.py\", line 360, in train_model\n    checkpoint = torch.load('best_chest_xray_model_regnet_y_1_6gf.pth',\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/serialization.py\", line 1470, in load\n    raise pickle.UnpicklingError(_get_wo_message(str(e))) from None\n_pickle.UnpicklingError: Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n\tWeightsUnpickler error: Unsupported global: GLOBAL numpy.core.multiarray.scalar was not an allowed global by default. Please use `torch.serialization.add_safe_globals([scalar])` or the `torch.serialization.safe_globals([scalar])` context manager to allowlist this global if you trust this class/function.\n\nCheck the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"**ENESEMBLE 4 MODEL**","metadata":{}},{"cell_type":"code","source":"# ============================================================\n# ENSEMBLE EfficientNet-B0 + B2 dengan TTA untuk Submission\n# ============================================================\nimport os\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torchvision import transforms, models\nfrom PIL import Image\nimport pandas as pd\nfrom tqdm import tqdm\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# ============================================================\n# CONFIG\n# ============================================================\nclass Config:\n    NUM_CLASSES = 3\n    IMG_SIZE_B0 = 224\n    IMG_SIZE_B2 = 260\n    \n    # Path model hasil training kamu\n    MODEL_B0_PATH = \"/kaggle/input/finetuning-b0/pytorch/default/1/best_final_finetuneB0.pth\"\n    MODEL_B2_PATH = \"/kaggle/input/finetuning-b2/pytorch/default/1/best_final_finetune_b2 (1)9927.pth\"\n    \n    TEST_DIR = \"/kaggle/input/final-srifoton-25-machine-learning-competition/test/test\"\n    SUBMISSION_PATH = \"/kaggle/working/submission.csv\"\n\nconfig = Config()\n\n# ============================================================\n# MODEL DEFINITIONS SAMA PERSIS DENGAN TRAINING\n# ============================================================\nclass EfficientXRayClassifierB0(nn.Module):\n    def _init_(self, num_classes=3, dropout=0.3):\n        super()._init_()\n        self.backbone = models.efficientnet_b0(weights=None)\n        in_features = self.backbone.classifier[1].in_features\n        self.backbone.classifier = nn.Sequential(\n            nn.Dropout(dropout),\n            nn.Linear(in_features, 256),\n            nn.ReLU(inplace=True),\n            nn.Dropout(dropout*0.5),\n            nn.Linear(256, num_classes)\n        )\n    def forward(self, x):\n        return self.backbone(x)\n\nclass EfficientXRayClassifierB2(nn.Module):\n    def _init_(self, num_classes=3, dropout=0.4):\n        super()._init_()\n        self.backbone = models.efficientnet_b2(weights=None)\n        in_features = self.backbone.classifier[1].in_features\n        self.backbone.classifier = nn.Sequential(\n            nn.Dropout(dropout),\n            nn.Linear(in_features, 512),\n            nn.ReLU(inplace=True),\n            nn.Dropout(dropout*0.5),\n            nn.Linear(512, num_classes)\n        )\n    def forward(self, x):\n        return self.backbone(x)\n\n# ============================================================\n# LOAD CHECKPOINT\n# ============================================================\ndef load_model(model_class, checkpoint_path, num_classes, dropout):\n    model = model_class(num_classes=num_classes, dropout=dropout)\n    checkpoint = torch.load(checkpoint_path, map_location=device)\n    model.load_state_dict(checkpoint[\"model_state_dict\"], strict=False)\n    model = model.to(device)\n    model.eval()\n    return model\n\n# ============================================================\n# TTA TRANSFORMS\n# ============================================================\ndef get_tta_transforms(img_size):\n    return [\n        transforms.Compose([\n            transforms.Resize((img_size, img_size)),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485,0.456,0.406],\n                                 std=[0.229,0.224,0.225])\n        ]),\n        transforms.Compose([\n            transforms.Resize((img_size, img_size)),\n            transforms.RandomHorizontalFlip(p=1.0),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485,0.456,0.406],\n                                 std=[0.229,0.224,0.225])\n        ]),\n        transforms.Compose([\n            transforms.Resize((img_size, img_size)),\n            transforms.RandomRotation(degrees=10, fill=0),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485,0.456,0.406],\n                                 std=[0.229,0.224,0.225])\n        ]),\n    ]\n\n# ============================================================\n# PREDICT ENSEMBLE + TTA UNTUK 1 GAMBAR\n# ============================================================\ndef predict_image(image, models_and_ttas):\n    all_logits = []\n    with torch.no_grad():\n        for model, tta_transforms in models_and_ttas:\n            logits_tta = []\n            for tta in tta_transforms:\n                img_tensor = tta(image).unsqueeze(0).to(device)\n                output = model(img_tensor)\n                logits_tta.append(output)\n            avg_logits = torch.mean(torch.stack(logits_tta), dim=0)\n            all_logits.append(avg_logits)\n    final_logits = torch.mean(torch.stack(all_logits), dim=0)\n    probs = F.softmax(final_logits, dim=1)\n    pred_class = torch.argmax(probs, dim=1).item()\n    return pred_class\n\n# ============================================================\n# MAIN INFERENCE\n# ============================================================\nif _name_ == \"_main_\":\n    # Load models sesuai training\n    model_b0 = load_model(EfficientXRayClassifierB0, config.MODEL_B0_PATH, config.NUM_CLASSES, dropout=0.3)\n    model_b2 = load_model(EfficientXRayClassifierB2, config.MODEL_B2_PATH, config.NUM_CLASSES, dropout=0.4)\n\n    # TTA untuk tiap model\n    tta_b0 = get_tta_transforms(config.IMG_SIZE_B0)\n    tta_b2 = get_tta_transforms(config.IMG_SIZE_B2)\n    models_and_ttas = [(model_b0, tta_b0), (model_b2, tta_b2)]\n\n    # Loop test set\n    test_images = sorted(os.listdir(config.TEST_DIR))\n    results = []\n    for img_name in tqdm(test_images, desc=\"Predicting\"):\n        img_path = os.path.join(config.TEST_DIR, img_name)\n        image = Image.open(img_path).convert(\"RGB\")\n        pred = predict_image(image, models_and_ttas)\n        img_id = os.path.splitext(img_name)[0]  # misal test_0000\n        results.append({\"Id\": img_id, \"Predicted\": pred})\n\n    # Save CSV submission\n    df = pd.DataFrame(results)\n    df.to_csv(config.SUBMISSION_PATH, index=False)\n    print(f\"✅ Submission saved to {config.SUBMISSION_PATH}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-01T07:53:30.345790Z","iopub.execute_input":"2025-10-01T07:53:30.345976Z","iopub.status.idle":"2025-10-01T07:53:41.534765Z","shell.execute_reply.started":"2025-10-01T07:53:30.345958Z","shell.execute_reply":"2025-10-01T07:53:41.534162Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":1}]}